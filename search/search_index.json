{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p> Official Python SDK for Lexsi.ai \u2014 Fast, Secure &amp; Developer-Friendly </p> <p> </p>"},{"location":"#lexsi-sdk","title":"lexsi-sdk","text":"<p><code>lexsi-sdk</code> is the official Python SDK for interacting with the Lexsi.ai platform. It provides a clean, high-performance interface for accessing chat completions, embeddings, model management, logging, and more \u2014 optimized for production workloads, enterprise integration, and research workflows.</p>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<p>Install from PyPI:</p> <pre><code>pip install lexsi-sdk\n</code></pre>"},{"location":"#examples-notebooks-for-sdk","title":"\ud83d\udcd3 Examples Notebooks for SDK","text":"Modality Notebook Description Tabular Classic ML ML Models Tabular TabTune TabTune Project"},{"location":"api/","title":"Lexsi REST API (curl snippets)","text":"<p>Use these ready-to-run curl with your Lexsi API key. Replace the placeholder values before running.</p>"},{"location":"api/#basic","title":"Basic","text":""},{"location":"api/#health-check","title":"Health check","text":"<pre><code>curl -X GET \"https://apiv1.lexsi.ai/healthcheck\"\n</code></pre>"},{"location":"api/#tabular-modality-api","title":"Tabular Modality API","text":""},{"location":"api/#generate-prediction-and-explainability","title":"Generate Prediction and Explainability","text":"<pre><code>curl --http2 -X POST \"https://apiv1.lexsi.ai/v2/project/case-register\" \\\n   -H \"x-api-token: &lt;$X_API_TOKEN&gt;\" \\\n   -H \"Content-Type: application/x-www-form-urlencoded\" \\\n   --data-urlencode \"client_id=&lt;$USERNAME&gt;\" \\\n   --data-urlencode \"project_name=&lt;$PROJECTNAME&gt;\" \\\n   --data-urlencode \"unique_identifier=&lt;$UNIQUE_IDENTIFIER&gt;\" \\\n   --data-urlencode \"tag=&lt;$Tag&gt;\" \\\n   --data-urlencode \"serverless_instance_type=&lt;$SERVERLESS_COMPUTE_TYPE&gt;\" \\\n   --data-urlencode \"xai=&lt;$EXPLAINABILITY_METHOD&gt;\" \\\n   --data-urlencode \"data=[{\n    \\\"$UNIQUE_ID_KEY\\\": \\\"$UNIQUE_IDENTIFIER\\\",\n    \\\"$SAMPLE_KEY\\\": \\\"$SAMPLE_VALUE\\\",\n    \\\"$SAMPLE_KEY\\\": \\\"$SAMPLE_VALUE\\\",\n        .\n        .\n    \\\"$SAMPLE_KEY\\\": \\\"$SAMPLE_VALUE\\\"\n  }]\"\n</code></pre> Placeholder Description <code>$X_API_TOKEN</code> Your Lexsi API token from the SDK or portal <code>$USERNAME</code> Your Lexsi username / client ID <code>$PROJECTNAME</code> Target project name <code>$UNIQUE_IDENTIFIER</code> Unique row ID for the registered case <code>$Tag</code> Dataset tag to attach to this upload or prediction <code>$SERVERLESS_COMPUTE_TYPE</code> Serverless instance type (e.g. <code>NOVA</code>, <code>GOVA</code>, or <code>local</code>) <code>$EXPLAINABILITY_METHOD</code> Explainability technique to run (e.g. <code>shap</code>, <code>lime</code>) <code>$data</code> List of JSON objects containing feature key/value pairs"},{"location":"api/#image-modality-api","title":"Image Modality API","text":"<pre><code>curl --http2 -X POST \"https://apiv1.lexsi.ai/v2/project/case-register\" \\\n   -H \"x-api-token: &lt;$X_API_TOKEN&gt;\" \\\n   -F \"client_id=&lt;$USERNAME&gt;\" \\\n   -F \"project_name=&lt;$PROJECT_NAME&gt;\" \\\n   -F \"unique_identifier=&lt;$UNIQUE_IDENTIFIER&gt;\" \\\n   -F \"tag=&lt;$TAG&gt;\" \\\n   -F \"xai=&lt;$EXPLAINABILITY_METHOD&gt;\" \\\n   -F \"serverless_instance_type=&lt;$SERVERLESS_COMPUTE_TYPE&gt;\" \\\n   -F \"in_file=&lt;$IMAGE_PATH&gt;\" \\\n   -F \"image_class=&lt;$IMAGE_CLASS&gt;\"\n</code></pre> Placeholder Description <code>$X_API_TOKEN</code> Your Lexsi API token <code>$USERNAME</code> Your Lexsi username / client ID <code>$PROJECT_NAME</code> Target project name for this image case <code>$UNIQUE_IDENTIFIER</code> Filename or unique identifier for the image case <code>$TAG</code> Tag to associate with the upload <code>$EXPLAINABILITY_METHOD</code> Explainability method to run (e.g.  <code>gradcam</code>,<code>dlb</code>,<code>ig</code>) <code>$SERVERLESS_COMPUTE_TYPE</code> Serverless instance type for processing <code>$IMAGE_PATH</code> Local filesystem path to the image file <code>$IMAGE_CLASS</code> Optional class or label for the image"},{"location":"api/#text-modality-apis","title":"Text Modality API's","text":""},{"location":"api/#text-generation-api","title":"Text Generation API","text":"<pre><code>curl --http2 -X POST 'https://apiv1.lexsi.ai/v2/project/case-register' \\\n  -H \"x-api-token: &lt;$API_TOKEN&gt;\" \\\n  -F \"provider= &lt;$MODEL_PROVIDER&gt;\" \\\n  -F \"client_id=&lt;$USERNAME&gt;\" \\\n  -F \"project_name=&lt;$PROJECT_NAME&gt;\" \\\n  -F \"prompt=&lt;$INPUT_PROMPT&gt;\" \\\n  -F \"serverless_instance_type=&lt;$SERVERLESS_COMPUTE_TYPE&gt;\" \\\n  -F \"model_name=&lt;$MODEL_NAME&gt;\" \\\n  -F \"min_tokens=&lt;$MIN_TOKENS&gt;\" \\\n  -F \"max_tokens=&lt;$MAX_TOKENS&gt;\" \\\n  -F \"session_id=&lt;$SESSION_ID&gt;\" \\\n  -F \"instance_type=&lt;$POD_INSTANCE_TYPE&gt;\" \\\n  -F \"explain_model=&lt;$EXPLAINABILTY_FLAG&gt;\"\n</code></pre> Placeholder Description <code>$API_TOKEN</code> Your Lexsi API token <code>$MODEL_PROVIDER</code> Provider identifier (e.g. <code>Lexsi</code>, <code>OpenAI</code>, <code>Grok</code>) <code>$USERNAME</code> Your Lexsi username / client ID <code>$PROJECT_NAME</code> Target text project name <code>$INPUT_PROMPT</code> User prompt to send to the model <code>$SERVERLESS_COMPUTE_TYPE</code> Serverless instance type for processing <code>$MODEL_NAME</code> Model name within the selected provider <code>$MIN_TOKENS</code> / <code>$MAX_TOKENS</code> Minimum and maximum tokens to generate (integers) <code>$SESSION_ID</code> Optional session ID for threaded or multi-turn conversations <code>$POD_INSTANCE_TYPE</code> Optional dedicated instance type for processing <code>$EXPLAINABILTY_FLAG</code> Boolean flag indicating whether explainability is computed"},{"location":"api/#chat-completions","title":"Chat completions","text":"<pre><code>curl --request POST 'https://apiv1.lexsi.ai/gateway/v1/chat/completions' \\\n  --header \"x-api-token: &lt;$API_TOKEN&gt;\" \\\n  --header 'Content-Type: application/json' \\\n  --data \"{\n    \\\"provider\\\": \\\"&lt;$MODEL_PROVIDER_NAME&gt;\\\",\n    \\\"api_key\\\": \\\"&lt;$API_KEY&gt;\\\",\n    \\\"client_id\\\": \\\"&lt;$USERNAME&gt;\\\",\n    \\\"max_tokens\\\": &lt;$MAX_NEW_TOKENS&gt;,\n    \\\"project_name\\\": \\\"&lt;$PROJECT_NAME&gt;\\\",\n    \\\"model\\\": \\\"&lt;$MODEL_NAME&gt;\\\",\n    \\\"messages\\\": [\n      {\n        \\\"role\\\": \\\"&lt;$ROLE&gt;\\\",\n        \\\"content\\\": \\\"&lt;$PROMPT&gt;\\\"\n      }\n    ],\n    \\\"stream\\\": &lt;$STREAM_BOOL&gt;\n  }\"\n</code></pre> Placeholder Description <code>$API_TOKEN</code> Your Lexsi API token <code>$MODEL_PROVIDER_NAME</code> Provider identifier (e.g. <code>openai</code>) <code>$API_KEY</code> Provider-specific API key or token, if required <code>$USERNAME</code> Your Lexsi username / client ID <code>$MAX_NEW_TOKENS</code> Maximum number of tokens to generate (integer) <code>$PROJECT_NAME</code> Target project name <code>$MODEL_NAME</code> Model name within the selected provider <code>$ROLE</code> Message role (e.g. <code>user</code>, <code>system</code>) <code>$PROMPT</code> Input text prompt <code>$STREAM_BOOL</code> Boolean flag (<code>true</code> or <code>false</code>) to enable or disable streaming responses"},{"location":"api/#completions","title":"Completions","text":"<pre><code>curl --request POST 'https://apiv1.lexsi.ai/gateway/v1/completions' \\\n  --header \"x-api-token: &lt;$API_TOKEN&gt;\" \\\n  --header 'Content-Type: application/json' \\\n  --data \"{\n    \\\"provider\\\": \\\"&lt;$MODEL_PROVIDER_NAME&gt;\\\",\n    \\\"api_key\\\": \\\"&lt;$API_KEY&gt;\\\",\n    \\\"client_id\\\": \\\"&lt;$USERNAME&gt;\\\",\n    \\\"max_tokens\\\": &lt;$MAX_NEW_TOKENS&gt;,\n    \\\"project_name\\\": \\\"&lt;$PROJECT_NAME&gt;\\\",\n    \\\"model\\\": \\\"&lt;$MODEL_NAME&gt;\\\",\n    \\\"prompt\\\": \\\"&lt;$PROMPT&gt;\\\",\n    \\\"stream\\\": \\\"&lt;$STREAM_BOOL&gt;\\\"\n  }\"\n</code></pre> Placeholder Description <code>$API_TOKEN</code> Your Lexsi API token <code>$MODEL_PROVIDER_NAME</code> Provider identifier (e.g. <code>openai</code>) <code>$API_KEY</code> Provider-specific API key or token, if required <code>$USERNAME</code> Your Lexsi username / client ID <code>$MAX_NEW_TOKENS</code> Maximum number of tokens to generate (integer) <code>$PROJECT_NAME</code> Target project name <code>$MODEL_NAME</code> Model name within the selected provider <code>$PROMPT</code> Input text prompt <code>$STREAM_BOOL</code> Boolean flag (<code>true</code> or <code>false</code>) to enable or disable streaming responses"},{"location":"api/#embeddings","title":"Embeddings","text":"<pre><code>curl -X POST \"https://apiv1.lexsi.ai/gateway/v1/embeddings\" \\\n  -H \"Authorization: Bearer $LEXSI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\n    \\\"model\\\": \\\"&lt;$MODEL_NAME&gt;\\\",\n    \\\"input\\\": [\\\"&lt;$INPUT_PROMPT&gt;\\\"]\n  }\"\n</code></pre> Placeholder Description <code>$LEXSI_API_KEY</code> Your Lexsi API key for gateway endpoints <code>$MODEL_NAME</code> Embedding model to use <code>$INPUT_PROMPT</code> Text input to generate embeddings for (single string or list of strings)"},{"location":"api/#image-generation","title":"Image generation","text":"<pre><code>curl -X POST \"https://apiv1.lexsi.ai/gateway/v1/images/generations\" \\\n  -H \"Authorization: Bearer $LEXSI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\n    \\\"model\\\": \\\"&lt;$MODEL_NAME&gt;\\\",\n    \\\"prompt\\\": \\\"&lt;$INPUT_PROMPT&gt;\\\"\n  }\"\n</code></pre> Placeholder Description <code>$LEXSI_API_KEY</code> Your Lexsi API key for gateway endpoints <code>$MODEL_NAME</code> Image generation model to use <code>$INPUT_PROMPT</code> Text prompt describing the image to generate"},{"location":"redoc/","title":"API Playground (Swagger UI)","text":"<p>Use the embedded Swagger UI to explore and call the Lexsi API. Replace the bearer token in the Authorize dialog with your <code>LEXSI_API_KEY</code>. Ensure CORS is allowed from this docs origin.</p> <p></p>"},{"location":"sdk/","title":"SDK Documentation","text":""},{"location":"sdk/#getting-started","title":"Getting Started","text":"<p>SDK token can be generated from the Lexsi Console under Dashboard \u2192 Access Token: https://console.lexsi.ai/dashboard/access-token</p> <pre><code>from lexsi_sdk import lexsi\n\n# Login using your Lexsi SDK Token\nlexsi.login(sdk_access_token=\"YOUR_SDK_TOKEN\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI","title":"LEXSI","text":"<pre><code>LEXSI(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Base entry-point class for interacting with the Lexsi.ai platform. Handles authentication, organization discovery and selection, notification retrieval, and provides access to higher-level SDK abstractions.</p> <p>Initialize the API client using environment-derived settings. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the API client using environment-derived settings.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n\n    debug = self.env.get_debug()\n    base_url = self.env.get_base_url()\n\n    self.api_client = APIClient(debug=debug, base_url=base_url)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.available_batch_servers","title":"available_batch_servers","text":"<pre><code>available_batch_servers()\n</code></pre> <p>Retrieve a dictionary of available batch servers (compute instances) that can be used for running custom batch tasks. Useful for selecting compute resources.</p> <p>Returns:</p> Type Description <code>dict</code> <p>response</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def available_batch_servers(self) -&gt; dict:\n    \"\"\"Retrieve a dictionary of available batch servers (compute instances) that can be used for running custom batch tasks. Useful for selecting compute resources.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.available_custom_servers","title":"available_custom_servers","text":"<pre><code>available_custom_servers()\n</code></pre> <p>Retrieve a dictionary or list of available custom servers that can be used for deploying models or running compute-heavy workloads.</p> <p>Returns:</p> Type Description <code>dict</code> <p>response</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def available_custom_servers(self) -&gt; dict:\n    \"\"\"Retrieve a dictionary or list of available custom servers that can be used for deploying models or running compute-heavy workloads.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.get(AVAILABLE_CUSTOM_SERVERS_URI)\n    return res\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.available_synthetic_custom_servers","title":"available_synthetic_custom_servers","text":"<pre><code>available_synthetic_custom_servers()\n</code></pre> <p>Retrieve details of custom servers available for generating synthetic data. This helps select the appropriate compute instance for synthetic data generation.</p> <p>Returns:</p> Type Description <code>dict</code> <p>response</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def available_synthetic_custom_servers(self) -&gt; dict:\n    \"\"\"Retrieve details of custom servers available for generating synthetic data. This helps select the appropriate compute instance for synthetic data generation.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.get(AVAILABLE_SYNTHETIC_CUSTOM_SERVERS_URI)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.clear_notifications","title":"clear_notifications","text":"<pre><code>clear_notifications()\n</code></pre> <p>Clear all notifications for the user by sending a POST request. Returns a confirmation string indicating success.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def clear_notifications(self) -&gt; str:\n    \"\"\"Clear all notifications for the user by sending a POST request. Returns a confirmation string indicating success.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.post(CLEAR_NOTIFICATIONS_URI)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while clearing user notifications.\")\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.create_organization","title":"create_organization","text":"<pre><code>create_organization(organization_name)\n</code></pre> <p>Create a new organization with the given name. It sends a POST request to the API and returns an Organization object representing the created organization.</p> <p>Parameters:</p> Name Type Description Default <code>organization_name</code> <code>str</code> <p>Name of the new organization</p> required <p>Returns:</p> Type Description <code>Organization</code> <p>Organization object</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def create_organization(self, organization_name: str) -&gt; Organization:\n    \"\"\"Create a new organization with the given name. It sends a POST request to the API and returns an Organization object representing the created organization.\n\n    :param organization_name: Name of the new organization\n    :return: Organization object\n    \"\"\"\n    payload = {\"organization_name\": organization_name}\n    res = self.api_client.post(CREATE_ORGANIZATION_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to create organization\"))\n\n    return Organization(api_client=self.api_client, **res[\"organization_details\"])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.get_notifications","title":"get_notifications","text":"<pre><code>get_notifications()\n</code></pre> <p>Fetch notifications for the user from Lexsi.ai. Notifications include project names, messages and timestamps and are returned as a DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>notification details dataFrame</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def get_notifications(self) -&gt; pd.DataFrame:\n    \"\"\"Fetch notifications for the user from Lexsi.ai. Notifications include project names, messages and timestamps and are returned as a DataFrame.\n\n    :return: notification details dataFrame\n    \"\"\"\n    res = self.api_client.get(GET_NOTIFICATIONS_URI)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while getting user notifications.\")\n\n    notifications = res[\"details\"]\n\n    if not notifications:\n        return \"No notifications found.\"\n\n    return pd.DataFrame(notifications).reindex(\n        columns=[\"project_name\", \"message\", \"time\"]\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.login","title":"login","text":"<pre><code>login(sdk_access_token=None)\n</code></pre> <p>Authenticate with Lexsi.ai using an access token. It prompts for or reads the access token from the environment variable XAI_ACCESS_TOKEN and sets it on the API client, enabling subsequent calls to the platform.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <p>API key, defaults to XAI_ACCESS_TOKEN environment variable</p> required Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def login(self, sdk_access_token: Optional[str] = None):\n    \"\"\"Authenticate with Lexsi.ai using an access token. It prompts for or reads the access token from the environment variable XAI_ACCESS_TOKEN and sets it on the API client, enabling subsequent calls to the platform.\n\n    :param api_key: API key, defaults to XAI_ACCESS_TOKEN environment variable\n    \"\"\"\n    if not sdk_access_token:\n        sdk_access_token = os.environ.get(\"XAI_ACCESS_TOKEN\", None) or getpass.getpass(\n            \"Enter your Lexsi.ai SDK Access Token: \"\n        )\n\n    if not sdk_access_token:\n        raise ValueError(\"Either set XAI_ACCESS_TOKEN or pass the Access token\")\n\n    res = self.api_client.post(LOGIN_URI, payload={\"access_token\": sdk_access_token})\n    self.api_client.update_headers(res[\"access_token\"])\n    self.api_client.set_access_token(sdk_access_token)\n\n    print(\"Authenticated successfully.\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.organization","title":"organization","text":"<pre><code>organization(organization_name)\n</code></pre> <p>Select a specific organization by its name. If the name is \"personal\", returns the personal organization. Otherwise, it searches the user\u2019s organizations and returns an Organization object for further management.</p> <p>Parameters:</p> Name Type Description Default <code>organization_name</code> <code>str</code> <p>Name of the organization to be used</p> required <p>Returns:</p> Type Description <code>Organization</code> <p>Organization object</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def organization(self, organization_name: str) -&gt; Organization:\n    \"\"\"Select a specific organization by its name. If the name is \"personal\", returns the personal organization. Otherwise, it searches the user\u2019s organizations and returns an Organization object for further management.\n\n    :param organization_name: Name of the organization to be used\n    :return: Organization object\n    \"\"\"\n    if organization_name == \"personal\":\n        return Organization(\n            api_client=self.api_client,\n            **{\n                \"name\": \"Personal\",\n                \"organization_owner\": True,\n                \"organization_admin\": True,\n                \"current_users\": 1,\n                \"created_by\": \"you\",\n            },\n        )\n\n    organizations = self.api_client.get(USER_ORGANIZATION_URI)\n\n    if not organizations[\"success\"]:\n        raise Exception(organizations.get(\"details\", \"Failed to get organizations\"))\n\n    user_organization = [\n        Organization(api_client=self.api_client, **organization)\n        for organization in organizations[\"details\"]\n    ]\n\n    organization = next(\n        filter(\n            lambda organization: organization.name == organization_name,\n            user_organization,\n        ),\n        None,\n    )\n\n    if organization is None:\n        raise Exception(\"Organization Not Found\")\n\n    return organization\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.organizations","title":"organizations","text":"<pre><code>organizations()\n</code></pre> <p>Retrieve all organizations associated with the authenticated user. Returns a DataFrame listing organization names and metadata such as ownership, admin status, number of users, creator, and creation date.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Organization details dataframe</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def organizations(self) -&gt; pd.DataFrame:\n    \"\"\"Retrieve all organizations associated with the authenticated user. Returns a DataFrame listing organization names and metadata such as ownership, admin status, number of users, creator, and creation date.\n\n    :return: Organization details dataframe\n    \"\"\"\n\n    res = self.api_client.get(USER_ORGANIZATION_URI)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to get organizations\"))\n\n    res[\"details\"].insert(\n        0,\n        {\n            \"name\": \"personal\",\n            \"organization_owner\": True,\n            \"organization_admin\": True,\n            \"current_users\": 1,\n            \"created_by\": res.get(\"current_user\", {}).get(\"username\", \"\"),\n            \"created_at\": res.get(\"current_user\", {}).get(\"created_at\", \"\"),\n        },\n    )\n\n    organization_df = pd.DataFrame(\n        res[\"details\"],\n        columns=[\n            \"name\",\n            \"organization_owner\",\n            \"organization_admin\",\n            \"current_users\",\n            \"created_by\",\n            \"created_at\",\n        ],\n    )\n\n    return organization_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.lexsi.LEXSI.register_case","title":"register_case","text":"<pre><code>register_case(\n    token,\n    client_id,\n    unique_identifier=None,\n    project_name=None,\n    tag=None,\n    data=None,\n    processed_data=False,\n    merge=False,\n    image_class=None,\n    prompt=None,\n    serverless_instance_type=None,\n    explainability_method=None,\n    explain_model=False,\n    session_id=None,\n    xai=None,\n    file_path=None,\n)\n</code></pre> <p>Register a new case entry with raw or processed payloads. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/lexsi.py</code> <pre><code>def register_case(\n    self,\n    token: str,\n    client_id: str,\n    unique_identifier: Optional[str] = None,\n    project_name: str = None,\n    tag: Optional[str] = None,\n    data: Optional[str] = None,\n    processed_data: Optional[bool] = False,\n    merge: Optional[bool] = False,\n    image_class: Optional[str] = None,\n    prompt: Optional[str] = None,\n    serverless_instance_type: Optional[str] = None,\n    explainability_method: Optional[str] = None,\n    explain_model: Optional[bool] = False,\n    session_id: Optional[str] = None,\n    xai: Optional[str] = None,\n    file_path: Optional[str] = None,\n):\n    \"\"\"Register a new case entry with raw or processed payloads.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    form_data = {\n        \"client_id\": client_id,\n        \"project_name\": project_name,\n        \"unique_identifier\": unique_identifier,\n        \"tag\": tag,\n        \"data\": json.dumps(data) if isinstance(data, list) else data,\n        \"processed_data\": str(processed_data).lower(),\n        \"merge\": str(merge).lower(),\n        \"image_class\": image_class,\n        \"prompt\": prompt,\n        \"serverless_instance_type\": serverless_instance_type,\n        \"explainability_method\": explainability_method,\n        \"explain_model\": str(explain_model).lower(),\n        \"session_id\": str(session_id).lower(),\n        \"xai\": xai,\n    }\n    headers = {\"x-api-token\": token}\n    form_data = {k: v for k, v in form_data.items() if v is not None}\n    files = {}\n    if file_path:\n        files[\"in_file\"] = open(file_path, \"rb\")\n    # response = requests.post(\n    #     self.env.get_base_url() + \"/\" + UPLOAD_DATA_PROJECT_URI,\n    #     data=form_data,\n    #     files=files if files else None,\n    #     headers=headers\n    # ).json()\n\n    with httpx.Client(http2=True, timeout=None) as client:\n        response = client.post(\n            self.env.get_base_url() + \"/\" + UPLOAD_DATA_PROJECT_URI,\n            data=form_data,\n            files=files or None,\n            headers=headers,\n        )\n        response.raise_for_status()\n        response = response.json()\n\n    if files:\n        files[\"in_file\"].close()\n    return response\n</code></pre>"},{"location":"sdk/#working-with-organizations","title":"Working With Organizations","text":"<p>The recommended pattern is:</p> <pre><code>organization = lexsi.organization(\"Your Organization name\")\n</code></pre> <p> You can use the following function with organization class :</p>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization","title":"Organization","text":"<pre><code>Organization(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Represents a Lexsi organization. Provides APIs to manage workspaces, users, data connectors, and organization-scoped resources.</p> <p>Attach API client to the organization instance. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Attach API client to the organization instance.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.add_user_to_organization","title":"add_user_to_organization","text":"<pre><code>add_user_to_organization(user_email)\n</code></pre> <p>Invite a user to join the organization by sending an invitation email. Requires the user\u2019s email address and uses the organization ID internally to associate the user.</p> <p>Parameters:</p> Name Type Description Default <code>user_email</code> <code>str</code> <p>Email of user to be added to organization.</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def add_user_to_organization(self, user_email: str) -&gt; str:\n    \"\"\"Invite a user to join the organization by sending an invitation email. Requires the user\u2019s email address and uses the organization ID internally to associate the user.\n\n    :param user_email: Email of user to be added to organization.\n    :return: response\n    \"\"\"\n    payload = {\n        \"email\": user_email,\n        \"organization_id\": self.organization_id,\n    }\n    res = self.api_client.post(INVITE_USER_ORGANIZATION_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to add user to organization\"))\n\n    return res.get(\"details\", \"User added successfully\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.create_data_connectors","title":"create_data_connectors","text":"<pre><code>create_data_connectors(\n    data_connector_name,\n    data_connector_type,\n    gcs_config=None,\n    s3_config=None,\n    gdrive_config=None,\n    sftp_config=None,\n    hf_token=None,\n)\n</code></pre> <p>Create a data connector for a project, allowing external data (e.g., S3, GCS, Google Drive, SFTP, Dropbox, HuggingFace) to be linked. Requires the connector name and type, plus the corresponding credential dictionary depending on the connector type.</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>str # name for data connector</p> required <code>data_connector_type</code> <code>str</code> <p>str # type of data connector (s3 | gcs | gdrive)</p> required <code>gcs_config</code> <code>Optional[GCSConfig]</code> <p>dict # credentials from service account json</p> <code>None</code> <code>s3_config</code> <code>Optional[S3Config]</code> <p>dict # credentials of s3 storage</p> <code>None</code> <code>gdrive_config</code> <code>Optional[GDriveConfig]</code> <p>dict # credentials from service account json</p> <code>None</code> <code>sftp_config</code> <code>Optional[SFTPConfig]</code> <p>dict # hostname, port, username and password for sftp connection</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def create_data_connectors(\n    self,\n    data_connector_name: str,\n    data_connector_type: str,\n    gcs_config: Optional[GCSConfig] = None,\n    s3_config: Optional[S3Config] = None,\n    gdrive_config: Optional[GDriveConfig] = None,\n    sftp_config: Optional[SFTPConfig] = None,\n    hf_token: Optional[str] = None,\n) -&gt; str:\n    \"\"\"Create a data connector for a project, allowing external data (e.g., S3, GCS, Google Drive, SFTP, Dropbox, HuggingFace) to be linked. Requires the connector name and type, plus the corresponding credential dictionary depending on the connector type.\n\n    :param data_connector_name: str # name for data connector\n    :param data_connector_type: str # type of data connector (s3 | gcs | gdrive)\n    :param gcs_config: dict # credentials from service account json\n    :param s3_config: dict # credentials of s3 storage\n    :param gdrive_config: dict # credentials from service account json\n    :param sftp_config: dict # hostname, port, username and password for sftp connection\n    :return: response\n    \"\"\"\n    if not self.organization_id:\n        return \"No Organization id found\"\n    if data_connector_type.lower() == \"s3\":\n        if not s3_config:\n            return \"No configuration for S3 found\"\n\n        Validate.value_against_list(\n            \"s3 config\",\n            list(s3_config.keys()),\n            [\"region\", \"access_key\", \"secret_key\"],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"region\": s3_config.get(\"region\", \"ap-south-1\"),\n                \"access_key\": s3_config.get(\"access_key\"),\n                \"secret_key\": s3_config.get(\"secret_key\"),\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type.lower() == \"gcs\":\n        if not gcs_config:\n            return \"No configuration for GCS found\"\n\n        Validate.value_against_list(\n            \"gcs config\",\n            list(gcs_config.keys()),\n            [\n                \"project_id\",\n                \"gcp_project_name\",\n                \"type\",\n                \"private_key_id\",\n                \"private_key\",\n                \"client_email\",\n                \"client_id\",\n                \"auth_uri\",\n                \"token_uri\",\n            ],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"project_id\": gcs_config.get(\"project_id\"),\n                \"gcp_project_name\": gcs_config.get(\"gcp_project_name\"),\n                \"service_account_json\": {\n                    \"type\": gcs_config.get(\"type\"),\n                    \"project_id\": gcs_config.get(\"project_id\"),\n                    \"private_key_id\": gcs_config.get(\"private_key_id\"),\n                    \"private_key\": gcs_config.get(\"private_key\"),\n                    \"client_email\": gcs_config.get(\"client_email\"),\n                    \"client_id\": gcs_config.get(\"client_id\"),\n                    \"auth_uri\": gcs_config.get(\"auth_uri\"),\n                    \"token_uri\": gcs_config.get(\"token_uri\"),\n                },\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"gdrive\":\n        if not gdrive_config:\n            return \"No configuration for Google Drive found\"\n\n        Validate.value_against_list(\n            \"gdrive config\",\n            list(gdrive_config.keys()),\n            [\n                \"project_id\",\n                \"type\",\n                \"private_key_id\",\n                \"private_key\",\n                \"client_email\",\n                \"client_id\",\n                \"auth_uri\",\n                \"token_uri\",\n            ],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"service_account_json\": {\n                    \"type\": gdrive_config.get(\"type\"),\n                    \"project_id\": gdrive_config.get(\"project_id\"),\n                    \"private_key_id\": gdrive_config.get(\"private_key_id\"),\n                    \"private_key\": gdrive_config.get(\"private_key\"),\n                    \"client_email\": gdrive_config.get(\"client_email\"),\n                    \"client_id\": gdrive_config.get(\"client_id\"),\n                    \"auth_uri\": gdrive_config.get(\"auth_uri\"),\n                    \"token_uri\": gdrive_config.get(\"token_uri\"),\n                },\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"sftp\":\n        if not sftp_config:\n            return \"No configuration for Google Drive found\"\n\n        Validate.value_against_list(\n            \"sftp config\",\n            list(sftp_config.keys()),\n            [\"hostname\", \"port\", \"username\", \"password\"],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"sftp_json\": {\n                    \"hostname\": sftp_config.get(\"hostname\"),\n                    \"port\": sftp_config.get(\"port\"),\n                    \"username\": sftp_config.get(\"username\"),\n                    \"password\": sftp_config.get(\"password\"),\n                },\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"dropbox\":\n        url_data = self.api_client.get(\n            f\"{DROPBOX_OAUTH}?organization_id={self.organization_id}\"\n        )\n        print(f\"Url: {url_data['details']['url']}\")\n        code = input(f\"{url_data['details']['message']}: \")\n\n        if not code:\n            return \"No authentication code provided.\"\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"dropbox_json\": {\"code\": code},\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"HuggingFace\":\n        if not hf_token:\n            return \"No hf_token provided\"\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"hf_token\": hf_token,\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    url = build_url(\n        CREATE_DATA_CONNECTORS, data_connector_name, None, self.organization_id\n    )\n    res = self.api_client.post(url, payload)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.create_workspace","title":"create_workspace","text":"<pre><code>create_workspace(workspace_name, server_type=None)\n</code></pre> <p>Create a new workspace within the organization. Accepts a workspace name and an optional server_type to specify the compute instance. Returns a Workspace object for the newly created workspace.</p> <p>Parameters:</p> Name Type Description Default <code>workspace_name</code> <code>str</code> <p>name for the workspace</p> required <code>server_type</code> <code>Optional[str]</code> <p>dedicated instance to run workloads for all available instances check xai.available_custom_servers() defaults to shared</p> <code>None</code> <p>Returns:</p> Type Description <code>Workspace</code> <p>response</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def create_workspace(\n    self, workspace_name: str, server_type: Optional[str] = None\n) -&gt; Workspace:\n    \"\"\"Create a new workspace within the organization. Accepts a workspace name and an optional server_type to specify the compute instance. Returns a Workspace object for the newly created workspace.\n\n    :param workspace_name: name for the workspace\n    :param server_type: dedicated instance to run workloads\n        for all available instances check xai.available_custom_servers()\n        defaults to shared\n    :return: response\n    \"\"\"\n    payload = {\"workspace_name\": workspace_name}\n\n    if server_type:\n        custom_servers = self.api_client.get(AVAILABLE_CUSTOM_SERVERS_URI)\n        Validate.value_against_list(\n            \"server_type\",\n            server_type,\n            [server[\"name\"] for server in custom_servers],\n        )\n\n        payload[\"instance_type\"] = server_type\n        payload[\"server_config\"] = {}\n\n    if self.organization_id:\n        payload[\"organization_id\"] = self.organization_id\n\n    res = self.api_client.post(CREATE_WORKSPACE_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    workspace = Workspace(api_client=self.api_client, **res[\"workspace_details\"])\n\n    return workspace\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.credits","title":"credits","text":"<pre><code>credits()\n</code></pre> <p>Return credit usage and quota information for the organization.</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def credits(self):\n    \"\"\"Return credit usage and quota information for the organization.\"\"\"\n    url = build_list_data_connector_url(\n        COMPUTE_CREDIT_URI, None, self.organization_id\n    )\n    res = self.api_client.get(url)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.delete_data_connectors","title":"delete_data_connectors","text":"<pre><code>delete_data_connectors(data_connector_name)\n</code></pre> <p>Delete a data connector from the organization using its name. This removes the external data link and returns a confirmation message.</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def delete_data_connectors(self, data_connector_name) -&gt; str:\n    \"\"\"Delete a data connector from the organization using its name. This removes the external data link and returns a confirmation message.\n\n    :param data_connector_name: str\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id:\n        return \"No Project Name or Organization id found\"\n\n    url = build_url(\n        DELETE_DATA_CONNECTORS, data_connector_name, None, self.organization_id\n    )\n    res = self.api_client.post(url)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.list_data_connectors","title":"list_data_connectors","text":"<pre><code>list_data_connectors()\n</code></pre> <p>List all data connectors configured in the organization. If successful, returns a DataFrame with details about each connector; otherwise returns an error message.</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def list_data_connectors(self) -&gt; str | pd.DataFrame:\n    \"\"\"List all data connectors configured in the organization. If successful, returns a DataFrame with details about each connector; otherwise returns an error message.\"\"\"\n    url = build_list_data_connector_url(\n        LIST_DATA_CONNECTORS, None, self.organization_id\n    )\n    res = self.api_client.post(url)\n\n    if res[\"success\"]:\n        df = pd.DataFrame(res[\"details\"])\n        df = df.drop(\n            [\n                \"_id\",\n                \"region\",\n                \"gcp_project_name\",\n                \"gcp_project_id\",\n                \"gdrive_file_name\",\n                \"project_name\",\n            ],\n            axis=1,\n            errors=\"ignore\",\n        )\n        return df\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.list_data_connectors_buckets","title":"list_data_connectors_buckets","text":"<pre><code>list_data_connectors_buckets(data_connector_name)\n</code></pre> <p>Retrieve the list of buckets (for S3 or GCS connectors) or similar container names for the specified data connector.</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def list_data_connectors_buckets(self, data_connector_name) -&gt; str | List:\n    \"\"\"Retrieve the list of buckets (for S3 or GCS connectors) or similar container names for the specified data connector.\n\n    :param data_connector_name: str\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id:\n        return \"No Organization id found\"\n\n    url = build_url(LIST_BUCKETS, data_connector_name, None, self.organization_id)\n    res = self.api_client.get(url)\n\n    if res.get(\"message\", None):\n        print(res[\"message\"])\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.list_data_connectors_filepath","title":"list_data_connectors_filepath","text":"<pre><code>list_data_connectors_filepath(\n    data_connector_name, bucket_name=None, root_folder=None\n)\n</code></pre> <p>List file paths within the specified data connector. For S3/GCS connectors you may need to provide a bucket_name; for SFTP connectors you may need to provide a root_folder.</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required <code>bucket_name</code> <code>Optional[str]</code> <p>str | Required for S3 &amp; GCS</p> <code>None</code> <code>root_folder</code> <code>Optional[str]</code> <p>str | Root folder of SFTP</p> <code>None</code> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def list_data_connectors_filepath(\n    self,\n    data_connector_name,\n    bucket_name: Optional[str] = None,\n    root_folder: Optional[str] = None,\n) -&gt; str | Dict:\n    \"\"\"List file paths within the specified data connector. For S3/GCS connectors you may need to provide a bucket_name; for SFTP connectors you may need to provide a root_folder.\n\n    :param data_connector_name: str\n    :param bucket_name: str | Required for S3 &amp; GCS\n    :param root_folder: str | Root folder of SFTP\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id:\n        return \"No Organization id found\"\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Retrieve connector metadata for the given link service name.\n        Reads from internal state or a backend client as needed.\"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, None, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n\n        if ds_type == \"sftp\":\n            if not root_folder:\n                return \"Missing argument root_folder\"\n\n    if self.organization_id:\n        url = f\"{LIST_FILEPATHS}?organization_id={self.organization_id}&amp;link_service_name={data_connector_name}&amp;bucket_name={bucket_name}&amp;root_folder={root_folder}\"\n    res = self.api_client.get(url)\n\n    if res.get(\"message\", None):\n        print(res[\"message\"])\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.member_details","title":"member_details","text":"<pre><code>member_details()\n</code></pre> <p>Return a DataFrame containing details about members of the organization, including their names, emails, roles (owner/admin), and creation dates.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>member details dataframe</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def member_details(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame containing details about members of the organization, including their names, emails, roles (owner/admin), and creation dates.\n\n    :return: member details dataframe\n    \"\"\"\n    res = self.api_client.get(\n        f\"{ORGANIZATION_MEMBERS_URI}?organization_id={self.organization_id}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(\n            res.get(\"details\", \"Failed to get organization member details\")\n        )\n\n    member_details_df = pd.DataFrame(\n        res.get(\"details\").get(\"users\"),\n        columns=[\n            \"full_name\",\n            \"email\",\n            \"organization_owner\",\n            \"organization_admin\",\n            \"created_at\",\n        ],\n    )\n\n    return member_details_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.remove_user_from_organization","title":"remove_user_from_organization","text":"<pre><code>remove_user_from_organization(user_email)\n</code></pre> <p>Remove an existing user from the organization using their email address. Returns a confirmation message on success.</p> <p>Parameters:</p> Name Type Description Default <code>user_email</code> <code>str</code> <p>Email of user to be removed from organization.</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def remove_user_from_organization(self, user_email: str) -&gt; str:\n    \"\"\"Remove an existing user from the organization using their email address. Returns a confirmation message on success.\n\n    :param user_email: Email of user to be removed from organization.\n    :return: response\n    \"\"\"\n    payload = {\n        \"organization_user_email\": user_email,\n        \"organization_id\": self.organization_id,\n    }\n    res = self.api_client.post(REMOVE_USER_ORGANIZATION_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(\n            res.get(\"details\", \"Failed to remove user from organization\")\n        )\n\n    return res.get(\"details\", \"User removed successfully\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.test_data_connectors","title":"test_data_connectors","text":"<pre><code>test_data_connectors(data_connector_name)\n</code></pre> <p>Test the connection of an existing data connector to ensure credentials and connectivity are valid. Takes the connector name as input and returns the status of the connection test.</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def test_data_connectors(self, data_connector_name) -&gt; str:\n    \"\"\"Test the connection of an existing data connector to ensure credentials and connectivity are valid. Takes the connector name as input and returns the status of the connection test.\n\n    :param data_connector_name: str\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id:\n        return \"No Project Name or Organization id found\"\n    url = build_url(\n        TEST_DATA_CONNECTORS, data_connector_name, None, self.organization_id\n    )\n    res = self.api_client.post(url)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.update_user_access_for_organization","title":"update_user_access_for_organization","text":"<pre><code>update_user_access_for_organization(\n    user_email, access_type=[\"admin\", \"user\"]\n)\n</code></pre> <p>Change the role of a user within the organization. Accepts the user\u2019s email and the new access type (admin or user) and returns a confirmation message.</p> <p>Parameters:</p> Name Type Description Default <code>user_email</code> <code>str</code> <p>Email of user to be added to project.</p> required <code>access_type</code> <code>str</code> <p>access type to be given to user (admin | write | read)</p> <code>['admin', 'user']</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def update_user_access_for_organization(\n    self,\n    user_email: str,\n    access_type: str = [\"admin\", \"user\"],\n) -&gt; str:\n    \"\"\"Change the role of a user within the organization. Accepts the user\u2019s email and the new access type (admin or user) and returns a confirmation message.\n\n    :param user_email: Email of user to be added to project.\n    :param access_type: access type to be given to user (admin | write | read)\n    :return: response\n    \"\"\"\n    if access_type not in [\"admin\", \"user\"]:\n        raise ValueError(\"access_type must be either 'admin' or 'user'\")\n    payload = {\n        \"organization_user_email\": user_email,\n        \"organization_id\": self.organization_id,\n        \"organization_admin\": True if access_type == \"admin\" else False,\n    }\n    res = self.api_client.post(UPDATE_ORGANIZATION_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to update user access\"))\n\n    return res.get(\"details\", \"User access updated successfully\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.workspace","title":"workspace","text":"<pre><code>workspace(workspace_name)\n</code></pre> <p>Select a specific workspace by name within the organization and return a Workspace object for further operations.</p> <p>Parameters:</p> Name Type Description Default <code>workspace_name</code> <code>str</code> <p>Name of the workspace to be used</p> required <p>Returns:</p> Type Description <code>Workspace</code> <p>Workspace</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def workspace(self, workspace_name: str) -&gt; Workspace:\n    \"\"\"Select a specific workspace by name within the organization and return a Workspace object for further operations.\n\n    :param workspace_name: Name of the workspace to be used\n    :return: Workspace\n    \"\"\"\n\n    url = GET_WORKSPACES_URI\n    if self.organization_id:\n        url = url + f\"?organization_id={self.organization_id}\"\n    workspaces = self.api_client.get(url)\n    user_workspaces = [\n        Workspace(api_client=self.api_client, **workspace)\n        for workspace in workspaces[\"details\"]\n    ]\n\n    workspace = next(\n        filter(\n            lambda workspace: workspace.user_workspace_name == workspace_name,\n            user_workspaces,\n        ),\n        None,\n    )\n\n    if workspace is None:\n        raise Exception(\"Workspace Not Found\")\n\n    return workspace\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.organization.Organization.workspaces","title":"workspaces","text":"<pre><code>workspaces()\n</code></pre> <p>List all workspaces associated with the organization. Returns a DataFrame with workspace names, access types, creator, and instance details.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>workspace details dataframe</p> Source code in <code>lexsi_sdk/core/organization.py</code> <pre><code>def workspaces(self) -&gt; pd.DataFrame:\n    \"\"\"List all workspaces associated with the organization. Returns a DataFrame with workspace names, access types, creator, and instance details.\n\n    :return: workspace details dataframe\n    \"\"\"\n\n    url = GET_WORKSPACES_URI\n    if self.organization_id:\n        url = url + f\"?organization_id={self.organization_id}\"\n    workspaces = self.api_client.get(url)\n\n    workspace_df = pd.DataFrame(\n        workspaces[\"details\"],\n        columns=[\n            \"user_workspace_name\",\n            \"access_type\",\n            \"created_by\",\n            \"created_at\",\n            \"updated_at\",\n            \"instance_type\",\n            \"instance_status\",\n        ],\n    )\n\n    return workspace_df\n</code></pre>"},{"location":"sdk/#working-with-workspaces","title":"Working With Workspaces","text":"<p>The recommended pattern is:</p> <pre><code>workspace = organization.workspace(\"Your workspace name\")\n</code></pre> <p> You can use the following function with workspace class :</p>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace","title":"Workspace","text":"<pre><code>Workspace(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Logical container inside an organization that groups projects, users, and compute resources. Supports workspace-level user access and project lifecycle management.</p> <p>Attach API client for workspace operations. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Attach API client for workspace operations.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.add_user_to_workspace","title":"add_user_to_workspace","text":"<pre><code>add_user_to_workspace(email, role)\n</code></pre> <p>Add a user to the workspace with a specified role. Valid roles include admin, manager, or user.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>str</code> <p>user email</p> required <code>role</code> <code>str</code> <p>user role [\"admin\", \"manager\", \"user\"]</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def add_user_to_workspace(self, email: str, role: str) -&gt; str:\n    \"\"\"Add a user to the workspace with a specified role. Valid roles include admin, manager, or user.\n\n    :param email: user email\n    :param role: user role [\"admin\", \"manager\", \"user\"]\n    :return: response\n    \"\"\"\n    payload = {\n        \"workspace_name\": self.workspace_name,\n        \"modify_req\": {\n            \"add_user_workspace\": {\n                \"email\": email,\n                \"role\": role,\n            },\n        },\n    }\n    res = self.api_client.post(UPDATE_WORKSPACE_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.clear_notifications","title":"clear_notifications","text":"<pre><code>clear_notifications()\n</code></pre> <p>Clear all notifications for the workspace. Sends a POST request and returns a confirmation message.</p> <p>Returns:</p> Type Description <code>str</code> <p>str</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def clear_notifications(self) -&gt; str:\n    \"\"\"Clear all notifications for the workspace. Sends a POST request and returns a confirmation message.\n\n    :raises Exception: _description_\n    :return: str\n    \"\"\"\n    url = f\"{CLEAR_NOTIFICATIONS_URI}?workspace_name={self.workspace_name}\"\n\n    res = self.api_client.post(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while clearing workspace notifications.\")\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.create_project","title":"create_project","text":"<pre><code>create_project(\n    project_name,\n    modality,\n    project_type,\n    project_sub_type=None,\n    server_type=None,\n)\n</code></pre> <p>Create a new project within the workspace. Requires project_name, modality (e.g., tabular, text, image), project_type (e.g., classification), and optional project_sub_type and server_type. Returns the created Project object.</p> <p>:project_type: type for the project     Eg:- classification, regression</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>name for the project</p> required <code>modality</code> <code>str</code> <p>modality for the project Eg:- tabular, image, text</p> required <p>Returns:</p> Type Description <code>Project</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def create_project(\n    self,\n    project_name: str,\n    modality: str,\n    project_type: str,\n    project_sub_type: Optional[str] = None,\n    server_type: Optional[str] = None,\n) -&gt; Project:\n    \"\"\"Create a new project within the workspace. Requires project_name, modality (e.g., tabular, text, image), project_type (e.g., classification), and optional project_sub_type and server_type. Returns the created Project object.\n\n    :param project_name: name for the project\n    :param modality: modality for the project\n        Eg:- tabular, image, text\n    :project_type: type for the project\n        Eg:- classification, regression\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": project_name,\n        \"modality\": modality,\n        \"project_type\": project_type,\n        \"project_sub_type\": project_sub_type,\n        \"workspace_name\": self.workspace_name,\n    }\n\n    if self.organization_id:\n        payload[\"organization_id\"] = self.organization_id\n\n    if server_type:\n        custom_servers = self.api_client.get(AVAILABLE_CUSTOM_SERVERS_URI)\n        Validate.value_against_list(\n            \"server_type\",\n            server_type,\n            [server[\"name\"] for server in custom_servers],\n        )\n\n        payload[\"instance_type\"] = server_type\n        payload[\"server_config\"] = {}\n\n    res = self.api_client.post(CREATE_PROJECT_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    if modality == \"text\":\n        project = TextProject(api_client=self.api_client, **res[\"details\"])\n    elif modality == \"agent\":\n        project = AgentProject(api_client=self.api_client, **res[\"details\"])\n    else:\n        project = Project(api_client=self.api_client, **res[\"details\"])\n\n    return project\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.delete_workspace","title":"delete_workspace","text":"<pre><code>delete_workspace()\n</code></pre> <p>Delete the current workspace by sending a delete request. Returns a confirmation message upon success.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def delete_workspace(self) -&gt; str:\n    \"\"\"Delete the current workspace by sending a delete request. Returns a confirmation message upon success.\n    :return: response\n    \"\"\"\n    payload = {\n        \"workspace_name\": self.workspace_name,\n        \"modify_req\": {\"delete_workspace\": self.user_workspace_name},\n    }\n    res = self.api_client.post(UPDATE_WORKSPACE_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.get_notifications","title":"get_notifications","text":"<pre><code>get_notifications()\n</code></pre> <p>Get notifications specific to the workspace. Returns a DataFrame listing notifications including the project name, message, and timestamp.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def get_notifications(self) -&gt; pd.DataFrame:\n    \"\"\"Get notifications specific to the workspace. Returns a DataFrame listing notifications including the project name, message, and timestamp.\n\n    :return: DataFrame\n    \"\"\"\n    url = f\"{GET_NOTIFICATIONS_URI}?workspace_name={self.workspace_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while getting workspace notifications.\")\n\n    notifications = res[\"details\"]\n\n    if not notifications:\n        return \"No notifications found.\"\n\n    return pd.DataFrame(notifications).reindex(\n        columns=[\"project_name\", \"message\", \"time\"]\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.project","title":"project","text":"<pre><code>project(project_name)\n</code></pre> <p>Select a specific project by name from the workspace. Returns a Project object (or a subclass like TextProject or AgentProject) for the chosen project.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>Name of the project</p> required <p>Returns:</p> Type Description <code>Project</code> <p>Project</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def project(self, project_name: str) -&gt; Project:\n    \"\"\"Select a specific project by name from the workspace. Returns a Project object (or a subclass like TextProject or AgentProject) for the chosen project.\n\n    :param project_name: Name of the project\n    :return: Project\n    \"\"\"\n    workspace = self.api_client.get(\n        f\"{GET_WORKSPACES_DETAILS_URI}?workspace_name={self.workspace_name}\"\n    )\n\n    project = next(\n        filter(\n            lambda project: project.get(\"user_project_name\") == project_name,\n            workspace.get(\"data\", {}).get(\"projects\", []),\n        ),\n        None,\n    )\n\n    if project is None:\n        raise Exception(\"Project Not Found\")\n\n    if project.get(\"metadata\", {}).get(\"modality\") == \"text\":\n        return TextProject(api_client=self.api_client, **project)\n    elif project.get(\"metadata\", {}).get(\"modality\") == \"agent\":\n        return AgentProject(api_client=self.api_client, **project)\n\n    return Project(api_client=self.api_client, **project)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.projects","title":"projects","text":"<pre><code>projects()\n</code></pre> <p>Retrieve a DataFrame listing all projects in the workspace, with details like project name, access type, creator, and instance type.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Projects details dataframe</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def projects(self) -&gt; pd.DataFrame:\n    \"\"\"Retrieve a DataFrame listing all projects in the workspace, with details like project name, access type, creator, and instance type.\n\n    :return: Projects details dataframe\n    \"\"\"\n    workspace = self.api_client.get(\n        f\"{GET_WORKSPACES_DETAILS_URI}?workspace_name={self.workspace_name}\"\n    )\n    projects_df = pd.DataFrame(\n        workspace.get(\"data\", {}).get(\"projects\", []),\n        columns=[\n            \"user_project_name\",\n            \"access_type\",\n            \"created_by\",\n            \"created_at\",\n            \"updated_at\",\n            \"instance_type\",\n            \"instance_status\",\n        ],\n    )\n    return projects_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.remove_user_from_workspace","title":"remove_user_from_workspace","text":"<pre><code>remove_user_from_workspace(email)\n</code></pre> <p>Remove a user from the workspace using their email address. Returns a response message.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>str</code> <p>user email</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def remove_user_from_workspace(self, email: str) -&gt; str:\n    \"\"\"Remove a user from the workspace using their email address. Returns a response message.\n\n    :param email: user email\n    :return: response\n    \"\"\"\n    payload = {\n        \"workspace_name\": self.workspace_name,\n        \"modify_req\": {\n            \"remove_user_workspace\": email,\n        },\n    }\n    res = self.api_client.post(UPDATE_WORKSPACE_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.rename_workspace","title":"rename_workspace","text":"<pre><code>rename_workspace(new_workspace_name)\n</code></pre> <p>Rename the current workspace to a new name by sending an update request to the API. Updates internal properties and returns the response message.</p> <p>Parameters:</p> Name Type Description Default <code>new_workspace_name</code> <code>str</code> <p>name for the workspace to be renamed to</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def rename_workspace(self, new_workspace_name: str) -&gt; str:\n    \"\"\"Rename the current workspace to a new name by sending an update request to the API. Updates internal properties and returns the response message.\n\n    :param new_workspace_name: name for the workspace to be renamed to\n    :return: response\n    \"\"\"\n    payload = {\n        \"workspace_name\": self.workspace_name,\n        \"modify_req\": {\n            \"update_workspace\": {\n                \"workspace_name\": new_workspace_name,\n            }\n        },\n    }\n    res = self.api_client.post(UPDATE_WORKSPACE_URI, payload)\n    self.user_workspace_name = new_workspace_name\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.start_server","title":"start_server","text":"<pre><code>start_server()\n</code></pre> <p>Start a dedicated compute server for the workspace, enabling compute-intensive tasks.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def start_server(self) -&gt; str:\n    \"\"\"Start a dedicated compute server for the workspace, enabling compute-intensive tasks.\n\n    :return: response\n    \"\"\"\n\n    res = self.api_client.post(\n        f\"{START_CUSTOM_SERVER_URI}?workspace_name={self.workspace_name}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"message\"))\n\n    return res[\"message\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.stop_server","title":"stop_server","text":"<pre><code>stop_server()\n</code></pre> <p>Stop the dedicated compute server associated with the workspace.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def stop_server(self) -&gt; str:\n    \"\"\"Stop the dedicated compute server associated with the workspace.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.post(\n        f\"{STOP_CUSTOM_SERVER_URI}?workspace_name={self.workspace_name}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"message\"))\n\n    return res[\"message\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.update_server","title":"update_server","text":"<pre><code>update_server(server_type)\n</code></pre> <p>Change the compute instance type for the workspace by specifying a new server_type. Valid values depend on available custom servers.</p> <p>Parameters:</p> Name Type Description Default <code>server_type</code> <code>str</code> <p>dedicated instance to run workloads for all available instances check xai.available_custom_servers()</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def update_server(self, server_type: str) -&gt; str:\n    \"\"\"Change the compute instance type for the workspace by specifying a new server_type. Valid values depend on available custom servers.\n    :param server_type: dedicated instance to run workloads\n        for all available instances check xai.available_custom_servers()\n\n    :return: response\n    \"\"\"\n    custom_servers = self.api_client.get(AVAILABLE_CUSTOM_SERVERS_URI)\n    Validate.value_against_list(\n        \"server_type\",\n        server_type,\n        [server[\"name\"] for server in custom_servers],\n    )\n\n    payload = {\n        \"workspace_name\": self.workspace_name,\n        \"modify_req\": {\n            \"update_workspace\": {\n                \"workspace_name\": self.user_workspace_name,\n                \"instance_type\": server_type,\n            },\n            \"update_operational_hours\": {},\n        },\n    }\n\n    res = self.api_client.post(UPDATE_WORKSPACE_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Server Updated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.workspace.Workspace.update_user_access_for_workspace","title":"update_user_access_for_workspace","text":"<pre><code>update_user_access_for_workspace(email, role)\n</code></pre> <p>Update the role of a user in the workspace. Accepts the user\u2019s email and the new role (admin or user).</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>str</code> <p>user email</p> required <code>role</code> <code>UserRole</code> <p>new user role [\"admin\", \"user\"]</p> required <p>Returns:</p> Type Description <code>str</code> <p>description</p> Source code in <code>lexsi_sdk/core/workspace.py</code> <pre><code>def update_user_access_for_workspace(self, email: str, role: UserRole) -&gt; str:\n    \"\"\"Update the role of a user in the workspace. Accepts the user\u2019s email and the new role (admin or user).\n\n    :param email: user email\n    :param role: new user role [\"admin\", \"user\"]\n    :return: _description_\n    \"\"\"\n    payload = {\n        \"workspace_name\": self.workspace_name,\n        \"modify_req\": {\n            \"update_user_workspace\": {\n                \"email\": email,\n                \"role\": role,\n            }\n        },\n    }\n    res = self.api_client.post(UPDATE_WORKSPACE_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#working-with-projects","title":"Working With Projects","text":"<p>The recommended pattern is:</p> <pre><code>project = workspace.project(\"Your Project name\")\n</code></pre> <p> You can use the following function with organization class :</p>"},{"location":"sdk/#lexsi_sdk.core.project.Project","title":"Project","text":"<pre><code>Project(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Represents a project within a workspace. Provides APIs for model monitoring, explainability cases, alerts, dashboards, and data uploads.</p> <p>Initialize a <code>Project</code> instance and attach the API client. Populates model fields from <code>kwargs</code> and stores <code>api_client</code> for later requests.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>Project fields used to construct the instance (including <code>api_client</code>).</p> <code>{}</code> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize a `Project` instance and attach the API client.\n    Populates model fields from `kwargs` and stores `api_client` for later requests.\n\n    :param kwargs: Project fields used to construct the instance (including `api_client`).\n    \"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.activate_model","title":"activate_model","text":"<pre><code>activate_model(model_name)\n</code></pre> <p>Sets the model to active for the project</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>name of the model</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def activate_model(self, model_name: str) -&gt; str:\n    \"\"\"Sets the model to active for the project\n\n    :param model_name: name of the model\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n    }\n    res = self.api_client.post(UPDATE_ACTIVE_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.active_model","title":"active_model","text":"<pre><code>active_model()\n</code></pre> <p>Current Active Model for project</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>current active model dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def active_model(self) -&gt; pd.DataFrame:\n    \"\"\"Current Active Model for project\n\n    :return: current active model dataframe\n    \"\"\"\n    staged_models_df = self.models()\n    active_model = staged_models_df[staged_models_df[\"status\"] == \"active\"]\n    return active_model\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.add_user_to_project","title":"add_user_to_project","text":"<pre><code>add_user_to_project(email, role)\n</code></pre> <p>Add a user to the project with a specified role such as admin, manager, or user.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>str</code> <p>user email</p> required <code>role</code> <code>str</code> <p>user role [\"admin\", \"manager\", \"user\"]</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def add_user_to_project(self, email: str, role: str) -&gt; str:\n    \"\"\"Add a user to the project with a specified role such as admin, manager, or user.\n\n    :param email: user email\n    :param role: user role [\"admin\", \"manager\", \"user\"]\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"add_user_project\": {\n                \"email\": email,\n                \"role\": role,\n            },\n        },\n    }\n    res = self.api_client.post(UPDATE_PROJECT_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.alerts","title":"alerts","text":"<pre><code>alerts(page_num=1)\n</code></pre> <p>get monitoring alerts of project</p> <p>Parameters:</p> Name Type Description Default <code>page_num</code> <code>int</code> <p>page num, defaults to 1</p> <code>1</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>alerts DataFrame</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def alerts(self, page_num: int = 1) -&gt; pd.DataFrame:\n    \"\"\"get monitoring alerts of project\n\n    :param page_num: page num, defaults to 1\n    :return: alerts DataFrame\n    \"\"\"\n    payload = {\"page_num\": page_num, \"project_name\": self.project_name}\n\n    res = self.api_client.post(EXECUTED_TRIGGER_URI, payload)\n\n    if not res[\"success\"]:\n        return Exception(res.get(\"details\", \"Failed to get alerts\"))\n\n    monitoring_alerts = res.get(\"details\", [])\n\n    if not monitoring_alerts:\n        return \"No monitoring alerts found.\"\n\n    return pd.DataFrame(monitoring_alerts)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.all_tags","title":"all_tags","text":"<pre><code>all_tags()\n</code></pre> <p>Available All Tags for Project</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>list of tags</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def all_tags(self) -&gt; List[str]:\n    \"\"\"Available All Tags for Project\n\n    :return: list of tags\n    \"\"\"\n    available_tags = self.available_tags()\n\n    tags = available_tags.get(\"alltags\")\n\n    return tags\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.available_models","title":"available_models","text":"<pre><code>available_models()\n</code></pre> <p>Returns all models which can be trained on platform</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>list of all models</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def available_models(self) -&gt; List[str]:\n    \"\"\"Returns all models which can be trained on platform\n\n    :return: list of all models\n    \"\"\"\n    res = self.api_client.get(f\"{GET_MODELS_URI}?project_name={self.project_name}\")\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    available_models = list(\n        map(lambda data: data[\"model_name\"], res[\"details\"][\"available\"])\n    )\n\n    available_models.extend(\n        list(\n            map(\n                lambda data: data[\"model_name\"], res[\"details\"][\"foundation_models\"]\n            )\n        )\n    )\n\n    return available_models, res[\"details\"][\"foundation_models\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.available_tags","title":"available_tags","text":"<pre><code>available_tags()\n</code></pre> <p>Return a list of tags that are available for data categorization within the project.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def available_tags(self) -&gt; str:\n    \"\"\"Return a list of tags that are available for data categorization within the project.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.get(\n        f\"{AVAILABLE_TAGS_URI}?project_name={self.project_name}\"\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to get available tags.\")\n        raise Exception(error_details)\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.case_info","title":"case_info","text":"<pre><code>case_info(\n    unique_identifer,\n    case_id=None,\n    tag=None,\n    model_name=None,\n    instance_type=None,\n    xai=[],\n    risk_policies=False,\n)\n</code></pre> <p>Case Info</p> <p>Parameters:</p> Name Type Description Default <code>unique_identifer</code> <code>str</code> <p>unique identifer of case</p> required <code>case_id</code> <code>Optional[str]</code> <p>case id, defaults to None</p> <code>None</code> <code>tag</code> <code>Optional[str]</code> <p>case tag, defaults to None</p> <code>None</code> <code>model_name</code> <code>Optional[str]</code> <p>trained model name, defaults to None</p> <code>None</code> <code>instance_type</code> <code>Optional[str]</code> <p>instance to be used for case Eg:- nova-0.5, nova-1, nova-1.5</p> <code>None</code> <code>components</code> <p>various components to be generated with predictions Eg:- ['feature_importance', 'similar_cases', 'policies']</p> required <p>Returns:</p> Type Description <code>Case</code> <p>Case object with details</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def case_info(\n    self,\n    unique_identifer: str,\n    case_id: Optional[str] = None,\n    tag: Optional[str] = None,\n    model_name: Optional[str] = None,\n    instance_type: Optional[str] = None,\n    xai: Optional[list] = [],\n    risk_policies: Optional[bool] = False,\n) -&gt; Case:\n    \"\"\"Case Info\n\n    :param unique_identifer: unique identifer of case\n    :param case_id: case id, defaults to None\n    :param tag: case tag, defaults to None\n    :param model_name: trained model name, defaults to None\n    :param instance_type: instance to be used for case\n            Eg:- nova-0.5, nova-1, nova-1.5\n    :param components: various components to be generated with predictions\n            Eg:- ['feature_importance', 'similar_cases', 'policies']\n    :return: Case object with details\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"case_id\": case_id,\n        \"unique_identifier\": unique_identifer,\n        \"tag\": tag,\n        \"model_name\": model_name,\n        \"instance_type\": instance_type,\n        \"risk_policies\": risk_policies,\n        \"xai\": xai,\n    }\n    if self.metadata.get(\"modality\") == \"text\":\n        res = self.api_client.post(CASE_INFO_TEXT_URI, payload)\n        return CaseText(**res[\"details\"])\n    else:\n        res = self.api_client.post(CASE_INFO_URI, payload)\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    if self.metadata.get(\"modality\") == \"tabular\" and \"dtree\" in xai:\n        prediction_path_payload = {\n            \"project_name\": self.project_name,\n            \"unique_identifier\": unique_identifer,\n            \"case_id\": case_id,\n            \"model_name\": res[\"details\"][\"model_name\"],\n            \"data_id\": res[\"details\"][\"data_id\"],\n            \"instance_type\": instance_type,\n        }\n\n        dtree_res = self.api_client.post(CASE_DTREE_URI, prediction_path_payload)\n        if dtree_res[\"success\"]:\n            res[\"details\"][\"case_prediction_svg\"] = dtree_res[\"details\"][\n                \"case_prediction_svg\"\n            ]\n            res[\"details\"][\"case_prediction_path\"] = dtree_res[\"details\"][\n                \"case_prediction_path\"\n            ]\n            res[\"details\"][\"audit_trail\"][\"cost\"][\"xai_dtree\"] = dtree_res[\n                \"details\"\n            ][\"cost_dtree\"]\n            res[\"details\"][\"audit_trail\"][\"time\"][\"xai_dtree\"] = dtree_res[\n                \"details\"\n            ][\"time_dtree\"]\n            res[\"details\"][\"audit_trail\"][\"compute_type\"][\"xai_dtree\"] = dtree_res[\n                \"details\"\n            ][\"compute_type\"]\n    res[\"details\"][\"project_name\"] = self.project_name\n    res[\"details\"][\"api_client\"] = self.api_client\n    case = Case(**res[\"details\"])\n\n    return case\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.case_logs","title":"case_logs","text":"<pre><code>case_logs(page=1)\n</code></pre> <p>Get already viewed case logs</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>Optional[int]</code> <p>page number, defaults to 1</p> <code>1</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Case object with details</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def case_logs(self, page: Optional[int] = 1) -&gt; pd.DataFrame:\n    \"\"\"Get already viewed case logs\n\n    :param page: page number, defaults to 1\n    :return: Case object with details\n    \"\"\"\n\n    res = self.api_client.get(\n        f\"{CASE_LOGS_URI}?project_name={self.project_name}&amp;page={page}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to get case logs\"))\n\n    case_logs_df = pd.DataFrame(\n        res[\"details\"][\"logs\"],\n        columns=[\n            \"case_log_id\",\n            \"case_id\",\n            \"unique_identifier\",\n            \"tag\",\n            \"model_name\",\n            \"time_taken\",\n            \"created_at\",\n        ],\n    )\n    case_logs_df[\"case_log_id\"] = case_logs_df[\"case_id\"].astype(str)\n    case_logs_df.drop(columns=[\"case_id\"], inplace=True)\n\n    return case_logs_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.cases","title":"cases","text":"<pre><code>cases(\n    unique_identifier=None,\n    tag=None,\n    start_date=None,\n    end_date=None,\n    page=1,\n)\n</code></pre> <p>Cases for the Project</p> <p>Parameters:</p> Name Type Description Default <code>unique_identifier</code> <code>Optional[str]</code> <p>unique identifer of the case for filtering, defaults to None</p> <code>None</code> <code>tag</code> <code>Optional[str]</code> <p>data tag for filtering, defaults to None</p> <code>None</code> <code>start_date</code> <code>Optional[str]</code> <p>start date for filtering, defaults to None</p> <code>None</code> <code>end_date</code> <code>Optional[str]</code> <p>end data for filtering, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>casse details dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def cases(\n    self,\n    unique_identifier: Optional[str] = None,\n    tag: Optional[str] = None,\n    start_date: Optional[str] = None,\n    end_date: Optional[str] = None,\n    page: Optional[int] = 1,\n) -&gt; pd.DataFrame:\n    \"\"\"Cases for the Project\n\n    :param unique_identifier: unique identifer of the case for filtering, defaults to None\n    :param tag: data tag for filtering, defaults to None\n    :param start_date: start date for filtering, defaults to None\n    :param end_date: end data for filtering, defaults to None\n    :return: casse details dataframe\n    \"\"\"\n\n    def get_cases():\n        \"\"\"Fetch paginated cases without any search filters.\n        Used when no identifier/tag/date filters are provided.\"\"\"\n        payload = {\n            \"project_name\": self.project_name,\n            \"page_num\": page,\n        }\n        res = self.api_client.post(GET_CASES_URI, payload)\n        return res\n\n    def search_cases():\n        \"\"\"Search cases using identifier/tag/date filters.\n        Posts the filter payload to the search endpoint and returns the raw API response.\n        \"\"\"\n        payload = {\n            \"project_name\": self.project_name,\n            \"unique_identifier\": unique_identifier,\n            \"start_date\": start_date,\n            \"end_date\": end_date,\n            \"tag\": tag,\n            \"page_num\": page,\n        }\n        res = self.api_client.post(SEARCH_CASE_URI, payload)\n        return res\n\n    cases = (\n        search_cases()\n        if unique_identifier or tag or start_date or end_date\n        else get_cases()\n    )\n\n    if not cases[\"success\"]:\n        raise Exception(\"No cases found\")\n\n    cases_df = pd.DataFrame(cases.get(\"details\"))\n\n    return cases_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.clear_notifications","title":"clear_notifications","text":"<pre><code>clear_notifications()\n</code></pre> <p>clear user project notifications</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def clear_notifications(self) -&gt; str:\n    \"\"\"clear user project notifications\n\n    :raises Exception: _description_\n    :return: response\n    \"\"\"\n    url = f\"{CLEAR_NOTIFICATIONS_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.post(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while clearing project notifications.\")\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.config","title":"config","text":"<pre><code>config()\n</code></pre> <p>Retrieve the full configuration of the project, including feature selections, encodings, and tags. Returns a dictionary.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def config(self) -&gt; str:\n    \"\"\"Retrieve the full configuration of the project, including feature selections, encodings, and tags. Returns a dictionary.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_PROJECT_CONFIG}?project_name={self.project_name}\"\n    )\n    if res.get(\"details\") != \"Not Found\":\n        res[\"details\"].pop(\"updated_by\", None)\n        res[\"details\"][\"metadata\"].pop(\"path\", None)\n        res[\"details\"][\"metadata\"].pop(\"avaialble_tags\", None)\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.create_data_connectors","title":"create_data_connectors","text":"<pre><code>create_data_connectors(\n    data_connector_name,\n    data_connector_type,\n    gcs_config=None,\n    s3_config=None,\n    gdrive_config=None,\n    sftp_config=None,\n    hf_token=None,\n)\n</code></pre> <p>Create Data Connectors for project</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>str # name for data connector</p> required <code>data_connector_type</code> <code>str</code> <p>str # type of data connector (s3 | gcs | gdrive)</p> required <code>gcs_config</code> <code>Optional[GCSConfig]</code> <p>dict # credentials from service account json</p> <code>None</code> <code>s3_config</code> <code>Optional[S3Config]</code> <p>dict # credentials of s3 storage</p> <code>None</code> <code>gdrive_config</code> <code>Optional[GDriveConfig]</code> <p>dict # credentials from service account json</p> <code>None</code> <code>sftp_config</code> <code>Optional[SFTPConfig]</code> <p>dict # hostname, port, username and password for sftp connection</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def create_data_connectors(\n    self,\n    data_connector_name: str,\n    data_connector_type: str,\n    gcs_config: Optional[GCSConfig] = None,\n    s3_config: Optional[S3Config] = None,\n    gdrive_config: Optional[GDriveConfig] = None,\n    sftp_config: Optional[SFTPConfig] = None,\n    hf_token: Optional[str] = None,\n) -&gt; str:\n    \"\"\"Create Data Connectors for project\n\n    :param data_connector_name: str # name for data connector\n    :param data_connector_type: str # type of data connector (s3 | gcs | gdrive)\n    :param gcs_config: dict # credentials from service account json\n    :param s3_config: dict # credentials of s3 storage\n    :param gdrive_config: dict # credentials from service account json\n    :param sftp_config: dict # hostname, port, username and password for sftp connection\n    :return: response\n    \"\"\"\n    if not self.organization_id and not self.project_name:\n        return \"No Project Name or Organization id found\"\n    if data_connector_type.lower() == \"s3\":\n        if not s3_config:\n            return \"No configuration for S3 found\"\n\n        Validate.value_against_list(\n            \"s3 config\",\n            list(s3_config.keys()),\n            [\"region\", \"access_key\", \"secret_key\"],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"region\": s3_config.get(\"region\", \"ap-south-1\"),\n                \"access_key\": s3_config.get(\"access_key\"),\n                \"secret_key\": s3_config.get(\"secret_key\"),\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type.lower() == \"gcs\":\n        if not gcs_config:\n            return \"No configuration for GCS found\"\n\n        Validate.value_against_list(\n            \"gcs config\",\n            list(gcs_config.keys()),\n            [\n                \"project_id\",\n                \"gcp_project_name\",\n                \"type\",\n                \"private_key_id\",\n                \"private_key\",\n                \"client_email\",\n                \"client_id\",\n                \"auth_uri\",\n                \"token_uri\",\n            ],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"project_id\": gcs_config.get(\"project_id\"),\n                \"gcp_project_name\": gcs_config.get(\"gcp_project_name\"),\n                \"service_account_json\": {\n                    \"type\": gcs_config.get(\"type\"),\n                    \"project_id\": gcs_config.get(\"project_id\"),\n                    \"private_key_id\": gcs_config.get(\"private_key_id\"),\n                    \"private_key\": gcs_config.get(\"private_key\"),\n                    \"client_email\": gcs_config.get(\"client_email\"),\n                    \"client_id\": gcs_config.get(\"client_id\"),\n                    \"auth_uri\": gcs_config.get(\"auth_uri\"),\n                    \"token_uri\": gcs_config.get(\"token_uri\"),\n                },\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"gdrive\":\n        if not gdrive_config:\n            return \"No configuration for Google Drive found\"\n\n        Validate.value_against_list(\n            \"gdrive config\",\n            list(gdrive_config.keys()),\n            [\n                \"project_id\",\n                \"type\",\n                \"private_key_id\",\n                \"private_key\",\n                \"client_email\",\n                \"client_id\",\n                \"auth_uri\",\n                \"token_uri\",\n            ],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"service_account_json\": {\n                    \"type\": gdrive_config.get(\"type\"),\n                    \"project_id\": gdrive_config.get(\"project_id\"),\n                    \"private_key_id\": gdrive_config.get(\"private_key_id\"),\n                    \"private_key\": gdrive_config.get(\"private_key\"),\n                    \"client_email\": gdrive_config.get(\"client_email\"),\n                    \"client_id\": gdrive_config.get(\"client_id\"),\n                    \"auth_uri\": gdrive_config.get(\"auth_uri\"),\n                    \"token_uri\": gdrive_config.get(\"token_uri\"),\n                },\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"sftp\":\n        if not sftp_config:\n            return \"No configuration for Google Drive found\"\n\n        Validate.value_against_list(\n            \"sftp config\",\n            list(sftp_config.keys()),\n            [\"hostname\", \"port\", \"username\", \"password\"],\n        )\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"sftp_json\": {\n                    \"hostname\": sftp_config.get(\"hostname\"),\n                    \"port\": sftp_config.get(\"port\"),\n                    \"username\": sftp_config.get(\"username\"),\n                    \"password\": sftp_config.get(\"password\"),\n                },\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"dropbox\":\n        url_data = self.api_client.get(\n            f\"{DROPBOX_OAUTH}?project_name={self.project_name}\"\n        )\n        print(f\"Url: {url_data['details']['url']}\")\n        code = input(f\"{url_data['details']['message']}: \")\n\n        if not code:\n            return \"No authentication code provided.\"\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"dropbox_json\": {\"code\": code},\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    if data_connector_type == \"HuggingFace\":\n        if not hf_token:\n            return \"No hf_token provided\"\n\n        payload = {\n            \"link_service\": {\n                \"service_name\": data_connector_name,\n                \"hf_token\": hf_token,\n            },\n            \"link_service_type\": data_connector_type,\n        }\n\n    url = build_url(\n        CREATE_DATA_CONNECTORS,\n        data_connector_name,\n        self.project_name,\n        self.organization_id,\n    )\n    res = self.api_client.post(url, payload)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.create_monitoring_trigger","title":"create_monitoring_trigger","text":"<pre><code>create_monitoring_trigger(payload)\n</code></pre> <p>create monitoring trigger for project</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>dict</code> <p>Data Drift Trigger Payload { \"trigger_type\": \"\"  #[\"Data Drift\", \"Target Drift\", \"Model Performance\"] \"trigger_name\": \"\", \"mail_list\": [], \"frequency\": \"\",   #['daily','weekly','monthly','quarterly','yearly'] \"stat_test_name\": \"\", \"stat_test_threshold\": 0, \"datadrift_features_per\": 7, \"dataset_drift_percentage\": 50, \"features_to_use\": [], \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"base_line_tag\": \"\", \"current_tag\": \"\", \"instance_type\": \"\"  #Instance type to used for running trigger } OR Target Drift Trigger Payload { \"trigger_type\": \"\"  #[\"Data Drift\", \"Target Drift\", \"Model Performance\"] \"trigger_name\": \"\", \"mail_list\": [], \"frequency\": \"\",   #['daily','weekly','monthly','quarterly','yearly'] \"model_type\": \"\", \"stat_test_name\": \"\" \"stat_test_threshold\": 0, \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"base_line_tag\": \"\", \"current_tag\": \"\", \"baseline_true_label\": \"\", \"current_true_label\": \"\", \"instance_type\": \"\"  #Instance type to used for running trigger } OR Model Performance Trigger Payload { \"trigger_type\": \"\"  #[\"Data Drift\", \"Target Drift\", \"Model Performance\"] \"trigger_name\": \"\", \"mail_list\": [], \"frequency\": \"\",   #['daily','weekly','monthly','quarterly','yearly'] \"model_type\": \"\", \"model_performance_metric\": \"\", \"model_performance_threshold\": \"\", \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"base_line_tag\": \"\", \"baseline_true_label\": \"\", \"baseline_pred_label\": \"\", \"instance_type\": \"\"  #Instance type to used for running trigger }</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def create_monitoring_trigger(self, payload: dict) -&gt; str:\n    \"\"\"create monitoring trigger for project\n\n    :param payload: Data Drift Trigger Payload\n            {\n                \"trigger_type\": \"\"  #[\"Data Drift\", \"Target Drift\", \"Model Performance\"]\n                \"trigger_name\": \"\",\n                \"mail_list\": [],\n                \"frequency\": \"\",   #['daily','weekly','monthly','quarterly','yearly']\n                \"stat_test_name\": \"\",\n                \"stat_test_threshold\": 0,\n                \"datadrift_features_per\": 7,\n                \"dataset_drift_percentage\": 50,\n                \"features_to_use\": [],\n                \"date_feature\": \"\",\n                \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"base_line_tag\": \"\",\n                \"current_tag\": \"\",\n                \"instance_type\": \"\"  #Instance type to used for running trigger\n            } OR Target Drift Trigger Payload\n            {\n                \"trigger_type\": \"\"  #[\"Data Drift\", \"Target Drift\", \"Model Performance\"]\n                \"trigger_name\": \"\",\n                \"mail_list\": [],\n                \"frequency\": \"\",   #['daily','weekly','monthly','quarterly','yearly']\n                \"model_type\": \"\",\n                \"stat_test_name\": \"\"\n                \"stat_test_threshold\": 0,\n                \"date_feature\": \"\",\n                \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"base_line_tag\": \"\",\n                \"current_tag\": \"\",\n                \"baseline_true_label\": \"\",\n                \"current_true_label\": \"\",\n                \"instance_type\": \"\"  #Instance type to used for running trigger\n            } OR Model Performance Trigger Payload\n            {\n                \"trigger_type\": \"\"  #[\"Data Drift\", \"Target Drift\", \"Model Performance\"]\n                \"trigger_name\": \"\",\n                \"mail_list\": [],\n                \"frequency\": \"\",   #['daily','weekly','monthly','quarterly','yearly']\n                \"model_type\": \"\",\n                \"model_performance_metric\": \"\",\n                \"model_performance_threshold\": \"\",\n                \"date_feature\": \"\",\n                \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"base_line_tag\": \"\",\n                \"baseline_true_label\": \"\",\n                \"baseline_pred_label\": \"\",\n                \"instance_type\": \"\"  #Instance type to used for running trigger\n            }\n    :return: response\n    \"\"\"\n    payload[\"project_name\"] = self.project_name\n\n    required_payload_keys = [\n        \"trigger_type\",\n        \"priority\",\n        \"mail_list\",\n        \"frequency\",\n        \"trigger_name\",\n    ]\n\n    Validate.check_for_missing_keys(payload, required_payload_keys)\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"create_trigger\": payload,\n        },\n    }\n    res = self.api_client.post(CREATE_TRIGGER_URI, payload)\n\n    if not res[\"success\"]:\n        return Exception(res.get(\"details\", \"Failed to create trigger\"))\n\n    return \"Trigger created successfully.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.create_observation","title":"create_observation","text":"<pre><code>create_observation(\n    observation_name,\n    expression,\n    statement,\n    linked_features,\n    priority=5,\n)\n</code></pre> <p>Creates New Observation</p> <p>Parameters:</p> Name Type Description Default <code>observation_name</code> <code>str</code> <p>name of observation</p> required <code>expression</code> <code>str</code> <p>expression of observation Eg: BldgType !== Duplex and Neighborhood == OldTown Ensure that the left side of the conditional operator corresponds to a feature name, and the right side represents the comparison value for the feature. Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\" You can perform comparisons between two or more features using logical operators such as \"and\" or \"or.\" Additionally, you have the option to use parentheses () to group and prioritize certain conditions.</p> required <code>statement</code> <code>str</code> <p>statement of observation Eg: The building type is {BldgType} the content inside the curly brackets represents the feature name</p> required <code>linked_features</code> <code>List[str]</code> <p>linked features of observation</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def create_observation(\n    self,\n    observation_name: str,\n    expression: str,\n    statement: str,\n    linked_features: List[str],\n    priority: Optional[int] = 5,\n) -&gt; str:\n    \"\"\"Creates New Observation\n\n    :param observation_name: name of observation\n    :param expression: expression of observation\n        Eg: BldgType !== Duplex and Neighborhood == OldTown\n            Ensure that the left side of the conditional operator corresponds to a feature name,\n            and the right side represents the comparison value for the feature.\n            Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\"\n            You can perform comparisons between two or more features using\n            logical operators such as \"and\" or \"or.\"\n            Additionally, you have the option to use parentheses () to group and prioritize certain conditions.\n    :param statement: statement of observation\n        Eg: The building type is {BldgType}\n            the content inside the curly brackets represents the feature name\n    :param linked_features: linked features of observation\n    :return: response\n    \"\"\"\n    observation_params = self.api_client.get(\n        f\"{GET_OBSERVATION_PARAMS_URI}?project_name={self.project_name}\"\n    )\n\n    Validate.string(\"expression\", expression)\n\n    Validate.string(\"statement\", statement)\n\n    Validate.value_against_list(\n        \"linked_feature\",\n        linked_features,\n        list(observation_params[\"details\"][\"features\"].keys()),\n    )\n    configuration, expression = build_expression(expression)\n\n    validate_configuration(\n        configuration,\n        observation_params[\"details\"],\n        self.project_name,\n        self.api_client,\n        True,\n    )\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"observation_name\": observation_name,\n        \"status\": \"active\",\n        \"configuration\": configuration,\n        \"metadata\": {\"expression\": expression},\n        \"statement\": [statement],\n        \"linked_features\": linked_features,\n        \"priority\": priority,\n    }\n\n    res = self.api_client.post(CREATE_OBSERVATION_URI, payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Observation Created\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.create_policy","title":"create_policy","text":"<pre><code>create_policy(\n    policy_name,\n    expression,\n    statement,\n    decision,\n    input=None,\n    models=[],\n    priority=5,\n)\n</code></pre> <p>Creates New Policy</p> <p>Parameters:</p> Name Type Description Default <code>policy_name</code> <code>str</code> <p>name of policy</p> required <code>expression</code> <code>str</code> <p>expression of policy Eg: BldgType !== Duplex and Neighborhood == OldTown Ensure that the left side of the conditional operator corresponds to a feature name, and the right side represents the comparison value for the feature. Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\" You can perform comparisons between two or more features using logical operators such as \"and\" or \"or.\" Additionally, you have the option to use parentheses () to group and prioritize certain conditions.</p> required <code>statement</code> <code>str</code> <p>statement of policy Eg: The building type is {BldgType} the content inside the curly brackets represents the feature name</p> required <code>decision</code> <code>str</code> <p>decision of policy</p> required <code>input</code> <code>Optional[str]</code> <p>custom input for the decision if input selected for decision of policy</p> <code>None</code> <code>models</code> <code>Optional[list]</code> <p>List of trained model names - The policy will only execute for the selected model. In case of empty list will execute for all models</p> <code>[]</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def create_policy(\n    self,\n    policy_name: str,\n    expression: str,\n    statement: str,\n    decision: str,\n    input: Optional[str] = None,\n    models: Optional[list] = [],\n    priority: Optional[int] = 5,\n) -&gt; str:\n    \"\"\"Creates New Policy\n\n    :param policy_name: name of policy\n    :param expression: expression of policy\n        Eg: BldgType !== Duplex and Neighborhood == OldTown\n            Ensure that the left side of the conditional operator corresponds to a feature name,\n            and the right side represents the comparison value for the feature.\n            Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\"\n            You can perform comparisons between two or more features using\n            logical operators such as \"and\" or \"or.\"\n            Additionally, you have the option to use parentheses () to group and prioritize certain conditions.\n    :param statement: statement of policy\n        Eg: The building type is {BldgType}\n            the content inside the curly brackets represents the feature name\n    :param decision: decision of policy\n    :param input: custom input for the decision if input selected for decision of policy\n    :param models: List of trained model names - The policy will only execute for the selected model. In case of empty list will execute for all models\n    :return: response\n    \"\"\"\n    configuration, expression = build_expression(expression)\n\n    policy_params = self.api_client.get(\n        f\"{GET_POLICY_PARAMS_URI}?project_name={self.project_name}\"\n    )\n\n    validate_configuration(\n        configuration, policy_params[\"details\"], self.project_name, self.api_client\n    )\n\n    Validate.value_against_list(\n        \"decision\", decision, list(policy_params[\"details\"][\"decision\"].values())[0]\n    )\n\n    if decision == \"input\":\n        Validate.string(\"Decision input\", input)\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"policy_name\": policy_name,\n        \"status\": \"active\",\n        \"configuration\": configuration,\n        \"metadata\": {\"expression\": expression},\n        \"statement\": [statement],\n        \"decision\": input if decision == \"input\" else decision,\n        \"models\": models,\n        \"priority\": priority,\n    }\n\n    res = self.api_client.post(CREATE_POLICY_URI, payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Policy Created\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.create_synthetic_prompt","title":"create_synthetic_prompt","text":"<pre><code>create_synthetic_prompt(name, expression)\n</code></pre> <p>create synthetic prompt for the project</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>prompt name</p> required <code>expression</code> <code>str</code> <p>expression of policy Eg: BldgType !== Duplex and Neighborhood == OldTown Ensure that the left side of the conditional operator corresponds to a feature name, and the right side represents the comparison value for the feature. Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\" You can perform comparisons between two or more features using logical operators such as \"and\" or \"or.\" Additionally, you have the option to use parentheses () to group and prioritize certain conditions.</p> required <p>Returns:</p> Type Description <code>str</code> <p>response message</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def create_synthetic_prompt(self, name: str, expression: str) -&gt; str:\n    \"\"\"create synthetic prompt for the project\n\n    :param name: prompt name\n    :param expression: expression of policy\n        Eg: BldgType !== Duplex and Neighborhood == OldTown\n            Ensure that the left side of the conditional operator corresponds to a feature name,\n            and the right side represents the comparison value for the feature.\n            Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\"\n            You can perform comparisons between two or more features using\n            logical operators such as \"and\" or \"or.\"\n            Additionally, you have the option to use parentheses () to group and prioritize certain conditions.\n    :raises Exception: _description_\n    :return: response message\n    \"\"\"\n    name = name.strip()\n\n    if not name:\n        raise Exception(\"name is required\")\n\n    configuration, expression = build_expression(expression)\n\n    prompt_params = self.get_observation_params()\n    validate_configuration(\n        configuration, prompt_params, self.project_name, self.api_client\n    )\n\n    payload = {\n        \"prompt_name\": name,\n        \"project_name\": self.project_name,\n        \"configuration\": configuration,\n        \"metadata\": {\"expression\": expression},\n    }\n\n    res = self.api_client.post(CREATE_SYNTHETIC_PROMPT_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return \"Synthetic prompt created successfully.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.data_drift_diagnosis","title":"data_drift_diagnosis","text":"<pre><code>data_drift_diagnosis(\n    baseline_tags=None, current_tags=None, instance_type=\"\"\n)\n</code></pre> <p>Data Drift Diagnosis for the project</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <p>tag for data [\"Training\", \"Testing\", \"Validation\", \"Custom\"]</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>data drift diagnosis dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def data_drift_diagnosis(\n    self,\n    baseline_tags: Optional[List[str]] = None,\n    current_tags: Optional[List[str]] = None,\n    instance_type: Optional[str] = \"\",\n) -&gt; pd.DataFrame:\n    \"\"\"Data Drift Diagnosis for the project\n\n    :param tag: tag for data [\"Training\", \"Testing\", \"Validation\", \"Custom\"]\n    :return: data drift diagnosis dataframe\n    \"\"\"\n\n    if baseline_tags and current_tags:\n        if instance_type not in [\n            \"small\",\n            \"xsmall\",\n            \"2xsmall\",\n            \"3xsmall\",\n            \"medium\",\n            \"xmedium\",\n            \"2xmedium\",\n            \"3xmedium\",\n            \"large\",\n            \"xlarge\",\n            \"2xlarge\",\n            \"3xlarge\",\n        ]:\n            return \"instance_type is not valid. Valid types are small, xsmall, 2xsmall, 3xsmall, medium, xmedium, 2xmedium, 3xmedium, large, xlarge, 2xlarge, 3xlarge\"\n\n        payload = {\n            \"project_name\": self.project_name,\n            \"baseline_tags\": baseline_tags,\n            \"current_tags\": current_tags,\n            \"instance_type\": instance_type,\n        }\n        res = self.api_client.post(RUN_DATA_DRIFT_DIAGNOSIS_URI, payload)\n\n        if not res[\"success\"]:\n            if res.get(\"details\").get(\"reason\"):\n                raise Exception(res.get(\"details\").get(\"reason\"))\n            else:\n                raise Exception(res.get(\"message\"))\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n\n    res = self.api_client.post(\n        f\"{GET_DATA_DRIFT_DIAGNOSIS_URI}?project_name={self.project_name}\"\n    )\n    if not res.get(\"status\"):\n        raise Exception(res.get(\"details\", \"Data drift diagnosis not found\"))\n    data_drift_diagnosis = pd.DataFrame(res[\"details\"][\"detailed_report\"]).drop(\n        [\"current_small_hist\", \"ref_small_hist\"], axis=1\n    )\n\n    return data_drift_diagnosis\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.data_observations","title":"data_observations","text":"<pre><code>data_observations(tag)\n</code></pre> <p>Data Observations for the project</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>tag for data [\"Training\", \"Testing\", \"Validation\", \"Custom\"]</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>data observations dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def data_observations(self, tag: str) -&gt; pd.DataFrame:\n    \"\"\"Data Observations for the project\n\n    :param tag: tag for data [\"Training\", \"Testing\", \"Validation\", \"Custom\"]\n    :return: data observations dataframe\n    \"\"\"\n    payload = {\"project_name\": self.project_name, \"refresh\": \"false\"}\n    res = self.api_client.post(f\"{GET_DATA_SUMMARY_URI}\", payload)\n    valid_tags = res[\"data\"][\"data\"].keys()\n\n    if not valid_tags:\n        raise Exception(\"Data summary not available, please upload data first.\")\n\n    if tag not in valid_tags:\n        raise Exception(f\"Not a vaild tag. Pick a valid tag from {valid_tags}\")\n\n    data = {\n        \"Total Data Volume\": res[\"data\"][\"overview\"][\"Total Data Volumn\"],\n        \"Unique Features\": res[\"data\"][\"overview\"][\"Unique Features\"],\n    }\n\n    print(data)\n    summary = pd.DataFrame(res[\"data\"][\"data\"][tag])\n    return summary\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.data_warnings","title":"data_warnings","text":"<pre><code>data_warnings(tag)\n</code></pre> <p>Data warnings for the project</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>tag for data [\"Training\", \"Testing\", \"Validation\", \"Custom\"]</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>data warnings dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def data_warnings(self, tag: str) -&gt; pd.DataFrame:\n    \"\"\"Data warnings for the project\n\n    :param tag: tag for data [\"Training\", \"Testing\", \"Validation\", \"Custom\"]\n    :return: data warnings dataframe\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_DATA_DIAGNOSIS_URI}?project_name={self.project_name}\"\n    )\n    valid_tags = res[\"details\"].keys()\n\n    if not valid_tags:\n        raise Exception(\"Data warnings not available, please upload data first.\")\n\n    Validate.value_against_list(\"tag\", tag, valid_tags)\n\n    data_warnings = pd.DataFrame(res[\"details\"][tag][\"alerts\"])\n    data_warnings[[\"Tag\", \"Description\"]] = data_warnings[0].str.extract(\n        r\"\\['(.*?)'] (.+?) #\"\n    )\n    data_warnings[\"Description\"] = data_warnings[\"Description\"].str.replace(\n        r\"[^\\w\\s]\", \"\", regex=True\n    )\n    data_warnings = data_warnings[[\"Description\", \"Tag\"]]\n\n    data = {\"Warnings\": len(data_warnings)}\n    print(data)\n\n    return data_warnings\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_cases","title":"delete_cases","text":"<pre><code>delete_cases(\n    unique_identifier=None,\n    start_date=None,\n    end_date=None,\n    tag=None,\n)\n</code></pre> <p>Delete Cases</p> <p>Parameters:</p> Name Type Description Default <code>unique_identifier</code> <code>Optional[str]</code> <p>unique identifier of case, defaults to None</p> <code>None</code> <code>start_date</code> <code>Optional[str]</code> <p>start date of case, defaults to None</p> <code>None</code> <code>end_date</code> <code>Optional[str]</code> <p>end date of case, defaults to None</p> <code>None</code> <code>tag</code> <code>Optional[str]</code> <p>tag of case, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_cases(\n    self,\n    unique_identifier: Optional[str] = None,\n    start_date: Optional[str] = None,\n    end_date: Optional[str] = None,\n    tag: Optional[str] = None,\n) -&gt; str:\n    \"\"\"Delete Cases\n\n    :param unique_identifier: unique identifier of case, defaults to None\n    :param start_date: start date of case, defaults to None\n    :param end_date: end date of case, defaults to None\n    :param tag: tag of case, defaults to None\n    :return: response\n    \"\"\"\n    if tag:\n        all_tags = self.all_tags()\n        Validate.value_against_list(\"tag\", tag, all_tags)\n\n    paylod = {\n        \"project_name\": self.project_name,\n        \"unique_identifier\": [unique_identifier],\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"tag\": tag,\n    }\n\n    res = self.api_client.post(DELETE_CASE_URI, paylod)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_data_connectors","title":"delete_data_connectors","text":"<pre><code>delete_data_connectors(data_connector_name)\n</code></pre> <p>Delete the data connectors</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_data_connectors(self, data_connector_name) -&gt; str:\n    \"\"\"Delete the data connectors\n\n    :param data_connector_name: str\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id and not self.project_name:\n        return \"No Project Name or Organization id found\"\n\n    url = build_url(\n        DELETE_DATA_CONNECTORS,\n        data_connector_name,\n        self.project_name,\n        self.organization_id,\n    )\n    res = self.api_client.post(url)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_file","title":"delete_file","text":"<pre><code>delete_file(file_name)\n</code></pre> <p>deletes file for the project</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>uploaded file name</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_file(self, file_name: str) -&gt; str:\n    \"\"\"deletes file for the project\n\n    :param file_name: uploaded file name\n    :return: response\n    \"\"\"\n    files = self.api_client.get(\n        f\"{ALL_DATA_FILE_URI}?project_name={self.project_name}\"\n    )\n\n    if not files.get(\"details\"):\n        raise Exception(\"Please upload files first\")\n\n    file_data = next(\n        filter(\n            lambda file: file[\"filepath\"] == file_name\n            or file[\"filepath\"].split(\"/\")[-1] == file_name,\n            files[\"details\"],\n        ),\n        None,\n    )\n\n    if not file_data:\n        raise Exception(\"File Not Found, please pass valid file name\")\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"workspace_name\": self.workspace_name,\n        \"path\": file_data[\"filepath\"],\n    }\n\n    res = self.api_client.post(DELETE_DATA_FILE_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_monitoring_trigger","title":"delete_monitoring_trigger","text":"<pre><code>delete_monitoring_trigger(name)\n</code></pre> <p>delete monitoring trigger for project</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>trigger name</p> required <p>Returns:</p> Type Description <code>str</code> <p>str</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_monitoring_trigger(self, name: str) -&gt; str:\n    \"\"\"delete monitoring trigger for project\n\n    :param name: trigger name\n    :return: str\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"delete_trigger\": name,\n        },\n    }\n\n    res = self.api_client.post(DELETE_TRIGGER_URI, payload)\n\n    if not res[\"success\"]:\n        return Exception(res.get(\"details\", \"Failed to delete trigger\"))\n\n    return \"Monitoring trigger deleted successfully.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_observation","title":"delete_observation","text":"<pre><code>delete_observation(observation_id, observation_name)\n</code></pre> <p>Deletes Observation</p> <p>Parameters:</p> Name Type Description Default <code>observation_id</code> <code>str</code> <p>id of observation</p> required <code>observation_name</code> <code>str</code> <p>name of observation</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_observation(\n    self,\n    observation_id: str,\n    observation_name: str,\n) -&gt; str:\n    \"\"\"Deletes Observation\n\n    :param observation_id: id of observation\n    :param observation_name: name of observation\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"observation_id\": observation_id,\n        \"observation_name\": observation_name,\n        \"delete\": True,\n        \"update_keys\": {},\n    }\n\n    res = self.api_client.post(UPDATE_OBSERVATION_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Observation Deleted\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_policy","title":"delete_policy","text":"<pre><code>delete_policy(policy_id, policy_name)\n</code></pre> <p>Deletes Policy</p> <p>Parameters:</p> Name Type Description Default <code>policy_id</code> <code>str</code> <p>id of policy</p> required <code>policy_name</code> <code>str</code> <p>name of policy</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_policy(\n    self,\n    policy_id: str,\n    policy_name: str,\n) -&gt; str:\n    \"\"\"Deletes Policy\n\n    :param policy_id: id of policy\n    :param policy_name: name of policy\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"policy_id\": policy_id,\n        \"policy_name\": policy_name,\n        \"delete\": True,\n        \"update_keys\": {},\n    }\n\n    res = self.api_client.post(UPDATE_POLICY_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Policy Deleted\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.delete_project","title":"delete_project","text":"<pre><code>delete_project()\n</code></pre> <p>Delete the project. Sends a delete request to the API and returns the response message.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def delete_project(self) -&gt; str:\n    \"\"\"Delete the project. Sends a delete request to the API and returns the response message.\n\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"delete_project\": self.user_project_name,\n        },\n    }\n    res = self.api_client.post(UPDATE_PROJECT_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.duplicate_monitoring_triggers","title":"duplicate_monitoring_triggers","text":"<pre><code>duplicate_monitoring_triggers(\n    trigger_name, new_trigger_name\n)\n</code></pre> <p>Duplicate an existing monitoring trigger under a new name. Calls the backend duplication endpoint and returns the server response message.</p> <p>Parameters:</p> Name Type Description Default <code>trigger_name</code> <p>Existing trigger name to duplicate.</p> required <code>new_trigger_name</code> <p>New name for the duplicated trigger.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Backend response message.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def duplicate_monitoring_triggers(self, trigger_name, new_trigger_name) -&gt; str:\n    \"\"\"Duplicate an existing monitoring trigger under a new name.\n    Calls the backend duplication endpoint and returns the server response message.\n\n    :param trigger_name: Existing trigger name to duplicate.\n    :param new_trigger_name: New name for the duplicated trigger.\n    :return: Backend response message.\"\"\"\n    if trigger_name == new_trigger_name:\n        return \"Duplicate trigger name can't be same\"\n    url = f\"{DUPLICATE_MONITORS_URI}?project_name={self.project_name}&amp;trigger_name={trigger_name}&amp;new_trigger_name={new_trigger_name}\"\n    res = self.api_client.post(url)\n\n    if not res[\"success\"]:\n        return res.get(\"details\", \"Failed to clone triggers\")\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.duplicate_observation","title":"duplicate_observation","text":"<pre><code>duplicate_observation(\n    observation_name, new_observation_name\n)\n</code></pre> <p>Duplicate an existing observation under a new name. Calls the backend duplication endpoint and returns the server response message.</p> <p>Parameters:</p> Name Type Description Default <code>observation_name</code> <p>Existing observation name to duplicate.</p> required <code>new_observation_name</code> <p>New name for the duplicated observation.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Backend response message.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def duplicate_observation(self, observation_name, new_observation_name) -&gt; str:\n    \"\"\"Duplicate an existing observation under a new name.\n    Calls the backend duplication endpoint and returns the server response message.\n\n    :param observation_name: Existing observation name to duplicate.\n    :param new_observation_name: New name for the duplicated observation.\n    :return: Backend response message.\"\"\"\n    if observation_name == new_observation_name:\n        return \"Duplicate observation name can't be same\"\n    url = f\"{DUPLICATE_OBSERVATION_URI}?project_name={self.project_name}&amp;observation_name={observation_name}&amp;new_observation_name={new_observation_name}\"\n    res = self.api_client.post(url)\n\n    if not res[\"success\"]:\n        return res.get(\"details\", \"Failed to clone triggers\")\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.duplicate_policy","title":"duplicate_policy","text":"<pre><code>duplicate_policy(policy_name, new_policy_name)\n</code></pre> <p>Duplicate an existing policy under a new name. Calls the backend duplication endpoint and returns the server response message.</p> <p>Parameters:</p> Name Type Description Default <code>policy_name</code> <p>Existing policy name to duplicate.</p> required <code>new_policy_name</code> <p>New name for the duplicated policy.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Backend response message.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def duplicate_policy(self, policy_name, new_policy_name) -&gt; str:\n    \"\"\"Duplicate an existing policy under a new name.\n    Calls the backend duplication endpoint and returns the server response message.\n\n    :param policy_name: Existing policy name to duplicate.\n    :param new_policy_name: New name for the duplicated policy.\n    :return: Backend response message.\"\"\"\n    if policy_name == new_policy_name:\n        return \"Duplicate observation name can't be same\"\n    url = f\"{DUPLICATE_POLICY_URI}?project_name={self.project_name}&amp;policy_name={policy_name}&amp;new_policy_name={new_policy_name}\"\n    res = self.api_client.post(url)\n\n    if not res[\"success\"]:\n        return res.get(\"details\", \"Failed to clone Policy\")\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.evals_dl_image","title":"evals_dl_image","text":"<pre><code>evals_dl_image(model_name, unique_identifier)\n</code></pre> <p>get evals for ml tabular model</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>model name</p> required <p>Returns:</p> Type Description <p>evals</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def evals_dl_image(self, model_name: str, unique_identifier: str):\n    \"\"\"get evals for ml tabular model\n    :param model_name: model name\n    :return: evals\n    \"\"\"\n    url = f\"{IMAGE_DL}?model_name={model_name}&amp;project_name={self.project_name}&amp;unique_identifier={unique_identifier}\"\n    res = self.api_client.post(url)\n    if not res[\"success\"]:\n        raise Exception(res[\"message\"])\n\n    return res[\"attributions\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.evals_dl_tabular","title":"evals_dl_tabular","text":"<pre><code>evals_dl_tabular(model_name)\n</code></pre> <p>get evals for ml tabular model</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>model name</p> required <p>Returns:</p> Type Description <p>evals</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def evals_dl_tabular(self, model_name: str):\n    \"\"\"get evals for ml tabular model\n\n    :param model_name: model name\n    :return: evals\n    \"\"\"\n    url = f\"{TABULAR_DL}?model_name={model_name}&amp;project_name={self.project_name}\"\n    res = self.api_client.post(url)\n    if not res[\"success\"]:\n        raise Exception(res[\"message\"])\n\n    return pd.DataFrame(res[\"comparison_metrics\"])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.evals_tabular","title":"evals_tabular","text":"<pre><code>evals_tabular(model_name, tag='')\n</code></pre> <p>get evals for ml tabular model</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>model name</p> required <p>Returns:</p> Type Description <p>evals</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def evals_tabular(self, model_name: str, tag: Optional[str] = \"\"):\n    \"\"\"get evals for ml tabular model\n\n    :param model_name: model name\n    :return: evals\n    \"\"\"\n    url = f\"{TABULAR_ML}?model_name={model_name}&amp;project_name={self.project_name}&amp;tag={tag}\"\n    res = self.api_client.post(url)\n    if not res[\"success\"]:\n        raise Exception(res[\"message\"])\n\n    return pd.DataFrame(res[\"comparison_metrics\"])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.events","title":"events","text":"<pre><code>events(event_id=None, event_names=None, status=None)\n</code></pre> <p>get info about events</p> <p>Parameters:</p> Name Type Description Default <code>event_id</code> <code>Optional[str]</code> <p>Optional event id to filter by.</p> <code>None</code> <code>event_names</code> <code>Optional[List[str]]</code> <p>Optional list of event names to filter by.</p> <code>None</code> <code>status</code> <code>Optional[List[str]]</code> <p>Optional list of statuses to filter by.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>event details</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def events(\n    self,\n    event_id: Optional[str] = None,\n    event_names: Optional[List[str]] = None,\n    status: Optional[List[str]] = None,\n) -&gt; List[Dict]:\n    \"\"\"get info about events\n\n    :param event_id: Optional event id to filter by.\n    :param event_names: Optional list of event names to filter by.\n    :param status: Optional list of statuses to filter by.\n    :return: event details\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"event_id\": event_id,\n        \"event_names\": event_names,\n        \"status\": status,\n    }\n\n    res = self.api_client.post(FETCH_EVENTS, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.file_summary","title":"file_summary","text":"<pre><code>file_summary(file_name)\n</code></pre> <p>Return a summary (e.g., preview) of a file uploaded to the project. Accepts the file name and returns a DataFrame summarizing its contents.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>user uploaded file name</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>file summary dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def file_summary(self, file_name: str) -&gt; pd.DataFrame:\n    \"\"\"Return a summary (e.g., preview) of a file uploaded to the project. Accepts the file name and returns a DataFrame summarizing its contents.\n\n    :param file_name: user uploaded file name\n    :return: file summary dataframe\n    \"\"\"\n    files = self.api_client.get(\n        f\"{ALL_DATA_FILE_URI}?project_name={self.project_name}\"\n    )\n\n    if not files.get(\"details\"):\n        raise Exception(\"Please upload files first\")\n\n    file_data = next(\n        filter(\n            lambda file: file[\"filepath\"].split(\"/\")[-1] == file_name,\n            files[\"details\"],\n        ),\n        None,\n    )\n\n    if not file_data:\n        raise Exception(\"File Not Found, please pass valid file name\")\n\n    file_metadata = {\n        \"file_size_mb\": file_data[\"metadata\"][\"file_size_mb\"],\n        \"columns\": file_data[\"metadata\"][\"columns\"],\n        \"rows\": file_data[\"metadata\"][\"rows\"],\n    }\n\n    print(file_metadata)\n\n    file_summary_df = pd.DataFrame(file_data[\"metadata\"][\"details\"])\n\n    return file_summary_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.files","title":"files","text":"<pre><code>files()\n</code></pre> <p>List files uploaded to the project. Returns a DataFrame with file names and statuses. Only active files are included.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>user uploaded files dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def files(self) -&gt; pd.DataFrame:\n    \"\"\"List files uploaded to the project. Returns a DataFrame with file names and statuses. Only active files are included.\n\n    :return: user uploaded files dataframe\n    \"\"\"\n    files = self.api_client.get(\n        f\"{ALL_DATA_FILE_URI}?project_name={self.project_name}\"\n    )\n\n    if not files.get(\"details\"):\n        raise Exception(\"Please upload files first\")\n\n    files_df = (\n        pd.DataFrame(files[\"details\"])\n        .drop([\"metadata\", \"project_name\", \"version\"], axis=1)\n        .rename(columns={\"filepath\": \"file_name\"})\n    )\n\n    files_df = files_df.loc[files_df[\"status\"] == \"active\"]\n    files_df[\"file_name\"] = files_df[\"file_name\"].apply(\n        lambda file_path: file_path.split(\"/\")[-1]\n    )\n\n    return files_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_alert_details","title":"get_alert_details","text":"<pre><code>get_alert_details(id)\n</code></pre> <p>get alert details by id</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>alert or trigger id</p> required <p>Returns:</p> Type Description <code>Alert</code> <p>Alert</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_alert_details(self, id: str) -&gt; Alert:\n    \"\"\"get alert details by id\n\n    :param id: alert or trigger id\n    :return: Alert\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"id\": id,\n    }\n    res = self.api_client.post(GET_EXECUTED_TRIGGER_INFO, payload)\n\n    if not res[\"success\"]:\n        return Exception(res.get(\"details\", \"Failed to get trigger details\"))\n\n    trigger_info = res[\"details\"][0]\n\n    if not trigger_info[\"successful\"]:\n        return Alert(info={}, detailed_report=[], not_used_features=[])\n\n    trigger_info = trigger_info[\"details\"]\n\n    detailed_report = trigger_info.get(\"detailed_report\")\n    not_used_features = trigger_info.get(\"Not_Used_Features\")\n\n    trigger_info.pop(\"detailed_report\", None)\n    trigger_info.pop(\"Not_Used_Features\", None)\n\n    return Alert(\n        info=trigger_info,\n        detailed_report=detailed_report,\n        not_used_features=not_used_features,\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_all_dashboards","title":"get_all_dashboards","text":"<pre><code>get_all_dashboards(type, page=1)\n</code></pre> <p>get all dashboard</p> <p>:page: page number defaults to 1</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>type of the dashboard</p> required Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_all_dashboards(self, type: str, page: Optional[int] = 1):\n    \"\"\"get all dashboard\n\n    :param type: type of the dashboard\n    :page: page number defaults to 1\n    \"\"\"\n\n    Validate.value_against_list(\n        \"type\",\n        type,\n        DASHBOARD_TYPES,\n    )\n\n    res = self.api_client.get(\n        f\"{DASHBOARD_LOGS_URI}?project_name={self.project_name}&amp;type={type}&amp;page={page}\",\n    )\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to get all dashboard\"))\n    res = res.get(\"details\").get(\"dashboards\")\n\n    logs = pd.DataFrame(res)\n    logs.drop(\n        columns=[\n            \"max_features\",\n            \"limit_features\",\n            \"baseline_date\",\n            \"current_date\",\n            \"task_id\",\n            \"date_feature\",\n            \"stat_test_threshold\",\n            \"project_name\",\n            \"file_id\",\n            \"updated_at\",\n            \"features_to_use\",\n        ],\n        inplace=True,\n        errors=\"ignore\",\n    )\n    return logs\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_bias_monitoring_dashboard","title":"get_bias_monitoring_dashboard","text":"<pre><code>get_bias_monitoring_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>get bias monitoring dashboard</p> <p>Parameters:</p> Name Type Description Default <code>run_in_background</code> <code>bool</code> <p>runs in background without waiting for dashboard generation to complete</p> <code>False</code> <code>instance_type</code> <code>Optional[str]</code> <p>instance type for running on custom server</p> <code>None</code> <code>payload</code> <code>BiasMonitoringPayload</code> <p>bias monitoring payload { \"base_line_tag\": \"\", \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"model_type\": \"\", \"baseline_true_label\": \"\", \"baseline_pred_label\": \"\", \"features_to_use\": [] } defaults to None</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_bias_monitoring_dashboard(\n    self,\n    payload: BiasMonitoringPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"get bias monitoring dashboard\n\n    :param run_in_background: runs in background without waiting for dashboard generation to complete\n    :param instance_type: instance type for running on custom server\n    :param payload: bias monitoring payload\n            {\n                \"base_line_tag\": \"\",\n                \"date_feature\": \"\",\n                \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"model_type\": \"\",\n                \"baseline_true_label\": \"\",\n                \"baseline_pred_label\": \"\",\n                \"features_to_use\": []\n            }\n            defaults to None\n    :return: Dashboard\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"biasmonitoring\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate required fields\n    Validate.check_for_missing_keys(\n        payload, BIAS_MONITORING_DASHBOARD_REQUIRED_FIELDS\n    )\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n\n    Validate.validate_date_feature_val(payload, tags_info[\"alldatetimefeatures\"])\n\n    Validate.value_against_list(\"model_type\", payload[\"model_type\"], MODEL_TYPES)\n\n    Validate.value_against_list(\n        \"baseline_true_label\",\n        [payload[\"baseline_true_label\"]],\n        tags_info[\"alluniquefeatures\"],\n    )\n\n    Validate.value_against_list(\n        \"baseline_pred_label\",\n        [payload[\"baseline_pred_label\"]],\n        tags_info[\"alluniquefeatures\"],\n    )\n\n    if payload.get(\"features_to_use\"):\n        Validate.value_against_list(\n            \"features_to_use\",\n            payload.get(\"features_to_use\", []),\n            tags_info[\"alluniquefeatures\"],\n        )\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=biasmonitoring\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to get dashboard url\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"biasmonitoring\")\n\n    return \"Bias monitoring dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_dashboard","title":"get_dashboard","text":"<pre><code>get_dashboard(type, dashboard_id)\n</code></pre> <p>get dashboard</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>type of the dashboard</p> required <code>dashboard_id</code> <code>str</code> <p>id of dashboard</p> required <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_dashboard(self, type: str, dashboard_id: str) -&gt; Dashboard:\n    \"\"\"get dashboard\n\n    :param type: type of the dashboard\n    :param dashboard_id: id of dashboard\n    :return: Dashboard\n    \"\"\"\n    Validate.value_against_list(\n        \"type\",\n        type,\n        DASHBOARD_TYPES,\n    )\n\n    res = self.api_client.get(\n        f\"{GET_DASHBOARD_URI}?type={type}&amp;project_name={self.project_name}&amp;dashboard_id={dashboard_id}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to get dashboard\"))\n\n    auth_token = self.api_client.get_auth_token()\n    query_params = f\"?project_name={self.project_name}&amp;type={type}&amp;dashboard_id={dashboard_id}&amp;access_token={auth_token}\"\n\n    return Dashboard(\n        config=res.get(\"config\"),\n        raw_data=res.get(\"details\"),\n        query_params=query_params,\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_dashboard_log_data","title":"get_dashboard_log_data","text":"<pre><code>get_dashboard_log_data(type)\n</code></pre> <p>get all dashboard</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>type of the dashboard</p> required Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_dashboard_log_data(self, type: str):\n    \"\"\"get all dashboard\n\n    :param type: type of the dashboard\n    \"\"\"\n    Validate.value_against_list(\n        \"type\",\n        type,\n        DASHBOARD_TYPES,\n    )\n    self.api_client.refresh_bearer_token()\n    auth_token = self.api_client.get_auth_token()\n    query_params = (\n        f\"project_name={self.project_name}&amp;dashboard_type={type}&amp;token={auth_token}\"\n    )\n\n    uri = f\"{DOWNLOAD_DASHBOARD_LOGS_URI}?{query_params}\"\n    res = self.api_client.base_request(\"GET\", uri)\n\n    if res.status_code != 200:\n        raise Exception(\n            res.get(\n                \"details\", f\"Error Downloading Dasboard Logs, {res.status_code}\"\n            )\n        )\n\n    try:\n        df = pd.read_csv(io.StringIO(res.text))\n    except:\n        df = pd.DataFrame()\n\n    return df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_dashboard_metadata","title":"get_dashboard_metadata","text":"<pre><code>get_dashboard_metadata(type, dashboard_id)\n</code></pre> <p>get dashboard</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>type of the dashboard</p> required <code>dashboard_id</code> <code>str</code> <p>id of dashboard</p> required <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_dashboard_metadata(self, type: str, dashboard_id: str) -&gt; Dashboard:\n    \"\"\"get dashboard\n\n    :param type: type of the dashboard\n    :param dashboard_id: id of dashboard\n    :return: Dashboard\n    \"\"\"\n    Validate.value_against_list(\n        \"type\",\n        type,\n        DASHBOARD_TYPES,\n    )\n\n    res = self.api_client.get(\n        f\"{GET_DASHBOARD_URI}?type={type}&amp;project_name={self.project_name}&amp;dashboard_id={dashboard_id}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to get dashboard\"))\n\n    auth_token = self.api_client.get_auth_token()\n    query_params = f\"?project_name={self.project_name}&amp;type={type}&amp;dashboard_id={dashboard_id}&amp;access_token={auth_token}\"\n\n    return res\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_data_drift_dashboard","title":"get_data_drift_dashboard","text":"<pre><code>get_data_drift_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>get data drift dashboard</p> <p>Parameters:</p> Name Type Description Default <code>run_in_background</code> <code>bool</code> <p>runs in background without waiting for dashboard generation to complete</p> <code>False</code> <code>instance_type</code> <code>Optional[str]</code> <p>instance type for running on custom server</p> <code>None</code> <code>payload</code> <code>DataDriftPayload</code> <p>data drift payload { \"base_line_tag\": \"\", \"current_tag\": \"\", \"stat_test_name\": \"\", \"stat_test_threshold\": \"\", \"features_to_use\": [] \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, } defaults to None key values for payload: stat_test_name= chisquare (Chi-Square test): default for categorical features if the number of labels for feature &gt; 2 only for categorical features returns p_value default threshold 0.05 drift detected when p_value &lt; threshold jensenshannon (Jensen-Shannon distance): for numerical and categorical features returns distance default threshold 0.05 drift detected when distance &gt;= threshold ks (Kolmogorov\u2013Smirnov (K-S) test): default for numerical features only for numerical features returns p_value default threshold 0.05 drift detected when p_value &lt; threshold kl_div (Kullback-Leibler divergence): for numerical and categorical features returns divergence default threshold 0.05 drift detected when divergence &gt;= threshold, psi (Population Stability Index): for numerical and categorical features returns psi_value default_threshold=0.1 drift detected when psi_value &gt;= threshold wasserstein (Wasserstein distance (normed)): only for numerical features returns distance default threshold 0.05 drift detected when distance &gt;= threshold z (Ztest): default for categorical features if the number of labels for feature &lt;= 2 only for categorical features returns p_value default threshold 0.05 drift detected when p_value &lt; threshold</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_data_drift_dashboard(\n    self,\n    payload: DataDriftPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"get data drift dashboard\n\n    :param run_in_background: runs in background without waiting for dashboard generation to complete\n    :param instance_type: instance type for running on custom server\n    :param payload: data drift payload\n        {\n            \"base_line_tag\": \"\",\n            \"current_tag\": \"\",\n            \"stat_test_name\": \"\",\n            \"stat_test_threshold\": \"\",\n            \"features_to_use\": []\n            \"date_feature\": \"\",\n            \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n            \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n        }\n        defaults to None\n        key values for payload:\n            stat_test_name=\n                chisquare (Chi-Square test):\n                    default for categorical features if the number of labels for feature &gt; 2\n                    only for categorical features\n                    returns p_value\n                    default threshold 0.05\n                    drift detected when p_value &lt; threshold\n                jensenshannon (Jensen-Shannon distance):\n                    for numerical and categorical features\n                    returns distance\n                    default threshold 0.05\n                    drift detected when distance &gt;= threshold\n                ks (Kolmogorov\u2013Smirnov (K-S) test):\n                    default for numerical features\n                    only for numerical features\n                    returns p_value\n                    default threshold 0.05\n                    drift detected when p_value &lt; threshold\n                kl_div (Kullback-Leibler divergence):\n                    for numerical and categorical features\n                    returns divergence\n                    default threshold 0.05\n                    drift detected when divergence &gt;= threshold,\n                psi (Population Stability Index):\n                    for numerical and categorical features\n                    returns psi_value\n                    default_threshold=0.1\n                    drift detected when psi_value &gt;= threshold\n                wasserstein (Wasserstein distance (normed)):\n                    only for numerical features\n                    returns distance\n                    default threshold 0.05\n                    drift detected when distance &gt;= threshold\n                z (Ztest):\n                    default for categorical features if the number of labels for feature &lt;= 2\n                    only for categorical features\n                    returns p_value\n                    default threshold 0.05\n                    drift detected when p_value &lt; threshold\n    :return: Dashboard\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"data_drift\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate required fields\n    Validate.check_for_missing_keys(payload, DATA_DRIFT_DASHBOARD_REQUIRED_FIELDS)\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    Validate.validate_date_feature_val(payload, tags_info[\"alldatetimefeatures\"])\n\n    if payload.get(\"features_to_use\"):\n        Validate.value_against_list(\n            \"features_to_use\",\n            payload.get(\"features_to_use\", []),\n            tags_info[\"alluniquefeatures\"],\n        )\n\n    Validate.value_against_list(\n        \"stat_test_name\", payload[\"stat_test_name\"], DATA_DRIFT_STAT_TESTS\n    )\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(f\"{GENERATE_DASHBOARD_URI}?type=data_drift\", payload)\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to generate dashboard\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"data_drift\")\n\n    return \"Data Drift dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_default_dashboard","title":"get_default_dashboard","text":"<pre><code>get_default_dashboard(type)\n</code></pre> <p>get default dashboard</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>type of the dashboard</p> required <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_default_dashboard(self, type: str) -&gt; Dashboard:\n    \"\"\"get default dashboard\n\n    :param type: type of the dashboard\n    :return: Dashboard\n    \"\"\"\n\n    res = self.api_client.get(\n        f\"{GET_DASHBOARD_URI}?type={type}&amp;project_name={self.project_name}\"\n    )\n\n    if res[\"success\"]:\n        auth_token = self.api_client.get_auth_token()\n        query_params = f\"?project_name={self.project_name}&amp;type={type}&amp;access_token={auth_token}\"\n        return Dashboard(\n            config=res.get(\"config\"),\n            raw_data=res.get(\"details\"),\n            query_params=query_params,\n        )\n\n    raise Exception(\n        \"Cannot retrieve default dashboard, please create new dashboard\"\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_feature_importance","title":"get_feature_importance","text":"<pre><code>get_feature_importance(\n    model_name, feature_name, xai_method\n)\n</code></pre> <p>Fetch feature importance for a model/feature and XAI method. Calls the feature-importance endpoint and returns the backend-provided values.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Trained model name.</p> required <code>feature_name</code> <code>str</code> <p>Feature/column name.</p> required <code>xai_method</code> <code>str</code> <p>Explainability method (e.g. <code>shap</code>, <code>lime</code>).</p> required <p>Returns:</p> Type Description <p>Feature importance values (backend response payload).</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_feature_importance(\n    self, model_name: str, feature_name: str, xai_method: str\n):\n    \"\"\"Fetch feature importance for a model/feature and XAI method.\n    Calls the feature-importance endpoint and returns the backend-provided values.\n\n    :param model_name: Trained model name.\n    :param feature_name: Feature/column name.\n    :param xai_method: Explainability method (e.g. `shap`, `lime`).\n    :return: Feature importance values (backend response payload).\"\"\"\n    url = f\"{GET_FEATURE_IMPORTANCE_URI}?project_name={self.project_name}&amp;model_name={model_name}&amp;feature_name={feature_name}&amp;xai_method={xai_method}\"\n    res = self.api_client.get(url)\n    if not res[\"success\"]:\n        raise Exception(res[\"message\"])\n    return res.get(\"feature_importance\", \"\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_image_dataset_drift_dashboard","title":"get_image_dataset_drift_dashboard","text":"<pre><code>get_image_dataset_drift_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>Generate an image dataset drift dashboard for this project. Returns the default dashboard when <code>payload</code> is empty; otherwise triggers generation and waits unless <code>run_in_background</code>.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>ImageDashboardPayload</code> <p>Dashboard configuration payload (tags/labels and parameters).</p> <code>{}</code> <code>instance_type</code> <code>Optional[str]</code> <p>Optional compute instance for generation jobs.</p> <code>None</code> <code>run_in_background</code> <code>bool</code> <p>If True, trigger generation and return immediately.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>A <code>Dashboard</code> object (or a status string when background mode is enabled).</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_image_dataset_drift_dashboard(\n    self,\n    payload: ImageDashboardPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"Generate an image dataset drift dashboard for this project.\n    Returns the default dashboard when `payload` is empty; otherwise triggers generation and waits unless `run_in_background`.\n\n    :param payload: Dashboard configuration payload (tags/labels and parameters).\n    :param instance_type: Optional compute instance for generation jobs.\n    :param run_in_background: If True, trigger generation and return immediately.\n    :return: A `Dashboard` object (or a status string when background mode is enabled).\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"image_dataset_drift\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=image_dataset_drift\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to generate dashboard\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"image_dataset_drift\")\n\n    return \"Image Dataset Drift dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_image_property_drift_dashboard","title":"get_image_property_drift_dashboard","text":"<pre><code>get_image_property_drift_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>Generate an image property drift dashboard for this project. Returns the default dashboard when <code>payload</code> is empty; otherwise triggers generation and waits unless <code>run_in_background</code>.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>ImageDashboardPayload</code> <p>Dashboard configuration payload (tags/labels and parameters).</p> <code>{}</code> <code>instance_type</code> <code>Optional[str]</code> <p>Optional compute instance for generation jobs.</p> <code>None</code> <code>run_in_background</code> <code>bool</code> <p>If True, trigger generation and return immediately.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>A <code>Dashboard</code> object (or a status string when background mode is enabled).</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_image_property_drift_dashboard(\n    self,\n    payload: ImageDashboardPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"Generate an image property drift dashboard for this project.\n    Returns the default dashboard when `payload` is empty; otherwise triggers generation and waits unless `run_in_background`.\n\n    :param payload: Dashboard configuration payload (tags/labels and parameters).\n    :param instance_type: Optional compute instance for generation jobs.\n    :param run_in_background: If True, trigger generation and return immediately.\n    :return: A `Dashboard` object (or a status string when background mode is enabled).\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"image_property_drift\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=image_property_drift\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to generate dashboard\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"image_property_drift\")\n\n    return \"Image Property Drift dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_label_drift_dashboard","title":"get_label_drift_dashboard","text":"<pre><code>get_label_drift_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>Generate a label drift dashboard for image workloads. Returns the default dashboard when <code>payload</code> is empty; otherwise triggers generation and waits unless <code>run_in_background</code>.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>ImageDashboardPayload</code> <p>Dashboard configuration payload (tags/labels and parameters).</p> <code>{}</code> <code>instance_type</code> <code>Optional[str]</code> <p>Optional compute instance for generation jobs.</p> <code>None</code> <code>run_in_background</code> <code>bool</code> <p>If True, trigger generation and return immediately.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>A <code>Dashboard</code> object (or a status string when background mode is enabled).</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_label_drift_dashboard(\n    self,\n    payload: ImageDashboardPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"Generate a label drift dashboard for image workloads.\n    Returns the default dashboard when `payload` is empty; otherwise triggers generation and waits unless `run_in_background`.\n\n    :param payload: Dashboard configuration payload (tags/labels and parameters).\n    :param instance_type: Optional compute instance for generation jobs.\n    :param run_in_background: If True, trigger generation and return immediately.\n    :return: A `Dashboard` object (or a status string when background mode is enabled).\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"label_drift\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=label_drift\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to generate dashboard\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"label_drift\")\n\n    return \"Label Drift dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_labels","title":"get_labels","text":"<pre><code>get_labels(feature_name)\n</code></pre> <p>Get the unique values of a particular feature (column) in the dataset. Useful for enumerated categorical values.</p> <p>Parameters:</p> Name Type Description Default <code>feature_name</code> <code>str</code> <p>feature name</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>unique values of feature</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_labels(self, feature_name: str) -&gt; List[str]:\n    \"\"\"Get the unique values of a particular feature (column) in the dataset. Useful for enumerated categorical values.\n\n    :param feature_name: feature name\n    :return: unique values of feature\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_LABELS_URI}?project_name={self.project_name}&amp;feature_name={feature_name}\"\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\n            \"details\", f\"Failed to get labels for {feature_name}\"\n        )\n        raise Exception(error_details)\n\n    return res[\"labels\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_model_performance","title":"get_model_performance","text":"<pre><code>get_model_performance(model_name=None)\n</code></pre> <p>Get model performance dashboard data for this project. Builds dashboard query params and fetches raw data, optionally scoped to a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Optional model name to filter dashboard data.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>A <code>Dashboard</code> wrapper with query params and raw data.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_model_performance(self, model_name: str = None) -&gt; Dashboard:\n    \"\"\"Get model performance dashboard data for this project.\n    Builds dashboard query params and fetches raw data, optionally scoped to a model.\n\n    :param model_name: Optional model name to filter dashboard data.\n    :return: A `Dashboard` wrapper with query params and raw data.\"\"\"\n    auth_token = self.api_client.get_auth_token()\n    dashboard_query_params = f\"?type=model_performance&amp;project_name={self.project_name}&amp;access_token={auth_token}\"\n    raw_data_query_params = f\"?project_name={self.project_name}\"\n\n    if model_name:\n        dashboard_query_params = f\"{dashboard_query_params}&amp;model_name={model_name}\"\n        raw_data_query_params = f\"{raw_data_query_params}&amp;model_name={model_name}\"\n\n    raw_data = self.api_client.get(\n        f\"{MODEL_PERFORMANCE_DASHBOARD_URI}{raw_data_query_params}\"\n    )\n\n    return Dashboard(\n        config={},\n        query_params=dashboard_query_params,\n        raw_data=raw_data.get(\"details\"),\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_model_performance_dashboard","title":"get_model_performance_dashboard","text":"<pre><code>get_model_performance_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>get model performance dashboard</p> <p>Parameters:</p> Name Type Description Default <code>run_in_background</code> <code>bool</code> <p>runs in background without waiting for dashboard generation to complete</p> <code>False</code> <code>instance_type</code> <code>Optional[str]</code> <p>instance type for running on custom server</p> <code>None</code> <code>payload</code> <code>ModelPerformancePayload</code> <p>model performance payload { \"base_line_tag\": \"\", \"current_tag\": \"\", \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"model_type\": \"\", \"baseline_true_label\": \"\", \"baseline_pred_label\": \"\", \"current_true_label\": \"\", \"current_pred_label\": \"\" } defaults to None</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_model_performance_dashboard(\n    self,\n    payload: ModelPerformancePayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"get model performance dashboard\n\n    :param run_in_background: runs in background without waiting for dashboard generation to complete\n    :param instance_type: instance type for running on custom server\n    :param payload: model performance payload\n            {\n                \"base_line_tag\": \"\",\n                \"current_tag\": \"\",\n                \"date_feature\": \"\",\n                \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"model_type\": \"\",\n                \"baseline_true_label\": \"\",\n                \"baseline_pred_label\": \"\",\n                \"current_true_label\": \"\",\n                \"current_pred_label\": \"\"\n            }\n            defaults to None\n    :return: Dashboard\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"performance\")\n\n    payload[\"project_name\"] = self.project_name\n\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    if self.metadata.get(\"modality\") == \"image\":\n        Validate.check_for_missing_keys(payload, [\"base_line_tag\", \"current_tag\"])\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    if self.metadata.get(\"modality\") == \"tabular\":\n        Validate.check_for_missing_keys(\n            payload, MODEL_PERF_DASHBOARD_REQUIRED_FIELDS\n        )\n        Validate.validate_date_feature_val(\n            payload, tags_info[\"alldatetimefeatures\"]\n        )\n\n        Validate.value_against_list(\n            \"model_type\", payload[\"model_type\"], MODEL_TYPES\n        )\n\n        Validate.value_against_list(\n            \"baseline_true_label\",\n            [payload[\"baseline_true_label\"]],\n            tags_info[\"alluniquefeatures\"],\n        )\n\n        Validate.value_against_list(\n            \"baseline_pred_label\",\n            [payload[\"baseline_pred_label\"]],\n            tags_info[\"alluniquefeatures\"],\n        )\n\n        Validate.value_against_list(\n            \"current_true_label\",\n            [payload[\"current_true_label\"]],\n            tags_info[\"alluniquefeatures\"],\n        )\n\n        Validate.value_against_list(\n            \"current_pred_label\",\n            [payload[\"current_pred_label\"]],\n            tags_info[\"alluniquefeatures\"],\n        )\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=performance\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to get dashboard url\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"performance\")\n\n    return \"Model performance dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_monitors_alerts","title":"get_monitors_alerts","text":"<pre><code>get_monitors_alerts(monitor_id, time)\n</code></pre> <p>Fetch alerts for a specific monitor over a lookback window. Returns the alerts as a pandas DataFrame from the monitor alerts endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>monitor_id</code> <code>str</code> <p>Monitor identifier.</p> required <code>time</code> <code>int</code> <p>Lookback window (as expected by the backend).</p> required <p>Returns:</p> Type Description <p>Alerts as a pandas DataFrame.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_monitors_alerts(self, monitor_id: str, time: int):\n    \"\"\"Fetch alerts for a specific monitor over a lookback window.\n    Returns the alerts as a pandas DataFrame from the monitor alerts endpoint.\n\n    :param monitor_id: Monitor identifier.\n    :param time: Lookback window (as expected by the backend).\n    :return: Alerts as a pandas DataFrame.\"\"\"\n    url = f\"{GET_MONITORS_ALERTS}?project_name={self.project_name}&amp;monitor_id={monitor_id}&amp;time={time}\"\n    res = self.api_client.get(url)\n    data = pd.DataFrame(res.get(\"details\"))\n    return data\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_notifications","title":"get_notifications","text":"<pre><code>get_notifications()\n</code></pre> <p>get user project notifications</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_notifications(self) -&gt; pd.DataFrame:\n    \"\"\"get user project notifications\n\n    :return: DataFrame\n    \"\"\"\n    url = f\"{GET_NOTIFICATIONS_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while getting project notifications.\")\n\n    notifications = [\n        notification\n        for notification in res[\"details\"]\n        if notification.get(\"project_name\", None)\n    ]\n\n    if not notifications:\n        return \"No notifications found.\"\n\n    return pd.DataFrame(notifications).reindex(columns=[\"message\", \"time\"])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_observation_params","title":"get_observation_params","text":"<pre><code>get_observation_params()\n</code></pre> <p>Fetch observation/policy expression parameters for this project. Used for validating expressions, linked features, and supported operators.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_observation_params(self) -&gt; dict:\n    \"\"\"Fetch observation/policy expression parameters for this project.\n    Used for validating expressions, linked features, and supported operators.\"\"\"\n    url = f\"{GET_OBSERVATION_PARAMS_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.get(url)\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_property_label_correlation_dashboard","title":"get_property_label_correlation_dashboard","text":"<pre><code>get_property_label_correlation_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>Generate a property-label correlation dashboard for image workloads. Returns the default dashboard when <code>payload</code> is empty; otherwise triggers generation and waits unless <code>run_in_background</code>.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>ImageDashboardPayload</code> <p>Dashboard configuration payload (tags/labels and parameters).</p> <code>{}</code> <code>instance_type</code> <code>Optional[str]</code> <p>Optional compute instance for generation jobs.</p> <code>None</code> <code>run_in_background</code> <code>bool</code> <p>If True, trigger generation and return immediately.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>A <code>Dashboard</code> object (or a status string when background mode is enabled).</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_property_label_correlation_dashboard(\n    self,\n    payload: ImageDashboardPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"Generate a property-label correlation dashboard for image workloads.\n    Returns the default dashboard when `payload` is empty; otherwise triggers generation and waits unless `run_in_background`.\n\n    :param payload: Dashboard configuration payload (tags/labels and parameters).\n    :param instance_type: Optional compute instance for generation jobs.\n    :param run_in_background: If True, trigger generation and return immediately.\n    :return: A `Dashboard` object (or a status string when background mode is enabled).\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"property_label_correlation\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=property_label_correlation\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to generate dashboard\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"property_label_correlation\")\n\n    return \"Property label correlation dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_score","title":"get_score","text":"<pre><code>get_score(dashboard_id, feature_name)\n</code></pre> <p>Fetch dashboard score/drift details for a single feature. Returns the matching entry from <code>DatasetColumnDriftResults</code> for <code>feature_name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dashboard_id</code> <p>Dashboard identifier to query.</p> required <code>feature_name</code> <p>Feature/column name to match within drift results.</p> required <p>Returns:</p> Type Description <p>The matched feature entry dict, or None if not found.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_score(self, dashboard_id, feature_name):\n    \"\"\"Fetch dashboard score/drift details for a single feature.\n    Returns the matching entry from `DatasetColumnDriftResults` for `feature_name`.\n\n    :param dashboard_id: Dashboard identifier to query.\n    :param feature_name: Feature/column name to match within drift results.\n    :return: The matched feature entry dict, or None if not found.\"\"\"\n    resp = self.api_client.get(\n        f\"{GET_DASHBOARD_SCORE_URI}?project_name={self.project_name}&amp;dashboard_id={dashboard_id}&amp;feature_name={feature_name}\"\n    )\n    resp = resp.get(\"details\").get(\"dashboards\")\n    logs = pd.DataFrame(resp)\n    logs.drop(\n        columns=[\n            \"max_features\",\n            \"limit_features\",\n            \"baseline_date\",\n            \"current_date\",\n            \"task_id\",\n            \"date_feature\",\n            \"stat_test_threshold\",\n            \"project_name\",\n            \"file_id\",\n            \"updated_at\",\n            \"features_to_use\",\n        ],\n        inplace=True,\n        errors=\"ignore\",\n    )\n    column_drift_results = logs.metadata[0].get(\"DatasetColumnDriftResults\")\n    matched_column_info = next(\n        (\n            item\n            for item in column_drift_results\n            if item.get(\"column_name\") == feature_name\n        ),\n        None,\n    )\n    return matched_column_info\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_synthetic_model_params","title":"get_synthetic_model_params","text":"<pre><code>get_synthetic_model_params()\n</code></pre> <p>get hyper parameters of synthetic models</p> <p>Returns:</p> Type Description <code>dict</code> <p>hyper params</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_synthetic_model_params(self) -&gt; dict:\n    \"\"\"get hyper parameters of synthetic models\n\n    :return: hyper params\n    \"\"\"\n    return self.api_client.get(GET_SYNTHETIC_MODEL_PARAMS_URI)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_tag_data","title":"get_tag_data","text":"<pre><code>get_tag_data(tag)\n</code></pre> <p>Run model inference on data</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>data tag for downloading</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_tag_data(\n    self,\n    tag: str,\n) -&gt; pd.DataFrame:\n    \"\"\"Run model inference on data\n\n    :param tag: data tag for downloading\n    :return: dataframe\n    \"\"\"\n\n    tags = self.available_tags()\n    available_tags = tags[\"alltags\"]\n    if tag not in available_tags:\n        raise Exception(\n            f\"{tag} tag is not valid, select valid tag from :\\n{available_tags}\"\n        )\n\n    auth_token = self.api_client.get_auth_token()\n\n    uri = f\"{DOWNLOAD_TAG_DATA_URI}?project_name={self.project_name}&amp;tag={tag}&amp;token={auth_token}\"\n\n    tag_data = self.api_client.base_request(\"GET\", uri)\n\n    tag_data_df = pd.read_csv(io.StringIO(tag_data.text))\n\n    return tag_data_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_target_drift_dashboard","title":"get_target_drift_dashboard","text":"<pre><code>get_target_drift_dashboard(\n    payload={}, instance_type=None, run_in_background=False\n)\n</code></pre> <p>get target drift dashboard</p> <p>Parameters:</p> Name Type Description Default <code>run_in_background</code> <code>bool</code> <p>runs in background without waiting for dashboard generation to complete</p> <code>False</code> <code>instance_type</code> <code>Optional[str]</code> <p>instance type for running on custom server</p> <code>None</code> <code>payload</code> <code>TargetDriftPayload</code> <p>target drift payload { \"base_line_tag\": \"\", \"current_tag\": \"\", \"stat_test_name\": \"\", \"stat_test_threshold\": \"\", \"date_feature\": \"\", \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"}, \"model_type\": \"\", \"baseline_true_label\": \"\", \"current_true_label\": \"\" } defaults to None key values for payload: stat_test_name= chisquare (Chi-Square test): default for categorical features if the number of labels for feature &gt; 2 only for categorical features returns p_value default threshold 0.05 drift detected when p_value &lt; threshold jensenshannon (Jensen-Shannon distance): for numerical and categorical features returns distance default threshold 0.05 drift detected when distance &gt;= threshold kl_div (Kullback-Leibler divergence): for numerical and categorical features returns divergence default threshold 0.05 drift detected when divergence &gt;= threshold, psi (Population Stability Index): for numerical and categorical features returns psi_value default_threshold=0.1 drift detected when psi_value &gt;= threshold z (Ztest): default for categorical features if the number of labels for feature &lt;= 2 only for categorical features returns p_value default threshold 0.05 drift detected when p_value &lt; threshold</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dashboard</code> <p>Dashboard</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_target_drift_dashboard(\n    self,\n    payload: TargetDriftPayload = {},\n    instance_type: Optional[str] = None,\n    run_in_background: bool = False,\n) -&gt; Dashboard:\n    \"\"\"get target drift dashboard\n\n    :param run_in_background: runs in background without waiting for dashboard generation to complete\n    :param instance_type: instance type for running on custom server\n    :param payload: target drift payload\n            {\n                \"base_line_tag\": \"\",\n                \"current_tag\": \"\",\n                \"stat_test_name\": \"\",\n                \"stat_test_threshold\": \"\",\n                \"date_feature\": \"\",\n                \"baseline_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"current_date\": { \"start_date\": \"\", \"end_date\": \"\"},\n                \"model_type\": \"\",\n                \"baseline_true_label\": \"\",\n                \"current_true_label\": \"\"\n            }\n            defaults to None\n            key values for payload:\n                stat_test_name=\n                    chisquare (Chi-Square test):\n                    default for categorical features if the number of labels for feature &gt; 2\n                    only for categorical features\n                    returns p_value\n                    default threshold 0.05\n                    drift detected when p_value &lt; threshold\n                jensenshannon (Jensen-Shannon distance):\n                    for numerical and categorical features\n                    returns distance\n                    default threshold 0.05\n                    drift detected when distance &gt;= threshold\n                kl_div (Kullback-Leibler divergence):\n                    for numerical and categorical features\n                    returns divergence\n                    default threshold 0.05\n                    drift detected when divergence &gt;= threshold,\n                psi (Population Stability Index):\n                    for numerical and categorical features\n                    returns psi_value\n                    default_threshold=0.1\n                    drift detected when psi_value &gt;= threshold\n                z (Ztest):\n                    default for categorical features if the number of labels for feature &lt;= 2\n                    only for categorical features\n                    returns p_value\n                    default threshold 0.05\n                    drift detected when p_value &lt; threshold\n    :return: Dashboard\n    \"\"\"\n    if not payload:\n        return self.get_default_dashboard(\"target_drift\")\n\n    payload[\"project_name\"] = self.project_name\n\n    # validate required fields\n    Validate.check_for_missing_keys(payload, TARGET_DRIFT_DASHBOARD_REQUIRED_FIELDS)\n\n    # validate tags and labels\n    tags_info = self.available_tags()\n    all_tags = tags_info[\"alltags\"]\n\n    Validate.value_against_list(\"base_line_tag\", payload[\"base_line_tag\"], all_tags)\n    Validate.value_against_list(\"current_tag\", payload[\"current_tag\"], all_tags)\n\n    Validate.validate_date_feature_val(payload, tags_info[\"alldatetimefeatures\"])\n\n    Validate.value_against_list(\"model_type\", payload[\"model_type\"], MODEL_TYPES)\n\n    Validate.value_against_list(\n        \"stat_test_name\", payload[\"stat_test_name\"], TARGET_DRIFT_STAT_TESTS\n    )\n\n    Validate.value_against_list(\n        \"baseline_true_label\",\n        [payload[\"baseline_true_label\"]],\n        tags_info[\"alluniquefeatures\"],\n    )\n\n    Validate.value_against_list(\n        \"current_true_label\",\n        [payload[\"current_true_label\"]],\n        tags_info[\"alluniquefeatures\"],\n    )\n\n    custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n    Validate.value_against_list(\n        \"instance_type\",\n        instance_type,\n        [\n            server[\"instance_name\"]\n            for server in custom_batch_servers.get(\"details\", [])\n        ],\n    )\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(\n        f\"{GENERATE_DASHBOARD_URI}?type=target_drift\", payload\n    )\n\n    if not res[\"success\"]:\n        error_details = res.get(\"details\", \"Failed to get dashboard url\")\n        raise Exception(error_details)\n\n    if not run_in_background:\n        poll_events(self.api_client, self.project_name, res[\"task_id\"])\n        return self.get_default_dashboard(\"target_drift\")\n\n    return \"Target drift dashboard generation initiated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.get_viewed_case","title":"get_viewed_case","text":"<pre><code>get_viewed_case(case_id)\n</code></pre> <p>Get already viewed case</p> <p>Parameters:</p> Name Type Description Default <code>case_id</code> <code>str</code> <p>case id</p> required <p>Returns:</p> Type Description <code>Case</code> <p>Case object with details</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def get_viewed_case(self, case_id: str) -&gt; Case:\n    \"\"\"Get already viewed case\n\n    :param case_id: case id\n    :return: Case object with details\n    \"\"\"\n\n    res = self.api_client.get(\n        f\"{GET_VIEWED_CASE_URI}?project_name={self.project_name}&amp;case_id={case_id}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to get viewed case\"))\n\n    data = {**res[\"details\"], **res[\"details\"].get(\"result\", {})}\n    data[\"api_client\"] = self.api_client\n    if self.metadata.get(\"modality\") != \"text\":\n        case = Case(**data)\n    if self.metadata.get(\"modality\") == \"text\":\n        case = CaseText(**data)\n    return case\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.list_data_connectors","title":"list_data_connectors","text":"<pre><code>list_data_connectors()\n</code></pre> <p>List data connectors available for this project/org. Returns a cleaned pandas DataFrame on success, otherwise an error message.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def list_data_connectors(self) -&gt; str | pd.DataFrame:\n    \"\"\"List data connectors available for this project/org.\n    Returns a cleaned pandas DataFrame on success, otherwise an error message.\"\"\"\n    url = build_list_data_connector_url(\n        LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n    )\n    res = self.api_client.post(url)\n\n    if res[\"success\"]:\n        df = pd.DataFrame(res[\"details\"])\n        df = df.drop(\n            [\n                \"_id\",\n                \"region\",\n                \"gcp_project_name\",\n                \"gcp_project_id\",\n                \"gdrive_file_name\",\n            ],\n            axis=1,\n            errors=\"ignore\",\n        )\n        return df\n\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.list_data_connectors_buckets","title":"list_data_connectors_buckets","text":"<pre><code>list_data_connectors_buckets(data_connector_name)\n</code></pre> <p>List the buckets in data connectors</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def list_data_connectors_buckets(self, data_connector_name) -&gt; str | List:\n    \"\"\"List the buckets in data connectors\n\n    :param data_connector_name: str\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id and not self.project_name:\n        return \"No Project Name or Organization id found\"\n\n    url = build_url(\n        LIST_BUCKETS, data_connector_name, self.project_name, self.organization_id\n    )\n    res = self.api_client.get(url)\n\n    if res.get(\"message\", None):\n        print(res[\"message\"])\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.list_data_connectors_filepath","title":"list_data_connectors_filepath","text":"<pre><code>list_data_connectors_filepath(\n    data_connector_name, bucket_name=None, root_folder=None\n)\n</code></pre> <p>List the filepaths in data connectors</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required <code>bucket_name</code> <code>Optional[str]</code> <p>str | Required for S3 &amp; GCS</p> <code>None</code> <code>root_folder</code> <code>Optional[str]</code> <p>str | Root folder of SFTP</p> <code>None</code> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def list_data_connectors_filepath(\n    self,\n    data_connector_name,\n    bucket_name: Optional[str] = None,\n    root_folder: Optional[str] = None,\n) -&gt; str | Dict:\n    \"\"\"List the filepaths in data connectors\n\n    :param data_connector_name: str\n    :param bucket_name: str | Required for S3 &amp; GCS\n    :param root_folder: str | Root folder of SFTP\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id and not self.project_name:\n        return \"No Project Name or Organization id found\"\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Look up the configured data connector by name.\n        Returns a one-row DataFrame (or an error string) with connector metadata.\"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n\n        if ds_type == \"sftp\":\n            if not root_folder:\n                return \"Missing argument root_folder\"\n\n    if self.project_name:\n        url = f\"{LIST_FILEPATHS}?project_name={self.project_name}&amp;link_service_name={data_connector_name}&amp;bucket_name={bucket_name}&amp;root_folder={root_folder}\"\n    elif self.organization_id:\n        url = f\"{LIST_FILEPATHS}?organization_id={self.organization_id}&amp;link_service_name={data_connector_name}&amp;bucket_name={bucket_name}&amp;root_folder={root_folder}\"\n    res = self.api_client.get(url)\n\n    if res.get(\"message\", None):\n        print(res[\"message\"])\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.model_inference","title":"model_inference","text":"<pre><code>model_inference(\n    tag=None,\n    file_name=None,\n    model_name=None,\n    instance_type=None,\n)\n</code></pre> <p>Run model inference on data</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>Optional[str]</code> <p>data tag for running inference</p> <code>None</code> <code>model_name</code> <code>Optional[str]</code> <p>name of the model, defaults to active model for the project</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>model inference dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def model_inference(\n    self,\n    tag: Optional[str] = None,\n    file_name: Optional[str] = None,\n    model_name: Optional[str] = None,\n    instance_type: Optional[str] = None\n) -&gt; pd.DataFrame:\n    \"\"\"Run model inference on data\n\n    :param tag: data tag for running inference\n    :param model_name: name of the model, defaults to active model for the project\n    :return: model inference dataframe\n    \"\"\"\n\n    if not tag and not file_name:\n        raise Exception(\"Either tag or file_name is required.\")\n    if tag and file_name:\n        raise Exception(\"Provide either tag or file_name, not both.\")\n    available_tags = self.tags()\n    if tag and tag not in available_tags:\n        raise Exception(\n            f\"{tag} tag is not valid, select valid tag from :\\n{available_tags}\"\n        )\n\n    files = self.api_client.get(\n        f\"{ALL_DATA_FILE_URI}?project_name={self.project_name}\"\n    )\n    file_names = []\n    for file in files.get(\"details\"):\n        file_names.append(file.get(\"filepath\").split(\"/\")[-1])\n\n    if file_name and file_name not in file_names:\n        raise Exception(\n            f\"{file_name} file name is not valid, select valid tag from :\\n{file_names.join(',')}\"\n        )\n    filepath = None\n    for file in files[\"details\"]:\n        file_path = file[\"filepath\"]\n        curr_file_name = file_path.split(\"/\")[-1]\n        if file_name == curr_file_name:\n            filepath = file_path\n            break\n\n    models = self.models()\n\n    available_models = models[\"model_name\"].to_list()\n\n    if model_name:\n        Validate.value_against_list(\"model_name\", model_name, available_models)\n\n    model = (\n        model_name\n        or models.loc[models[\"status\"] == \"active\"][\"model_name\"].values[0]\n    )\n\n    if instance_type:\n        custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n        available_custom_batch_servers = custom_batch_servers.get(\"details\", []) + custom_batch_servers.get(\"available_gpu_custom_servers\", [])\n        Validate.value_against_list(\n            \"instance_type\",\n            instance_type,\n            [\n                server[\"instance_name\"]\n                for server in available_custom_batch_servers\n            ],\n        )\n\n    run_model_payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model,\n        \"tags\": tag,\n        \"instance_type\": instance_type\n    }\n    if filepath:\n        run_model_payload[\"filepath\"] = filepath\n\n    run_model_res = self.api_client.post(RUN_MODEL_ON_DATA_URI, run_model_payload)\n\n    if not run_model_res[\"success\"]:\n        raise Exception(run_model_res[\"details\"])\n\n    poll_events(\n        api_client=self.api_client,\n        project_name=self.project_name,\n        event_id=run_model_res[\"event_id\"],\n    )\n\n    auth_token = self.api_client.get_auth_token()\n\n    if tag:\n        uri = f\"{DOWNLOAD_TAG_DATA_URI}?project_name={self.project_name}&amp;tag={tag}_{model}_Inference&amp;token={auth_token}\"\n    else:\n        file_name = file_name.replace(\".\", \"_\")\n        uri = f\"{DOWNLOAD_TAG_DATA_URI}?project_name={self.project_name}&amp;tag={file_name}_{model}_Inference&amp;token={auth_token}\"\n    tag_data = self.api_client.base_request(\"GET\", uri)\n\n    tag_data_df = pd.read_csv(io.StringIO(tag_data.text))\n\n    return tag_data_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.model_inference_settings","title":"model_inference_settings","text":"<pre><code>model_inference_settings(model_name, inference_compute)\n</code></pre> <p>Model Inference Settings</p> <p>Parameters:</p> Name Type Description Default <code>model_provider</code> <p>model of provider</p> required <code>model_name</code> <code>str</code> <p>name of the model to be initialized</p> required <code>model_task_type</code> <p>task type of model</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def model_inference_settings(\n    self, model_name: str, inference_compute: InferenceCompute\n) -&gt; str:\n    \"\"\"Model Inference Settings\n\n    :param model_provider: model of provider\n    :param model_name: name of the model to be initialized\n    :param model_task_type: task type of model\n    :return: response\n    \"\"\"\n    payload = {\n        \"model_name\": model_name,\n        \"project_name\": self.project_name,\n        \"inference_compute\": inference_compute,\n    }\n\n    res = self.api_client.post(f\"{TEXT_MODEL_INFERENCE_SETTINGS_URI}\", payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to update inference settings\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.model_inferences","title":"model_inferences","text":"<pre><code>model_inferences()\n</code></pre> <p>All model inferences</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>model inferences dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def model_inferences(self) -&gt; pd.DataFrame:\n    \"\"\"All model inferences\n\n    :return: model inferences dataframe\n    \"\"\"\n\n    res = self.api_client.get(\n        f\"{MODEL_INFERENCES_URI}?project_name={self.project_name}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    model_inference_df = pd.DataFrame(res[\"details\"][\"inference_details\"])\n\n    return model_inference_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.model_parameters","title":"model_parameters","text":"<pre><code>model_parameters()\n</code></pre> <p>Model Parameters</p> <p>Returns:</p> Type Description <code>dict</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def model_parameters(self) -&gt; dict:\n    \"\"\"Model Parameters\n\n    :return: response\n    \"\"\"\n\n    model_params = self.api_client.get(MODEL_PARAMETERS_URI)\n\n    return model_params\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.model_summary","title":"model_summary","text":"<pre><code>model_summary(model_name=None)\n</code></pre> <p>Model Summary</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>Optional[str]</code> <p>name of the model, defaults to active model for project</p> <code>None</code> <p>Returns:</p> Type Description <code>ModelSummary</code> <p>model summary</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def model_summary(self, model_name: Optional[str] = None) -&gt; ModelSummary:\n    \"\"\"Model Summary\n\n    :param model_name: name of the model, defaults to active model for project\n    :return: model summary\n    \"\"\"\n    if self.metadata.get(\"modality\") == \"text\":\n        res = self.api_client.post(\n            f\"{PROJECT_OVERVIEW_TEXT_URI}?project_name={self.project_name}\"\n        )\n        return res.get(\"details\")\n    else:\n        res = self.api_client.get(\n            f\"{MODEL_SUMMARY_URI}?project_name={self.project_name}\"\n            + (f\"&amp;model_name={model_name}\" if model_name else \"\")\n        )\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return ModelSummary(api_client=self.api_client, **res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.models","title":"models","text":"<pre><code>models()\n</code></pre> <p>Models trained for the project</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Dataframe with details of all models</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def models(self) -&gt; pd.DataFrame:\n    \"\"\"Models trained for the project\n\n    :return: Dataframe with details of all models\n    \"\"\"\n    res = self.api_client.get(f\"{GET_MODELS_URI}?project_name={self.project_name}\")\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    staged_models = res[\"details\"][\"staged\"]\n\n    staged_models_df = pd.DataFrame(staged_models)\n    staged_models_df = staged_models_df.drop(columns=['model_provider'])\n    staged_models_df = staged_models_df[\n        ~staged_models_df[\"status\"].isin([\"inactive\", \"failed\"])\n    ]\n\n    return staged_models_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.monitoring_triggers","title":"monitoring_triggers","text":"<pre><code>monitoring_triggers()\n</code></pre> <p>get monitoring triggers of project</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def monitoring_triggers(self) -&gt; pd.DataFrame:\n    \"\"\"get monitoring triggers of project\n\n    :return: DataFrame\n    \"\"\"\n    url = f\"{GET_TRIGGERS_URI}?project_name={self.project_name}\"\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        return Exception(res.get(\"details\", \"Failed to get triggers\"))\n\n    monitoring_triggers = res.get(\"details\", [])\n\n    if not monitoring_triggers:\n        return \"No monitoring triggers found.\"\n\n    monitoring_triggers = pd.DataFrame(monitoring_triggers)\n    monitoring_triggers = monitoring_triggers[\n        monitoring_triggers[\"deleted\"] == False\n    ]\n    monitoring_triggers = monitoring_triggers.drop(\"project_name\", axis=1)\n\n    return monitoring_triggers\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.observation_trail","title":"observation_trail","text":"<pre><code>observation_trail()\n</code></pre> <p>Observation Trail</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>observation trail details dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def observation_trail(self) -&gt; pd.DataFrame:\n    \"\"\"Observation Trail\n\n    :return: observation trail details dataframe\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_OBSERVATIONS_URI}?project_name={self.project_name}\"\n    )\n\n    if not res.get(\"details\"):\n        raise Exception(\"No observations found\")\n\n    observation_df = pd.DataFrame(res.get(\"details\"))\n    observation_df = observation_df[\n        observation_df[\"status\"].isin([\"updated\", \"deleted\"])\n    ]\n    if observation_df.empty:\n        raise Exception(\"No observation trail found\")\n    observation_df = observation_df.rename(\n        columns={\n            \"statement\": \"old_statement\",\n            \"linked_features\": \"old_linked_features\",\n        }\n    )\n    observation_df[\"updated_keys\"].replace(float(\"nan\"), None, inplace=True)\n    observation_df[\"updated_statement\"] = observation_df[\"updated_keys\"].apply(\n        lambda data: data.get(\"statement\") if data else None\n    )\n\n    observation_df[\"updated_linked_features\"] = observation_df[\n        \"updated_keys\"\n    ].apply(lambda data: data.get(\"linked_features\") if data else None)\n\n    observation_df[\"old_expression\"] = observation_df[\"metadata\"].apply(\n        lambda metadata: generate_expression(metadata[\"expression\"])\n    )\n\n    observation_df[\"updated_expression\"] = observation_df[\"updated_keys\"].apply(\n        lambda data: (\n            generate_expression(data.get(\"metadata\", {}).get(\"expression\"))\n            if data\n            else None\n        )\n    )\n\n    observation_df = observation_df.drop(\n        columns=[\n            \"project_name\",\n            \"configuration\",\n            \"metadata\",\n            \"updated_by\",\n            \"created_by\",\n            \"updated_keys\",\n        ],\n        errors=\"ignore\",\n    )\n\n    observation_df = observation_df.reindex(\n        [\n            \"observation_id\",\n            \"observation_name\",\n            \"status\",\n            \"old_statement\",\n            \"updated_statement\",\n            \"old_linked_features\",\n            \"updated_linked_features\",\n            \"old_expression\",\n            \"updated_expression\",\n            \"created_at\",\n            \"updated_at\",\n        ],\n        axis=1,\n    )\n\n    observation_df.reset_index(inplace=True, drop=True)\n    return observation_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.observations","title":"observations","text":"<pre><code>observations()\n</code></pre> <p>Observations</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>observation details dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def observations(self) -&gt; pd.DataFrame:\n    \"\"\"Observations\n\n    :return: observation details dataframe\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_OBSERVATIONS_URI}?project_name={self.project_name}\"\n    )\n\n    observation_df = pd.DataFrame(res.get(\"details\"))\n\n    if observation_df.empty:\n        return observation_df\n\n    observation_df = observation_df[\n        observation_df[\"status\"].isin([\"active\", \"inactive\"])\n    ]\n\n    if observation_df.empty:\n        return observation_df\n\n    observation_df[\"expression\"] = observation_df[\"metadata\"].apply(\n        lambda metadata: generate_expression(metadata[\"expression\"])\n    )\n\n    observation_df = observation_df.drop(\n        columns=[\n            \"project_name\",\n            \"configuration\",\n            \"metadata\",\n            \"updated_by\",\n            \"created_by\",\n            \"updated_keys\",\n        ],\n        errors=\"ignore\",\n    )\n    observation_df = observation_df.reindex(\n        [\n            \"observation_id\",\n            \"observation_name\",\n            \"status\",\n            \"statement\",\n            \"linked_features\",\n            \"expression\",\n            \"created_at\",\n            \"updated_at\",\n        ],\n        axis=1,\n    )\n    observation_df.reset_index(inplace=True, drop=True)\n    return observation_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.policies","title":"policies","text":"<pre><code>policies()\n</code></pre> <p>Policies</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>policy details dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def policies(self) -&gt; pd.DataFrame:\n    \"\"\"Policies\n\n    :return: policy details dataframe\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_POLICIES_URI}?project_name={self.project_name}\"\n    )\n\n    policy_df = pd.DataFrame(res.get(\"details\"))\n\n    if policy_df.empty:\n        return policy_df\n\n    policy_df = policy_df[policy_df[\"status\"].isin([\"active\", \"inactive\"])]\n\n    if policy_df.empty:\n        return policy_df\n\n    policy_df[\"expression\"] = policy_df[\"metadata\"].apply(\n        lambda metadata: generate_expression(metadata[\"expression\"])\n    )\n\n    policy_df = policy_df.drop(\n        columns=[\n            \"project_name\",\n            \"configuration\",\n            \"metadata\",\n            \"linked_features\",\n            \"updated_by\",\n            \"created_by\",\n            \"updated_keys\",\n        ],\n        errors=\"ignore\",\n    )\n    policy_df = policy_df.reindex(\n        [\n            \"policy_id\",\n            \"policy_name\",\n            \"status\",\n            \"statement\",\n            \"decision\",\n            \"expression\",\n            \"created_at\",\n            \"updated_at\",\n        ],\n        axis=1,\n    )\n    policy_df.reset_index(inplace=True, drop=True)\n    return policy_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.policy_trail","title":"policy_trail","text":"<pre><code>policy_trail()\n</code></pre> <p>Policy Trail</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>observation details dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def policy_trail(self) -&gt; pd.DataFrame:\n    \"\"\"Policy Trail\n\n    :return: observation details dataframe\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_POLICIES_URI}?project_name={self.project_name}\"\n    )\n\n    if not res.get(\"details\"):\n        raise Exception(\"No policies found\")\n\n    policy_df = pd.DataFrame(res.get(\"details\"))\n    policy_df = policy_df[policy_df[\"status\"].isin([\"updated\", \"deleted\"])]\n    if policy_df.empty:\n        raise Exception(\"No policy trail found\")\n    policy_df = policy_df.rename(\n        columns={\n            \"statement\": \"old_statement\",\n            \"decision\": \"old_decision\",\n        }\n    )\n\n    policy_df[\"updated_keys\"].replace(float(\"nan\"), None, inplace=True)\n\n    policy_df[\"updated_statement\"] = policy_df[\"updated_keys\"].apply(\n        lambda data: data.get(\"statement\") if data else None\n    )\n\n    policy_df[\"updated_decision\"] = policy_df[\"updated_keys\"].apply(\n        lambda data: data.get(\"decision\") if data else None\n    )\n\n    policy_df[\"old_expression\"] = policy_df[\"metadata\"].apply(\n        lambda metadata: generate_expression(metadata[\"expression\"])\n    )\n\n    policy_df[\"updated_expression\"] = policy_df[\"updated_keys\"].apply(\n        lambda data: (\n            generate_expression(data.get(\"metadata\", {}).get(\"expression\"))\n            if data\n            else None\n        )\n    )\n\n    policy_df = policy_df.drop(\n        columns=[\n            \"project_name\",\n            \"configuration\",\n            \"metadata\",\n            \"updated_by\",\n            \"created_by\",\n            \"updated_keys\",\n            \"linked_features\",\n        ],\n        errors=\"ignore\",\n    )\n    policy_df = policy_df.reindex(\n        [\n            \"policy_id\",\n            \"policy_name\",\n            \"status\",\n            \"old_statement\",\n            \"updated_statement\",\n            \"old_decision\",\n            \"updated_decision\",\n            \"old_expression\",\n            \"updated_expression\",\n            \"created_at\",\n            \"updated_at\",\n        ],\n        axis=1,\n    )\n    policy_df.reset_index(inplace=True, drop=True)\n\n    return policy_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.remove_model","title":"remove_model","text":"<pre><code>remove_model(model_name)\n</code></pre> <p>Removes the trained model for the project</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>name of the model</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def remove_model(self, model_name: str) -&gt; str:\n    \"\"\"Removes the trained model for the project\n\n    :param model_name: name of the model\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n    }\n    res = self.api_client.post(REMOVE_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.remove_synthetic_model","title":"remove_synthetic_model","text":"<pre><code>remove_synthetic_model(model_name)\n</code></pre> <p>deletes synthetic model</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>model name</p> required <p>Returns:</p> Type Description <code>str</code> <p>response message</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>description</p> <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def remove_synthetic_model(self, model_name: str) -&gt; str:\n    \"\"\"deletes synthetic model\n\n    :param model_name: model name\n    :raises ValueError: _description_\n    :raises Exception: _description_\n    :return: response message\n    \"\"\"\n    models_df = self.synthetic_models()\n    valid_models = models_df[\"model_name\"].tolist()\n\n    if model_name not in valid_models:\n        raise ValueError(\n            f\"{model_name} is not valid. Pick a valid value from {valid_models}\"\n        )\n\n    payload = {\"project_name\": self.project_name, \"model_name\": model_name}\n\n    res = self.api_client.post(DELETE_SYNTHETIC_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return f\"{model_name} deleted successfully.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.remove_synthetic_tag","title":"remove_synthetic_tag","text":"<pre><code>remove_synthetic_tag(tag)\n</code></pre> <p>delete synthetic data tag</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>Tag name to delete.</p> required <p>Returns:</p> Type Description <code>str</code> <p>response messsage</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def remove_synthetic_tag(self, tag: str) -&gt; str:\n    \"\"\"delete synthetic data tag\n\n    :param tag: Tag name to delete.\n    :raises Exception: _description_\n    :return: response messsage\n    \"\"\"\n    all_tags = self.all_tags()\n\n    Validate.value_against_list(\n        \"tag\",\n        tag,\n        all_tags,\n    )\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"tag\": tag,\n    }\n\n    res = self.api_client.post(DELETE_SYNTHETIC_TAG_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return f\"{tag} deleted successfully.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.remove_user_from_project","title":"remove_user_from_project","text":"<pre><code>remove_user_from_project(email)\n</code></pre> <p>Remove a user from the project using their email address. Returns a confirmation message.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>str</code> <p>user email</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def remove_user_from_project(self, email: str) -&gt; str:\n    \"\"\"Remove a user from the project using their email address. Returns a confirmation message.\n\n    :param email: user email\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\"remove_user_project\": email},\n    }\n    res = self.api_client.post(UPDATE_PROJECT_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.rename_project","title":"rename_project","text":"<pre><code>rename_project(new_project_name)\n</code></pre> <p>Rename the project by providing a new name. Sends an update request and returns a confirmation message.</p> <p>Parameters:</p> Name Type Description Default <code>new_project_name</code> <code>str</code> <p>new name for the project</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def rename_project(self, new_project_name: str) -&gt; str:\n    \"\"\"Rename the project by providing a new name. Sends an update request and returns a confirmation message.\n\n    :param new_project_name: new name for the project\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"update_project\": {\n                \"project_name\": new_project_name,\n            }\n        },\n    }\n    res = self.api_client.post(UPDATE_PROJECT_URI, payload)\n    self.user_project_name = new_project_name\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.start_server","title":"start_server","text":"<pre><code>start_server()\n</code></pre> <p>Start a dedicated server for the project, enabling training or inference activities.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def start_server(self) -&gt; str:\n    \"\"\"Start a dedicated server for the project, enabling training or inference activities.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.post(\n        f\"{START_CUSTOM_SERVER_URI}?project_name={self.project_name}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"message\"))\n\n    return res[\"message\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.stop_server","title":"stop_server","text":"<pre><code>stop_server()\n</code></pre> <p>Stop the dedicated project server to release compute resources.</p> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def stop_server(self) -&gt; str:\n    \"\"\"Stop the dedicated project server to release compute resources.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.post(\n        f\"{STOP_CUSTOM_SERVER_URI}?project_name={self.project_name}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"message\"))\n\n    return res[\"message\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_model","title":"synthetic_model","text":"<pre><code>synthetic_model(model_name)\n</code></pre> <p>get synthetic model details</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>model name</p> required <p>Returns:</p> Type Description <code>SyntheticModel</code> <p>description</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_model(self, model_name: str) -&gt; SyntheticModel:\n    \"\"\"get synthetic model details\n\n    :param model_name: model name\n    :raises Exception: _description_\n    :return: _description_\n    \"\"\"\n    models_df = self.synthetic_models()\n    valid_models = models_df[\"model_name\"].tolist()\n\n    if model_name not in valid_models:\n        raise ValueError(\n            f\"{model_name} is not valid. Pick a valid value from {valid_models}\"\n        )\n\n    url = f\"{GET_SYNTHETIC_MODEL_DETAILS_URI}?project_name={self.project_name}&amp;model_name={model_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    model_details = res[\"details\"][0]\n\n    metadata = model_details[\"metadata\"]\n    data_quality = model_details[\"results\"]\n\n    del model_details[\"metadata\"]\n    del model_details[\"results\"]\n\n    synthetic_model = SyntheticModel(\n        **model_details,\n        **data_quality,\n        metadata=metadata,\n        api_client=self.api_client,\n        project=self,\n    )\n\n    return synthetic_model\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_models","title":"synthetic_models","text":"<pre><code>synthetic_models()\n</code></pre> <p>get synthetic models for the project</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>synthetic models</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_models(self) -&gt; pd.DataFrame:\n    \"\"\"get synthetic models for the project\n\n    :return: synthetic models\n    \"\"\"\n    url = f\"{GET_SYNTHETIC_MODELS_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while getting synthetics models.\")\n\n    models = res[\"details\"]\n\n    models_df = pd.DataFrame(models)\n\n    return models_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_prompt","title":"synthetic_prompt","text":"<pre><code>synthetic_prompt(prompt_id)\n</code></pre> <p>get synthetic prompt by prompt id</p> <p>Parameters:</p> Name Type Description Default <code>prompt_id</code> <code>str</code> <p>Prompt identifier.</p> required <p>Returns:</p> Type Description <code>SyntheticPrompt</code> <p>description</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_prompt(self, prompt_id: str) -&gt; SyntheticPrompt:\n    \"\"\"get synthetic prompt by prompt id\n\n    :param prompt_id: Prompt identifier.\n    :raises Exception: _description_\n    :return: _description_\n    \"\"\"\n    url = f\"{GET_SYNTHETIC_PROMPT_URI}?project_name={self.project_name}\"\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    prompts = res[\"details\"]\n\n    curr_prompt = next(\n        (prompt for prompt in prompts if prompt[\"prompt_id\"] == prompt_id), None\n    )\n\n    if not curr_prompt:\n        raise Exception(f\"Invalid prompt_id\")\n\n    return SyntheticPrompt(**curr_prompt, api_client=self.api_client, project=self)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_prompts","title":"synthetic_prompts","text":"<pre><code>synthetic_prompts()\n</code></pre> <p>get synthetic prompts for the project</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>description</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_prompts(self) -&gt; pd.DataFrame:\n    \"\"\"get synthetic prompts for the project\n\n    :raises Exception: _description_\n    :return: _description_\n    \"\"\"\n    url = f\"{GET_SYNTHETIC_PROMPT_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    prompts = res[\"details\"]\n\n    return pd.DataFrame(prompts).reindex(\n        columns=[\"prompt_id\", \"prompt_name\", \"status\", \"created_at\", \"updated_at\"]\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_tag","title":"synthetic_tag","text":"<pre><code>synthetic_tag(tag)\n</code></pre> <p>get synthetic data tag by tag name</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>tag name</p> required <p>Returns:</p> Type Description <code>SyntheticDataTag</code> <p>tag</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_tag(self, tag: str) -&gt; SyntheticDataTag:\n    \"\"\"get synthetic data tag by tag name\n    :param tag: tag name\n    :raises Exception: _description_\n    :return: tag\n    \"\"\"\n    url = f\"{GET_SYNTHETIC_DATA_TAGS_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while getting synthetics data tags.\")\n\n    data_tags = res[\"details\"]\n\n    syn_data_tags = [\n        SyntheticDataTag(\n            **data_tag,\n            api_client=self.api_client,\n            project_name=self.project_name,\n            project=self,\n        )\n        for data_tag in data_tags\n    ]\n\n    data_tag = next(\n        (syn_data_tag for syn_data_tag in syn_data_tags if syn_data_tag.tag == tag),\n        None,\n    )\n\n    if not data_tag:\n        valid_tags = [syn_data_tag.tag for syn_data_tag in syn_data_tags]\n        raise Exception(f\"{tag} is invalid. Pick a valid value from {valid_tags}\")\n\n    return data_tag\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_tag_datapoints","title":"synthetic_tag_datapoints","text":"<pre><code>synthetic_tag_datapoints(tag)\n</code></pre> <p>get synthetic tag datapoints</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>tag name</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>datapoints</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_tag_datapoints(self, tag: str) -&gt; pd.DataFrame:\n    \"\"\"get synthetic tag datapoints\n\n    :param tag: tag name\n    :raises Exception: _description_\n    :return: datapoints\n    \"\"\"\n    all_tags = self.all_tags()\n\n    Validate.value_against_list(\n        \"tag\",\n        tag,\n        all_tags,\n    )\n\n    res = self.api_client.base_request(\n        \"GET\",\n        f\"{DOWNLOAD_SYNTHETIC_DATA_URI}?project_name={self.project_name}&amp;tag={tag}&amp;token={self.api_client.get_auth_token()}\",\n    )\n\n    synthetic_data = pd.read_csv(io.StringIO(res.content.decode(\"utf-8\")))\n\n    return synthetic_data\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.synthetic_tags","title":"synthetic_tags","text":"<pre><code>synthetic_tags()\n</code></pre> <p>get synthetic data tags of the model</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>list of tags</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def synthetic_tags(self) -&gt; pd.DataFrame:\n    \"\"\"get synthetic data tags of the model\n    :raises Exception: _description_\n    :return: list of tags\n    \"\"\"\n    url = f\"{GET_SYNTHETIC_DATA_TAGS_URI}?project_name={self.project_name}\"\n\n    res = self.api_client.get(url)\n\n    if not res[\"success\"]:\n        raise Exception(\"Error while getting synthetics data tags.\")\n\n    data_tags = res[\"details\"]\n\n    for data_tag in data_tags:\n        del data_tag[\"metadata\"]\n        del data_tag[\"plot_data\"]\n\n    return pd.DataFrame(data_tags)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.tag_data","title":"tag_data","text":"<pre><code>tag_data(tag, page=1)\n</code></pre> <p>Tag Data</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>Tag name to filter data by.</p> required <code>page</code> <code>Optional[int]</code> <p>Page number for paginated results.</p> <code>1</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>tag data dataframe</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def tag_data(self, tag: str, page: Optional[int] = 1) -&gt; pd.DataFrame:\n    \"\"\"Tag Data\n\n    :param tag: Tag name to filter data by.\n    :param page: Page number for paginated results.\n    :return: tag data dataframe\n    \"\"\"\n    tags = self.all_tags()\n\n    Validate.value_against_list(\"tag\", tag, tags)\n\n    payload = {\"page\": page, \"project_name\": self.project_name, \"tag\": tag}\n    res = self.api_client.post(TAG_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Tag data Not Found\"))\n\n    tag_data_df = pd.DataFrame(res[\"details\"][\"data\"])\n\n    return tag_data_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.tags","title":"tags","text":"<pre><code>tags()\n</code></pre> <p>Available User Tags for Project</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>list of tags</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def tags(self) -&gt; List[str]:\n    \"\"\"Available User Tags for Project\n\n    :return: list of tags\n    \"\"\"\n    available_tags = self.available_tags()\n\n    tags = available_tags.get(\"user_tags\")\n\n    return tags\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.test_data_connectors","title":"test_data_connectors","text":"<pre><code>test_data_connectors(data_connector_name)\n</code></pre> <p>Test connection for the data connectors</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <p>str</p> required Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def test_data_connectors(self, data_connector_name) -&gt; str:\n    \"\"\"Test connection for the data connectors\n\n    :param data_connector_name: str\n    \"\"\"\n    if not data_connector_name:\n        return \"Missing argument data_connector_name\"\n    if not self.organization_id and not self.project_name:\n        return \"No Project Name or Organization id found\"\n    url = build_url(\n        TEST_DATA_CONNECTORS,\n        data_connector_name,\n        self.project_name,\n        self.organization_id,\n    )\n    res = self.api_client.post(url)\n    return res[\"details\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.train_model","title":"train_model","text":"<pre><code>train_model(\n    model_type,\n    data_config=None,\n    model_config=None,\n    tunning_config=None,\n    peft_config=None,\n    processor_config=None,\n    finetune_mode=None,\n    tunning_strategy=None,\n    instance_type=None,\n)\n</code></pre> <p>Train a Classic ML model or a Tabular Foundational model.</p> <p>This method is the single entry-point to train models in Lexsi. It applies the full training pipeline end-to-end:</p> <ul> <li>selects and prepares data (filtering, sampling, feature handling, imbalance handling)</li> <li>applies preprocessing / feature engineering (optional)</li> <li>trains either a classic ML model or a tabular foundation model</li> <li>optionally performs hyperparameter tuning (classic or foundational depending on strategy)</li> <li>optionally performs fine-tuning / PEFT for foundation models</li> <li>produces a trained model artifact and returns its identifier/reference</li> </ul> <p>Parameters:</p> Name Type Description Default <code>model_type</code> <code>str</code> <p>Name of the model to train. Must be one of the supported following values Classic ML models - <code>XGBoost</code> - <code>LGBoost</code> - <code>CatBoost</code> - <code>RandomForest</code> - <code>SGD</code> - <code>LogisticRegression</code> - <code>LinearRegression</code> - <code>GaussianNaiveBayes</code> Tabular foundation models (TabTune wrapper) - <code>TabPFN</code> - <code>TabICL</code> - <code>TabDPT</code> - <code>OrionMSP</code> - <code>OrionBix</code> - <code>Mitra</code> - <code>ContextTab</code></p> required <code>data_config</code> <code>Optional[DataConfig]</code> <p>Dataset selection + training-time data behavior such as: tag-based filtering, train/test tags, feature exclusion/encodings, optional Optuna usage, sampling fractions, and explainability controls. See :class:<code>lexsi_sdk.common.types.DataConfig</code>.</p> <code>None</code> <code>processor_config</code> <code>Optional[ProcessorParams]</code> <p>Optional preprocessing / feature engineering configuration applied before training (e.g., imputation, scaling, resampling strategy). See :class:<code>lexsi_sdk.common.types.ProcessorParams</code>.</p> <code>None</code> <code>model_config</code> <code>Optional[Union[XGBoostParams, LightGBMParams, CatBoostParams, RandomForestParams, FoundationalModelParams]]</code> <p>Model hyperparameters for the chosen <code>model_type</code>. Use the matching config type:  - For <code>XGBoost</code>: :class:<code>lexsi_sdk.common.types.XGBoostParams</code> - For <code>LGBoost</code>: :class:<code>lexsi_sdk.common.types.LightGBMParams</code> - For <code>CatBoost</code>: :class:<code>lexsi_sdk.common.types.CatBoostParams</code> - For <code>RandomForest</code>: :class:<code>lexsi_sdk.common.types.RandomForestParams</code> - For foundation models (e.g., <code>TabPFN</code>, <code>TabICL</code>, ...): :class:<code>lexsi_sdk.common.types.FoundationalModelParams</code>  For models like <code>SGD</code>, <code>LogisticRegression</code>, <code>LinearRegression</code>, <code>GaussianNaiveBayes</code>, parameters may be taken from defaults in the wrapper if not explicitly exposed through a typed config.</p> <code>None</code> <code>tunning_config</code> <code>Optional[TuningParams]</code> <p>Optional tuning / adaptation loop configuration. Used for episodic / few-shot / fine-tuning style training and some tuning strategies. See :class:<code>lexsi_sdk.common.types.TuningParams</code>.</p> <code>None</code> <code>tuning_strategy</code> <code>str | None</code> <p>Training / fine-tuning strategy to apply.  Supported values:  - <code>\"inference\"</code>: Zero-shot inference only. No training or parameter updates are performed.  - <code>\"base-ft\"</code>: Full fine-tuning of all model parameters.  - <code>\"peft\"</code>: Parameter-efficient fine-tuning using LoRA adapters. Requires <code>peft_config</code> and a foundation model that supports PEFT.  - <code>\"finetune\"</code>: Alias for <code>\"base-ft\"</code>.  If not provided, the default behavior depends on the selected <code>model_type</code>.</p> required <code>finetune_mode</code> <code>Optional[str]</code> <p>Fine-tuning mode for episodic / foundation models.  Supported values:  - <code>\"meta-learning\"</code>: Episodic meta-learning mode (default). Uses support/query splits and episodic optimization.  - <code>\"sft\"</code>: Standard supervised fine-tuning using conventional batches.  This parameter is applicable only to episodic or foundational models and is ignored for classic ML models.</p> <code>None</code> <code>peft_config</code> <code>Optional[PEFTParams]</code> <p>Parameter-efficient fine-tuning configuration (e.g., LoRA params). Used only when <code>finetune_mode=\"peft\"</code> and the selected foundation model supports PEFT. See :class:<code>lexsi_sdk.common.types.PEFTParams</code>.</p> <code>None</code> <code>instance_type</code> <code>Optional[str]</code> <p>Compute instance used for training (CPU/GPU). This is used by the computation layer to select the appropriate runtime environment we have CPU/GPU runtime with small medium large with 2x 3x nomeclature with GPU T4 and A10G . Example values: <code>\"small\"</code>, <code>\"medium\"</code>,<code>\"large\"</code>, <code>\"2xsmall\"</code>, <code>\"T4.small\"</code>, <code>\"A10G.xmedium\"</code></p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Identifier or reference for the trained model artifact (e.g., model ID / artifact URI).</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def train_model(\n    self,\n    model_type: str,\n    data_config: Optional[DataConfig] = None,\n    model_config: Optional[Union[XGBoostParams, LightGBMParams, CatBoostParams, RandomForestParams, FoundationalModelParams]] = None,\n    tunning_config: Optional[TuningParams] = None,\n    peft_config: Optional[PEFTParams] = None,\n    processor_config: Optional[ProcessorParams] = None,\n    finetune_mode: Optional[str] = None,\n    tunning_strategy: Optional[str] = None,\n    instance_type: Optional[str] = None\n) -&gt; str:\n\n    \"\"\"\n    Train a Classic ML model or a Tabular Foundational model.\n\n    This method is the single entry-point to train models in Lexsi. It applies the full\n    training pipeline end-to-end:\n\n    - selects and prepares data (filtering, sampling, feature handling, imbalance handling)\n    - applies preprocessing / feature engineering (optional)\n    - trains either a **classic ML model** or a **tabular foundation model**\n    - optionally performs hyperparameter tuning (classic or foundational depending on strategy)\n    - optionally performs fine-tuning / PEFT for foundation models\n    - produces a trained model artifact and returns its identifier/reference\n\n    :param model_type: Name of the model to train. Must be one of the supported following values\n        **Classic ML models**\n        - ``XGBoost``\n        - ``LGBoost``\n        - ``CatBoost``\n        - ``RandomForest``\n        - ``SGD``\n        - ``LogisticRegression``\n        - ``LinearRegression``\n        - ``GaussianNaiveBayes``\n\n    **Tabular foundation models (TabTune wrapper)**\n        - ``TabPFN``\n        - ``TabICL``\n        - ``TabDPT``\n        - ``OrionMSP``\n        - ``OrionBix``\n        - ``Mitra``\n        - ``ContextTab``\n    :type model_type: str\n\n    :param data_config: Dataset selection + training-time data behavior such as:\n        tag-based filtering, train/test tags, feature exclusion/encodings, optional Optuna usage,\n        sampling fractions, and explainability controls.\n        See :class:`lexsi_sdk.common.types.DataConfig`.\n    :type data_config: DataConfig | None\n\n    :param processor_config: Optional preprocessing / feature engineering configuration applied\n        before training (e.g., imputation, scaling, resampling strategy).\n        See :class:`lexsi_sdk.common.types.ProcessorParams`.\n    :type processor_config: ProcessorParams | None\n\n    :param model_config: Model hyperparameters for the chosen ``model_type``.\n        Use the matching config type:\n\n        - For ``XGBoost``: :class:`lexsi_sdk.common.types.XGBoostParams`\n        - For ``LGBoost``: :class:`lexsi_sdk.common.types.LightGBMParams`\n        - For ``CatBoost``: :class:`lexsi_sdk.common.types.CatBoostParams`\n        - For ``RandomForest``: :class:`lexsi_sdk.common.types.RandomForestParams`\n        - For foundation models (e.g., ``TabPFN``, ``TabICL``, ...):\n        :class:`lexsi_sdk.common.types.FoundationalModelParams`\n\n        For models like ``SGD``, ``LogisticRegression``, ``LinearRegression``,\n        ``GaussianNaiveBayes``, parameters may be taken from defaults in the wrapper if not\n        explicitly exposed through a typed config.\n    :type model_config: XGBoostParams | LightGBMParams | CatBoostParams | RandomForestParams | FoundationalModelParams | None\n\n    :param tunning_config: Optional tuning / adaptation loop configuration.\n        Used for episodic / few-shot / fine-tuning style training and some tuning strategies.\n        See :class:`lexsi_sdk.common.types.TuningParams`.\n    :type tunning_config: TuningParams | None\n\n    :param tuning_strategy: Training / fine-tuning strategy to apply.\n\n    Supported values:\n\n        - ``\"inference\"``:\n        Zero-shot inference only. No training or parameter updates are performed.\n\n        - ``\"base-ft\"``:\n        Full fine-tuning of all model parameters.\n\n        - ``\"peft\"``:\n        Parameter-efficient fine-tuning using LoRA adapters.\n        Requires ``peft_config`` and a foundation model that supports PEFT.\n\n        - ``\"finetune\"``:\n        Alias for ``\"base-ft\"``.\n\n    If not provided, the default behavior depends on the selected ``model_type``.\n    :type tuning_strategy: str | None\n\n    :param finetune_mode: Fine-tuning mode for episodic / foundation models.\n\n    Supported values:\n\n        - ``\"meta-learning\"``:\n        Episodic meta-learning mode (default). Uses support/query splits\n        and episodic optimization.\n\n        - ``\"sft\"``:\n        Standard supervised fine-tuning using conventional batches.\n\n    This parameter is applicable only to episodic or foundational models and\n    is ignored for classic ML models.\n    :type finetune_mode: str | None\n\n    :param peft_config: Parameter-efficient fine-tuning configuration (e.g., LoRA params).\n        Used only when ``finetune_mode=\"peft\"`` and the selected foundation model supports PEFT.\n        See :class:`lexsi_sdk.common.types.PEFTParams`.\n    :type peft_config: PEFTParams | None\n\n    :param instance_type: Compute instance used for training (CPU/GPU).\n        This is used by the computation layer to select the appropriate runtime environment we have CPU/GPU runtime with small medium large with 2x 3x nomeclature with GPU T4 and A10G .\n        Example values: ``\"small\"``, ``\"medium\"``,``\"large\"``, ``\"2xsmall\"``, ``\"T4.small\"``, ``\"A10G.xmedium\"``\n    :type instance_type: str | None\n\n    :return: Identifier or reference for the trained model artifact (e.g., model ID / artifact URI).\n    :rtype: str\n    \"\"\"\n\n\n    project_config = self.config()\n\n    if project_config == \"Not Found\":\n        raise Exception(\"Upload files first\")\n\n    available_models, foundational_models = self.available_models()\n\n    Validate.value_against_list(\"model_type\", model_type, available_models)\n\n    all_unique_features = [\n        *project_config[\"metadata\"][\"feature_exclude\"],\n        *project_config[\"metadata\"][\"feature_include\"],\n    ]\n\n    if tunning_strategy != \"inference\" and instance_type:\n        custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n        available_custom_batch_servers = custom_batch_servers.get(\"details\", []) + custom_batch_servers.get(\"available_gpu_custom_servers\", [])\n        Validate.value_against_list(\n            \"instance_type\",\n            instance_type,\n            [\n                server[\"instance_name\"]\n                for server in available_custom_batch_servers\n            ],\n        )\n\n    if data_config:\n        if data_config.get(\"feature_exclude\"):\n            Validate.value_against_list(\n                \"feature_exclude\",\n                data_config[\"feature_exclude\"],\n                all_unique_features,\n            )\n\n        if data_config.get(\"tags\"):\n            available_tags = self.tags()\n            Validate.value_against_list(\"tags\", data_config[\"tags\"], available_tags)\n\n        if data_config.get(\"test_tags\"):\n            available_tags = self.tags()\n            Validate.value_against_list(\n                \"test_tags\", data_config[\"test_tags\"], available_tags\n            )\n\n        if data_config.get(\"feature_encodings\"):\n            Validate.value_against_list(\n                \"feature_encodings_feature\",\n                list(data_config[\"feature_encodings\"].keys()),\n                list(project_config[\"metadata\"][\"feature_encodings\"].keys()),\n            )\n            Validate.value_against_list(\n                \"feature_encodings_feature\",\n                list(data_config[\"feature_encodings\"].values()),\n                [\"labelencode\", \"countencode\", \"onehotencode\"],\n            )\n\n        if data_config.get(\"sample_percentage\"):\n            if (\n                data_config[\"sample_percentage\"] &lt; 0\n                or data_config[\"sample_percentage\"] &gt; 1\n            ):\n                raise Exception(\n                    \"Data sample percentage is invalid, select between 0 and 1\"\n                )\n\n        if data_config.get(\"explainability_sample_percentage\"):\n            if (\n                data_config[\"explainability_sample_percentage\"] &lt; 0\n                or data_config[\"explainability_sample_percentage\"] &gt; 1\n            ):\n                raise Exception(\n                    \"Explainability sample percentage is invalid, select between 0 and 1\"\n                )\n\n        if data_config.get(\"lime_explainability_iterations\"):\n            if (\n                data_config[\"lime_explainability_iterations\"] &lt; 1\n                or data_config[\"lime_explainability_iterations\"] &gt; 10000\n            ):\n                raise Exception(\n                    \"Lime explainability iterations is invalid, select between 1 and 10000\"\n                )\n\n        if data_config.get(\"explainability_method\"):\n            Validate.value_against_list(\n                \"explainability_method\",\n                data_config[\"explainability_method\"],\n                [\"shap\", \"lime\"],\n            )\n\n    if model_config:\n        model_params = self.api_client.get(MODEL_PARAMETERS_URI)\n        model_name = f\"{model_type}_{project_config['project_type']}\".lower()\n        model_parameters = model_params.get(model_name)\n\n        if model_parameters:\n\n            def validate_params(param_group, config_group):\n                \"\"\"Validate config values against model parameter constraints.\n                Checks select options and numeric min/max bounds, raising exceptions on invalid values.\n\n                :param param_group: Parameter definition dict (select/input types with constraints).\n                :param config_group: User-supplied config dict to validate against `param_group`.\n                :raises Exception: If any value violates the declared constraints.\n                \"\"\"\n                if config_group:\n                    for param_name, param_value in config_group.items():\n                        model_param = param_group.get(param_name)\n                        if not model_param:\n                            # raise Exception(\n                            #     f\"Invalid model config for {model_type} \\n {json.dumps(model_parameters)}\"\n                            # )\n                            continue\n\n                        param_type = model_param[\"type\"]\n\n                        if param_type == \"select\":\n                            Validate.value_against_list(\n                                param_name, param_value, model_param[\"value\"]\n                            )\n                        elif param_type == \"input\":\n                            if param_value &gt; model_param[\"max\"]:\n                                raise Exception(\n                                    f\"{param_name} value cannot be greater than {model_param['max']}\"\n                                )\n                            if param_value &lt; model_param[\"min\"]:\n                                raise Exception(\n                                    f\"{param_name} value cannot be less than {model_param['min']}\"\n                                )\n\n            if model_type in foundational_models:\n                validate_params(\n                    model_parameters.get(\"model_params\", {}), model_config\n                )\n                validate_params(\n                    model_parameters.get(\"tunning_params\", {}), tunning_config\n                )\n                validate_params(\n                    model_parameters.get(\"processor_params\", {}), processor_config\n                )\n                validate_params(\n                    model_parameters.get(\"peft_params\", {}), peft_config\n                )\n            else:\n                validate_params(model_parameters, model_config)\n    if finetune_mode:\n        Validate.value_against_list(\n            \"finetune_mode\",\n            finetune_mode,\n            [\"meta-learning\", \"sft\"],\n        )\n    if tunning_strategy:\n        Validate.value_against_list(\n            \"tunning_strategy\",\n            tunning_strategy,\n            [\"base-ft\", \"inference\", \"peft\", \"finetune\"],\n        )\n    data_conf = data_config or {}\n\n    feature_exclude = [\n        *data_conf.get(\"feature_exclude\", []),\n    ]\n\n    feature_include = [\n        feature for feature in all_unique_features if feature not in feature_exclude\n    ]\n\n    feature_encodings = (\n        data_conf.get(\"feature_encodings\")\n        or project_config[\"metadata\"][\"feature_encodings\"]\n    )\n\n    drop_duplicate_uid = (\n        data_conf.get(\"drop_duplicate_uid\")\n        or project_config[\"metadata\"][\"drop_duplicate_uid\"]\n    )\n\n    explainability_method = (\n        data_conf.get(\"explainability_method\")\n        or project_config[\"metadata\"][\"explainability_method\"]\n    )\n\n    tags = data_conf.get(\"tags\") or project_config[\"metadata\"][\"tags\"]\n    test_tags = (\n        data_conf.get(\"test_tags\") or project_config[\"metadata\"][\"test_tags\"] or []\n    )\n    use_optuna = (\n        data_conf.get(\"use_optuna\")\n        or project_config[\"metadata\"][\"use_optuna\"]\n        or False\n    )\n    handle_data_imbalance = (\n        data_conf.get(\"handle_data_imbalance\")\n        or project_config[\"metadata\"][\"handle_data_imbalance\"]\n        or False\n    )\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"project_type\": project_config[\"project_type\"],\n        \"unique_identifier\": project_config[\"unique_identifier\"],\n        \"true_label\": project_config[\"true_label\"],\n        \"metadata\": {\n            \"model_name\": model_type,\n            \"model_parameters\": model_config,\n            \"feature_include\": feature_include,\n            \"feature_exclude\": feature_exclude,\n            \"feature_encodings\": feature_encodings,\n            \"drop_duplicate_uid\": drop_duplicate_uid,\n            \"tags\": tags,\n            \"test_tags\": test_tags,\n            \"use_optuna\": use_optuna,\n            \"explainability_method\": explainability_method,\n            \"handle_data_imbalance\": handle_data_imbalance,\n        },\n        \"sample_percentage\": data_conf.get(\"sample_percentage\"),\n        \"explainability_sample_percentage\": data_conf.get(\n            \"explainability_sample_percentage\"\n        ),\n        \"lime_explainability_iterations\": data_conf.get(\n            \"lime_explainability_iterations\"\n        )\n    }\n\n    if tunning_config:\n        payload[\"metadata\"][\"tunning_parameters\"] = tunning_config\n    if peft_config:\n        payload[\"metadata\"][\"peft_parameters\"] = peft_config\n    if processor_config:\n        payload[\"metadata\"][\"processor_parameters\"] = processor_config\n    if finetune_mode:\n        payload[\"metadata\"][\"finetune_mode\"] = finetune_mode\n    if tunning_strategy:\n        payload[\"metadata\"][\"tunning_strategy\"] = tunning_strategy\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    print(\"Config :-\")\n    print(json.dumps(payload[\"metadata\"], indent=1))\n\n    res = self.api_client.post(TRAIN_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    print(\"\\nTraining Initiated\")\n    poll_events(self.api_client, self.project_name, res[\"event_id\"])\n\n    return \"Model Trained Successfully\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.train_synthetic_model","title":"train_synthetic_model","text":"<pre><code>train_synthetic_model(\n    model_name,\n    data_config={},\n    hyper_params={},\n    instance_type=\"shared\",\n)\n</code></pre> <p>Train synthetic model</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>model name ['GPT2', 'CTGAN']</p> required <code>data_config</code> <code>Optional[SyntheticDataConfig]</code> <p>config for the data { \"tags\": List[str] \"feature_exclude\": List[str] \"feature_include\": List[str] \"drop_duplicate_uid\": bool }, defaults to {}</p> <code>{}</code> <code>hyper_params</code> <code>Optional[SyntheticModelHyperParams]</code> <p>hyper parameters for the model. check param type and value range below, For GPT2 (Generative Pretrained Transformer) model - Works well on high dimensional tabular data, { \"batch_size\": int [1, 500] defaults to 100 \"early_stopping_patience\": int [1, 100], defaults to 10 \"early_stopping_threshold\": float [0.1, 100], defaults to 0.0001 \"epochs\": int [1, 150], defaults to 100 \"model_type\": \"tabular\", \"random_state\": int [1, 150], defaults to 1 \"tabular_config\": \"GPT2Config\", \"train_size\": float [0, 0.9] defaults to 0.8 } For CTGAN (Conditional Tabular GANs) model - Balances between training computation and dimensionality, { \"epochs\": int, [1, 150] defaults to 100 \"test_ratio\": float [0, 1] defaults to 0.2 } defaults to {}</p> <code>{}</code> <code>instance_type</code> <code>Optional[str]</code> <p>type of instance to run training for all available instances check xai.available_synthetic_custom_servers() defaults to shared</p> <code>'shared'</code> <p>Returns:</p> Type Description <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def train_synthetic_model(\n    self,\n    model_name: str,\n    data_config: Optional[SyntheticDataConfig] = {},\n    hyper_params: Optional[SyntheticModelHyperParams] = {},\n    instance_type: Optional[str] = \"shared\",\n):\n    \"\"\"Train synthetic model\n\n    :param model_name: model name ['GPT2', 'CTGAN']\n    :param data_config: config for the data\n        {\n            \"tags\": List[str]\n            \"feature_exclude\": List[str]\n            \"feature_include\": List[str]\n            \"drop_duplicate_uid\": bool\n        },\n        defaults to {}\n    :param hyper_params: hyper parameters for the model. check param type and value range below,\n        For GPT2 (Generative Pretrained Transformer) model - Works well on high dimensional tabular data,\n        {\n            \"batch_size\": int [1, 500] defaults to 100\n            \"early_stopping_patience\": int [1, 100], defaults to 10\n            \"early_stopping_threshold\": float [0.1, 100], defaults to 0.0001\n            \"epochs\": int [1, 150], defaults to 100\n            \"model_type\": \"tabular\",\n            \"random_state\": int [1, 150], defaults to 1\n            \"tabular_config\": \"GPT2Config\",\n            \"train_size\": float [0, 0.9] defaults to 0.8\n        }\n        For CTGAN (Conditional Tabular GANs) model - Balances between training computation and dimensionality,\n        {\n            \"epochs\": int, [1, 150] defaults to 100\n            \"test_ratio\": float [0, 1] defaults to 0.2\n        }\n        defaults to {}\n    :param instance_type: type of instance to run training\n        for all available instances check xai.available_synthetic_custom_servers()\n        defaults to shared\n\n    :return: response\n    \"\"\"\n\n    project_config = self.config()\n\n    if project_config == \"Not Found\":\n        raise Exception(\"Upload files first\")\n\n    project_config = project_config[\"metadata\"]\n\n    if instance_type != \"shared\":\n        available_servers = self.api_client.get(\n            AVAILABLE_SYNTHETIC_CUSTOM_SERVERS_URI\n        )[\"details\"]\n        servers = list(\n            map(lambda instance: instance[\"instance_name\"], available_servers)\n        )\n        Validate.value_against_list(\"instance_type\", instance_type, servers)\n\n    all_models_param = self.get_synthetic_model_params()\n\n    try:\n        model_params = all_models_param[model_name]\n    except KeyError as e:\n        availabel_models = list(all_models_param.keys())\n        Validate.value_against_list(\"model\", [model_name], availabel_models)\n\n    # validate and prepare data config\n    data_config[\"model_name\"] = model_name\n\n    available_tags = self.tags()\n    tags = data_config.get(\"tags\", available_tags)\n\n    Validate.value_against_list(\"tag\", tags, available_tags)\n\n    feature_exclude = data_config.get(\n        \"feature_exclude\", project_config[\"feature_exclude\"]\n    )\n\n    Validate.value_against_list(\n        \"feature_exclude\", feature_exclude, project_config[\"avaialble_options\"]\n    )\n\n    feature_include = data_config.get(\n        \"feature_include\", project_config[\"feature_include\"]\n    )\n\n    Validate.value_against_list(\n        \"feature_include\",\n        feature_include,\n        project_config[\"avaialble_options\"],\n    )\n\n    drop_duplicate_uid = data_config.get(\n        \"drop_duplicate_uid\", project_config[\"drop_duplicate_uid\"]\n    )\n\n    SYNTHETIC_MODELS_DEFAULT_HYPER_PARAMS[model_name].update(hyper_params)\n    hyper_params = SYNTHETIC_MODELS_DEFAULT_HYPER_PARAMS[model_name]\n\n    # validate model hyper parameters\n    for key, value in hyper_params.items():\n        model_param = model_params.get(key, None)\n\n        if model_param:\n            if model_param[\"type\"] == \"input\":\n                if model_param[\"value\"] == \"int\":\n                    if not isinstance(value, int):\n                        raise Exception(f\"{key} value should be integer\")\n                elif model_param[\"value\"] == \"float\":\n                    if not isinstance(value, float):\n                        raise Exception(f\"{key} value should be float\")\n\n                    if value &lt; model_param[\"min\"] or value &gt; model_param[\"max\"]:\n                        raise Exception(\n                            f\"{key} value should be between {model_param['min']} and {model_param['max']}\"\n                        )\n                elif model_param[\"type\"] == \"select\":\n                    Validate.value_against_list(\n                        \"value\", [value], model_param[\"value\"]\n                    )\n\n    print(f\"Using data config: {json.dumps(data_config, indent=4)}\")\n    print(f\"Using hyper params: {json.dumps(hyper_params, indent=4)}\")\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n        \"instance_type\": instance_type,\n        \"metadata\": {\n            \"model_name\": model_name,\n            \"tags\": tags,\n            \"feature_exclude\": feature_exclude,\n            \"feature_include\": feature_include,\n            \"feature_actual_used\": [],\n            \"drop_duplicate_uid\": drop_duplicate_uid,\n            \"model_parameters\": hyper_params,\n        },\n    }\n\n    res = self.api_client.post(TRAIN_SYNTHETIC_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    print(\"Training initiated...\")\n    poll_events(self.api_client, self.project_name, res[\"event_id\"])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_config","title":"update_config","text":"<pre><code>update_config(config)\n</code></pre> <p>updates config for the project</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>DataConfig</code> <p>updated config { \"tags\": List[str] \"feature_exclude\": List[str] \"feature_encodings\": Dict[str, str]   # {\"feature_name\":\"labelencode | countencode\"} \"drop_duplicate_uid\": bool },</p> required <p>Returns:</p> Type Description <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_config(self, config: DataConfig):\n    \"\"\"updates config for the project\n\n    :param config: updated config\n                {\n                    \"tags\": List[str]\n                    \"feature_exclude\": List[str]\n                    \"feature_encodings\": Dict[str, str]   # {\"feature_name\":\"labelencode | countencode\"}\n                    \"drop_duplicate_uid\": bool\n                },\n\n    :return: response\n    \"\"\"\n    if not config:\n        raise Exception(\"Please upload config\")\n\n    project_config = self.config()\n\n    if project_config == \"Not Found\":\n        raise Exception(\"Config does not exist, please upload files first\")\n\n    available_tags = self.available_tags()\n\n    if config.get(\"tags\"):\n        Validate.value_against_list(\n            \"tags\", config[\"tags\"], available_tags.get(\"user_tags\")\n        )\n\n    all_unique_features = [\n        *project_config[\"metadata\"][\"feature_exclude\"],\n        *project_config[\"metadata\"][\"feature_include\"],\n    ]\n\n    if config.get(\"feature_exclude\"):\n        Validate.value_against_list(\n            \"feature_exclude\",\n            config[\"feature_exclude\"],\n            all_unique_features,\n        )\n\n    if config.get(\"feature_encodings\"):\n        Validate.value_against_list(\n            \"feature_encodings_feature\",\n            list(config[\"feature_encodings\"].keys()),\n            list(project_config[\"metadata\"][\"feature_encodings\"].keys()),\n        )\n        Validate.value_against_list(\n            \"feature_encodings_feature\",\n            list(config[\"feature_encodings\"].values()),\n            [\"labelencode\", \"countencode\"],\n        )\n\n    if config.get(\"feature_exclude\") is None:\n        feature_exclude = project_config[\"metadata\"][\"feature_exclude\"]\n    else:\n        feature_exclude = config.get(\"feature_exclude\", [])\n\n    feature_include = [\n        feature for feature in all_unique_features if feature not in feature_exclude\n    ]\n\n    feature_encodings = (\n        config.get(\"feature_encodings\")\n        or project_config[\"metadata\"][\"feature_encodings\"]\n    )\n\n    drop_duplicate_uid = (\n        config.get(\"drop_duplicate_uid\")\n        or project_config[\"metadata\"][\"drop_duplicate_uid\"]\n    )\n\n    tags = config.get(\"tags\") or project_config[\"metadata\"][\"tags\"]\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"project_type\": project_config[\"project_type\"],\n        \"unique_identifier\": project_config[\"unique_identifier\"],\n        \"true_label\": project_config[\"true_label\"],\n        \"pred_label\": project_config.get(\"pred_label\"),\n        \"config_update\": True,\n        \"metadata\": {\n            \"feature_include\": feature_include,\n            \"feature_exclude\": feature_exclude,\n            \"feature_encodings\": feature_encodings,\n            \"drop_duplicate_uid\": drop_duplicate_uid,\n            \"tags\": tags,\n        },\n    }\n\n    print(\"Config :-\")\n    print(json.dumps(payload[\"metadata\"], indent=1))\n\n    res = self.api_client.post(TRAIN_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to update config\"))\n\n    poll_events(self.api_client, self.project_name, res.get(\"event_id\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_inference_model_status","title":"update_inference_model_status","text":"<pre><code>update_inference_model_status(model_name, activate)\n</code></pre> <p>Sets the model to active for inferencing</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>name of the model</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_inference_model_status(self, model_name: str, activate: bool) -&gt; str:\n    \"\"\"Sets the model to active for inferencing\n\n    :param model_name: name of the model\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n        \"activate\": activate,\n    }\n\n    res = self.api_client.post(UPDATE_ACTIVE_INFERENCE_MODEL_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_observation","title":"update_observation","text":"<pre><code>update_observation(\n    observation_id,\n    observation_name,\n    status=None,\n    expression=None,\n    statement=None,\n    linked_features=None,\n)\n</code></pre> <p>Updates Observation</p> <p>Parameters:</p> Name Type Description Default <code>observation_id</code> <code>str</code> <p>id of observation</p> required <code>observation_name</code> <code>str</code> <p>name of observation</p> required <code>status</code> <code>Optional[str]</code> <p>status of observation [\"active\",\"inactive\"]</p> <code>None</code> <code>expression</code> <code>Optional[str]</code> <p>new expression for observation, defaults to None Eg: BldgType !== Duplex and Neighborhood == OldTown Ensure that the left side of the conditional operator corresponds to a feature name, and the right side represents the comparison value for the feature. Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\" You can perform comparisons between two or more features using logical operators such as \"and\" or \"or.\" Additionally, you have the option to use parentheses () to group and prioritize certain conditions.</p> <code>None</code> <code>statement</code> <code>Optional[str]</code> <p>new statement for observation, defaults to None Eg: The building type is {BldgType} the content inside the curly brackets represents the feature name</p> <code>None</code> <code>linked_features</code> <code>Optional[List[str]]</code> <p>new linked features for observation, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_observation(\n    self,\n    observation_id: str,\n    observation_name: str,\n    status: Optional[str] = None,\n    expression: Optional[str] = None,\n    statement: Optional[str] = None,\n    linked_features: Optional[List[str]] = None,\n) -&gt; str:\n    \"\"\"Updates Observation\n\n    :param observation_id: id of observation\n    :param observation_name: name of observation\n    :param status: status of observation [\"active\",\"inactive\"]\n    :param expression: new expression for observation, defaults to None\n        Eg: BldgType !== Duplex and Neighborhood == OldTown\n            Ensure that the left side of the conditional operator corresponds to a feature name,\n            and the right side represents the comparison value for the feature.\n            Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\"\n            You can perform comparisons between two or more features using\n            logical operators such as \"and\" or \"or.\"\n            Additionally, you have the option to use parentheses () to group and prioritize certain conditions.\n    :param statement: new statement for observation, defaults to None\n        Eg: The building type is {BldgType}\n            the content inside the curly brackets represents the feature name\n    :param linked_features: new linked features for observation, defaults to None\n    :return: response\n    \"\"\"\n    if not status and not expression and not statement and not linked_features:\n        raise Exception(\"update parameters for observation not passed\")\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"observation_id\": observation_id,\n        \"observation_name\": observation_name,\n        \"update_keys\": {},\n    }\n\n    observation_params = self.api_client.get(\n        f\"{GET_OBSERVATION_PARAMS_URI}?project_name={self.project_name}\"\n    )\n\n    if expression:\n        Validate.string(\"expression\", expression)\n        configuration, expression = build_expression(expression)\n        validate_configuration(\n            configuration,\n            observation_params[\"details\"],\n            self.project_name,\n            self.api_client,\n        )\n        payload[\"update_keys\"][\"configuration\"] = configuration\n        payload[\"update_keys\"][\"metadata\"] = {\"expression\": expression}\n\n    if linked_features:\n        Validate.value_against_list(\n            \"linked_feature\",\n            linked_features,\n            list(observation_params[\"details\"][\"features\"].keys()),\n        )\n        payload[\"update_keys\"][\"linked_features\"] = linked_features\n\n    if statement:\n        Validate.string(\"statement\", statement)\n        payload[\"update_keys\"][\"statement\"] = [statement]\n\n    if status:\n        Validate.value_against_list(\"status\", status, [\"active\", \"inactive\"])\n        payload[\"update_keys\"][\"status\"] = status\n\n    res = self.api_client.post(UPDATE_OBSERVATION_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Observation Updated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_policy","title":"update_policy","text":"<pre><code>update_policy(\n    policy_id,\n    policy_name,\n    status=None,\n    expression=None,\n    statement=None,\n    decision=None,\n    input=None,\n)\n</code></pre> <p>Updates Policy</p> <p>Parameters:</p> Name Type Description Default <code>policy_id</code> <code>str</code> <p>id of policy</p> required <code>policy_name</code> <code>str</code> <p>name of policy</p> required <code>status</code> <code>Optional[str]</code> <p>status of policy [\"active\",\"inactive\"]</p> <code>None</code> <code>expression</code> <code>Optional[str]</code> <p>new expression for policy, defaults to None Eg: BldgType !== Duplex and Neighborhood == OldTown Ensure that the left side of the conditional operator corresponds to a feature name, and the right side represents the comparison value for the feature. Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\" You can perform comparisons between two or more features using logical operators such as \"and\" or \"or.\" Additionally, you have the option to use parentheses () to group and prioritize certain conditions.</p> <code>None</code> <code>statement</code> <code>Optional[str]</code> <p>new statment for policy, defaults to None Eg: The building type is {BldgType} the content inside the curly brackets represents the feature name</p> <code>None</code> <code>decision</code> <code>Optional[str]</code> <p>new decision for policy, defaults to None</p> <code>None</code> <code>input</code> <code>Optional[str]</code> <p>custom input for the decision if input selected for decision of policy</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_policy(\n    self,\n    policy_id: str,\n    policy_name: str,\n    status: Optional[str] = None,\n    expression: Optional[str] = None,\n    statement: Optional[str] = None,\n    decision: Optional[str] = None,\n    input: Optional[str] = None,\n) -&gt; str:\n    \"\"\"Updates Policy\n\n    :param policy_id: id of policy\n    :param policy_name: name of policy\n    :param status: status of policy [\"active\",\"inactive\"]\n    :param expression: new expression for policy, defaults to None\n        Eg: BldgType !== Duplex and Neighborhood == OldTown\n            Ensure that the left side of the conditional operator corresponds to a feature name,\n            and the right side represents the comparison value for the feature.\n            Valid conditional operators include \"!==,\" \"==,\" \"&gt;,\", and \"&lt;.\"\n            You can perform comparisons between two or more features using\n            logical operators such as \"and\" or \"or.\"\n            Additionally, you have the option to use parentheses () to group and prioritize certain conditions.\n    :param statement: new statment for policy, defaults to None\n        Eg: The building type is {BldgType}\n            the content inside the curly brackets represents the feature name\n    :param decision: new decision for policy, defaults to None\n    :param input: custom input for the decision if input selected for decision of policy\n    :return: response\n    \"\"\"\n    if not status and not expression and not statement and not decision:\n        raise Exception(\"update parameters for policy not passed\")\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"policy_id\": policy_id,\n        \"policy_name\": policy_name,\n        \"update_keys\": {},\n    }\n\n    policy_params = self.api_client.get(\n        f\"{GET_POLICY_PARAMS_URI}?project_name={self.project_name}\"\n    )\n\n    if expression:\n        Validate.string(\"expression\", expression)\n        configuration, expression = build_expression(expression)\n        validate_configuration(\n            configuration,\n            policy_params[\"details\"],\n            self.project_name,\n            self.api_client,\n        )\n        payload[\"update_keys\"][\"configuration\"] = configuration\n        payload[\"update_keys\"][\"metadata\"] = {\"expression\": expression}\n\n    if statement:\n        Validate.string(\"statement\", statement)\n        payload[\"update_keys\"][\"statement\"] = [statement]\n\n    if status:\n        Validate.value_against_list(\"status\", status, [\"active\", \"inactive\"])\n        payload[\"update_keys\"][\"status\"] = status\n\n    if decision:\n        Validate.value_against_list(\n            \"decision\",\n            decision,\n            list(policy_params[\"details\"][\"decision\"].values())[0],\n        )\n        if decision == \"input\":\n            Validate.string(\"Decision input\", input)\n        payload[\"update_keys\"][\"decision\"] = (\n            input if decision == \"input\" else decision\n        )\n\n    res = self.api_client.post(UPDATE_POLICY_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Policy Updated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_server","title":"update_server","text":"<pre><code>update_server(server_type)\n</code></pre> <p>Update the dedicated server for the project by specifying a new instance type.</p> <p>Parameters:</p> Name Type Description Default <code>server_type</code> <code>str</code> <p>dedicated instance to run workloads for all available instances check xai.available_custom_servers()</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_server(self, server_type: str) -&gt; str:\n    \"\"\"Update the dedicated server for the project by specifying a new instance type.\n    :param server_type: dedicated instance to run workloads\n        for all available instances check xai.available_custom_servers()\n\n    :return: response\n    \"\"\"\n    custom_servers = self.api_client.get(AVAILABLE_CUSTOM_SERVERS_URI)\n    Validate.value_against_list(\n        \"server_type\",\n        server_type,\n        [server[\"name\"] for server in custom_servers],\n    )\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"update_project\": {\n                \"project_name\": self.user_project_name,\n                \"instance_type\": server_type,\n            },\n            \"update_operational_hours\": {},\n        },\n    }\n\n    res = self.api_client.post(UPDATE_PROJECT_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return \"Server Updated\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_synthetic_prompt","title":"update_synthetic_prompt","text":"<pre><code>update_synthetic_prompt(prompt_id, status)\n</code></pre> <p>update synthetic prompt</p> <p>Parameters:</p> Name Type Description Default <code>prompt_id</code> <code>str</code> <p>prompt id</p> required <code>activate</code> <p>True or False</p> required <p>Returns:</p> Type Description <code>str</code> <p>response message</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_synthetic_prompt(self, prompt_id: str, status: str) -&gt; str:\n    \"\"\"update synthetic prompt\n\n    :param prompt_id: prompt id\n    :param activate: True or False\n    :raises Exception: _description_\n    :raises Exception: _description_\n    :return: response message\n    \"\"\"\n    if status not in [\"active\", \"inactive\"]:\n        raise Exception(\n            \"Invalid status value. Pick a valid value from ['active', 'inactive'].\"\n        )\n\n    payload = {\n        \"delete\": False,\n        \"project_name\": self.project_name,\n        \"prompt_id\": prompt_id,\n        \"update_keys\": {\"status\": status},\n    }\n\n    res = self.api_client.post(UPDATE_SYNTHETIC_PROMPT_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    return \"Synthetic prompt updated successfully.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.update_user_access_for_project","title":"update_user_access_for_project","text":"<pre><code>update_user_access_for_project(email, role)\n</code></pre> <p>Update the role of a user within the project. Accepts an email and new role and returns a response.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>str</code> <p>user email</p> required <code>role</code> <code>str</code> <p>user role</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def update_user_access_for_project(self, email: str, role: str) -&gt; str:\n    \"\"\"Update the role of a user within the project. Accepts an email and new role and returns a response.\n\n    :param email: user email\n    :param role: user role\n    :return: response\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"modify_req\": {\n            \"update_user_project\": {\n                \"email\": email,\n                \"role\": role,\n            },\n        },\n    }\n    res = self.api_client.post(UPDATE_PROJECT_URI, payload)\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_data","title":"upload_data","text":"<pre><code>upload_data(\n    data,\n    tag,\n    model=None,\n    model_name=None,\n    model_architecture=None,\n    model_type=None,\n    config=None,\n    model_config=None,\n    tunning_config=None,\n    peft_config=None,\n    processor_config=None,\n    finetune_mode=None,\n    tunning_strategy=None,\n    instance_type=\"shared\",\n)\n</code></pre> <p>Uploads data for the current project</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | DataFrame</code> <p>file path | dataframe to be uploaded</p> required <code>tag</code> <code>str</code> <p>tag for data</p> required <code>config</code> <code>Optional[ProjectConfig]</code> <p>project config { \"project_type\": \"\", \"unique_identifier\": \"\", \"true_label\": \"\", \"pred_label\": \"\", \"feature_exclude\": [], \"drop_duplicate_uid: \"\", \"handle_errors\": False, \"handle_data_imbalance\": False, # SMOTE sampling \"feature_encodings\": Dict[str, str]   # {\"feature_name\":\"labelencode | countencode | onehotencode\"} }, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_data(\n    self,\n    data: str | pd.DataFrame,\n    tag: str,\n    model: Optional[str] = None,\n    model_name: Optional[str] = None,\n    model_architecture: Optional[str] = None,\n    model_type: Optional[str] = None,\n    config: Optional[ProjectConfig] = None,\n    model_config: Optional[dict] = None,\n    tunning_config: Optional[dict] = None,\n    peft_config: Optional[dict] = None,\n    processor_config: Optional[dict] = None,\n    finetune_mode: Optional[dict] = None,\n    tunning_strategy: Optional[str] = None,\n    instance_type: Optional[str] = \"shared\"\n) -&gt; str:\n    \"\"\"Uploads data for the current project\n    :param data: file path | dataframe to be uploaded\n    :param tag: tag for data\n    :param config: project config\n            {\n                \"project_type\": \"\",\n                \"unique_identifier\": \"\",\n                \"true_label\": \"\",\n                \"pred_label\": \"\",\n                \"feature_exclude\": [],\n                \"drop_duplicate_uid: \"\",\n                \"handle_errors\": False,\n                \"handle_data_imbalance\": False, # SMOTE sampling\n                \"feature_encodings\": Dict[str, str]   # {\"feature_name\":\"labelencode | countencode | onehotencode\"}\n            },\n            defaults to None\n    :return: response\n    \"\"\"\n\n    def build_upload_data(data):\n        \"\"\"Build a multipart-upload payload from a file path or DataFrame.\n        Converts DataFrames to an in-memory CSV buffer and returns a `(filename, bytes)` tuple.\n\n        :param data: Local file path or a pandas DataFrame.\n        :return: A file handle (path input) or `(filename, bytes)` tuple (DataFrame input).\n        \"\"\"\n        if isinstance(data, str):\n            file = open(data, \"rb\")\n            return file\n        elif isinstance(data, pd.DataFrame):\n            csv_buffer = io.BytesIO()\n            data.to_csv(csv_buffer, index=False, encoding=\"utf-8\")\n            csv_buffer.seek(0)\n            file_name = f\"{tag}_sdk_{datetime.now().replace(microsecond=0)}.csv\"\n            file = (file_name, csv_buffer.getvalue())\n            return file\n        else:\n            raise Exception(\"Invalid Data Type\")\n\n    def upload_file_and_return_path(data, data_type, tag=None) -&gt; str:\n        \"\"\"Upload a data/model artifact to Lexsi file storage.\n        Returns the server-side `filepath` that other project APIs reference.\n\n        :param data: File path or DataFrame to upload.\n        :param data_type: Upload type such as `data`, `model`, etc.\n        :param tag: Optional tag to associate with the upload.\n        :return: Server-side filepath for the uploaded artifact.\"\"\"\n        files = {\"in_file\": build_upload_data(data)}\n        res = self.api_client.file(\n            f\"{UPLOAD_DATA_FILE_URI}?project_name={self.project_name}&amp;data_type={data_type}&amp;tag={tag}\",\n            files,\n        )\n\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    project_config = self.config()\n\n    if project_config == \"Not Found\":\n        if self.metadata.get(\"modality\") == \"image\":\n            if (\n                not model\n                or not model_architecture\n                or not model_type\n                or not model_name\n            ):\n                raise Exception(\"Model details is required for Image project type\")\n\n            uploaded_path = upload_file_and_return_path(data, \"data\", tag)\n\n            model_uploaded_path = upload_file_and_return_path(model, \"model\")\n\n            payload = {\n                \"project_name\": self.project_name,\n                \"project_type\": self.metadata.get(\"project_type\"),\n                \"metadata\": {\n                    \"path\": uploaded_path,\n                    \"model_name\": model_name,\n                    \"model_path\": model_uploaded_path,\n                    \"model_architecture\": model_architecture,\n                    \"model_type\": model_type,\n                    \"tag\": tag,\n                    \"tags\": [tag],\n                },\n            }\n\n        if self.metadata.get(\"modality\") == \"tabular\":\n            if not config:\n                config = {\n                    \"project_type\": \"\",\n                    \"unique_identifier\": \"\",\n                    \"true_label\": \"\",\n                    \"pred_label\": \"\",\n                    \"feature_exclude\": [],\n                    \"drop_duplicate_uid\": False,\n                    \"handle_errors\": False,\n                    \"handle_data_imbalance\": False,\n                }\n                raise Exception(\n                    f\"Project Config is required, since no config is set for project \\n {json.dumps(config,indent=1)}\"\n                )\n\n            Validate.check_for_missing_keys(\n                config, [\"project_type\", \"unique_identifier\", \"true_label\"]\n            )\n\n            Validate.value_against_list(\n                \"project_type\", config, [\"classification\", \"regression\"]\n            )\n\n            uploaded_path = upload_file_and_return_path(data, \"data\", tag)\n\n            file_info = self.api_client.post(\n                UPLOAD_DATA_FILE_INFO_URI, {\"path\": uploaded_path}\n            )\n\n            column_names = file_info.get(\"details\").get(\"column_names\")\n\n            Validate.value_against_list(\n                \"unique_identifier\",\n                config[\"unique_identifier\"],\n                column_names,\n                lambda: self.delete_file(uploaded_path),\n            )\n\n            if config.get(\"feature_exclude\"):\n                Validate.value_against_list(\n                    \"feature_exclude\",\n                    config[\"feature_exclude\"],\n                    column_names,\n                    lambda: self.delete_file(uploaded_path),\n                )\n\n            feature_exclude = [\n                config[\"unique_identifier\"],\n                config[\"true_label\"],\n                *config.get(\"feature_exclude\", []),\n            ]\n\n            feature_include = [\n                feature\n                for feature in column_names\n                if feature not in feature_exclude\n            ]\n\n            feature_encodings = config.get(\"feature_encodings\", {})\n            if feature_encodings:\n                Validate.value_against_list(\n                    \"feature_encodings_feature\",\n                    list(feature_encodings.keys()),\n                    column_names,\n                )\n                Validate.value_against_list(\n                    \"feature_encodings_feature\",\n                    list(feature_encodings.values()),\n                    [\"labelencode\", \"countencode\", \"onehotencode\"],\n                )\n\n            payload = {\n                \"project_name\": self.project_name,\n                \"project_type\": config[\"project_type\"],\n                \"unique_identifier\": config[\"unique_identifier\"],\n                \"true_label\": config[\"true_label\"],\n                \"pred_label\": config.get(\"pred_label\"),\n                \"metadata\": {\n                    \"path\": uploaded_path,\n                    \"tag\": tag,\n                    \"tags\": [tag],\n                    \"drop_duplicate_uid\": config.get(\"drop_duplicate_uid\"),\n                    \"handle_errors\": config.get(\"handle_errors\", False),\n                    \"feature_exclude\": feature_exclude,\n                    \"feature_include\": feature_include,\n                    \"feature_encodings\": feature_encodings,\n                    \"feature_actual_used\": [],\n                    \"handle_data_imbalance\": config.get(\n                        \"handle_data_imbalance\", False\n                    ),\n                },\n                # \"gpu\": gpu,\n                \"instance_type\": instance_type,\n                \"sample_percentage\": config.get(\"sample_percentage\", None),\n            }\n            if config.get(\"model_name\"):\n                payload[\"metadata\"][\"model_name\"] = config.get(\"model_name\")\n\n        if config.get(\"explainability_method\"):\n            payload[\"metadata\"][\"explainability_method\"] = config.get(\n                \"explainability_method\"\n            )\n        if model_config:\n            payload[\"metadata\"][\"model_parameters\"] = model_config\n        if tunning_config:\n            payload[\"metadata\"][\"tunning_parameters\"] = tunning_config\n        if peft_config:\n            payload[\"metadata\"][\"peft_parameters\"] = peft_config\n        if processor_config:\n            payload[\"metadata\"][\"processor_parameters\"] = processor_config\n        if finetune_mode:\n            payload[\"metadata\"][\"finetune_mode\"] = finetune_mode\n        if tunning_strategy:\n            payload[\"metadata\"][\"tunning_strategy\"] = tunning_strategy\n        res = self.api_client.post(UPLOAD_DATA_WITH_CHECK_URI, payload)\n\n        if not res[\"success\"]:\n            self.delete_file(uploaded_path)\n            raise Exception(res.get(\"details\"))\n        try:\n            poll_events(self.api_client, self.project_name, res[\"event_id\"])\n        except Exception as e:\n            self.delete_file(uploaded_path)\n            raise e\n        return res.get(\"details\")\n\n    if project_config != \"Not Found\" and config:\n        raise Exception(\"Config already exists, please remove config\")\n\n    uploaded_path = upload_file_and_return_path(data, \"data\", tag)\n\n    payload = {\n        \"path\": uploaded_path,\n        \"tag\": tag,\n        \"type\": \"data\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_data_dataconnectors","title":"upload_data_dataconnectors","text":"<pre><code>upload_data_dataconnectors(\n    data_connector_name,\n    tag,\n    model_path=None,\n    model_name=None,\n    model_architecture=None,\n    model_type=None,\n    bucket_name=None,\n    file_path=None,\n    config=None,\n)\n</code></pre> <p>Uploads data for the current project with data connectors</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>name of the data connector</p> required <code>tag</code> <code>str</code> <p>tag for data</p> required <code>bucket_name</code> <code>Optional[str]</code> <p>if data connector has buckets # Example: s3/gcs buckets</p> <code>None</code> <code>file_path</code> <code>Optional[str]</code> <p>filepath from the bucket for the data to read</p> <code>None</code> <code>config</code> <code>Optional[ProjectConfig]</code> <p>project config { \"project_type\": \"\", \"unique_identifier\": \"\", \"true_label\": \"\", \"pred_label\": \"\", \"feature_exclude\": [], \"drop_duplicate_uid: \"\", \"handle_errors\": False, \"feature_encodings\": Dict[str, str]   # {\"feature_name\":\"labelencode | countencode | onehotencode\"} }, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_data_dataconnectors(\n    self,\n    data_connector_name: str,\n    tag: str,\n    model_path: Optional[str] = None,\n    model_name: Optional[str] = None,\n    model_architecture: Optional[str] = None,\n    model_type: Optional[str] = None,\n    bucket_name: Optional[str] = None,\n    file_path: Optional[str] = None,\n    config: Optional[ProjectConfig] = None,\n) -&gt; str:\n    \"\"\"Uploads data for the current project with data connectors\n    :param data_connector_name: name of the data connector\n    :param tag: tag for data\n    :param bucket_name: if data connector has buckets # Example: s3/gcs buckets\n    :param file_path: filepath from the bucket for the data to read\n    :param config: project config\n            {\n                \"project_type\": \"\",\n                \"unique_identifier\": \"\",\n                \"true_label\": \"\",\n                \"pred_label\": \"\",\n                \"feature_exclude\": [],\n                \"drop_duplicate_uid: \"\",\n                \"handle_errors\": False,\n                \"feature_encodings\": Dict[str, str]   # {\"feature_name\":\"labelencode | countencode | onehotencode\"}\n            },\n            defaults to None\n    :return: response\n    \"\"\"\n    print(\"Preparing Data Upload\")\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Look up the configured data connector by name.\n        Returns a one-row DataFrame (or an error string) with connector metadata.\"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n            if not file_path:\n                return \"Missing argument file_path\"\n    else:\n        return connectors\n\n    def upload_file_and_return_path(file_path, data_type, tag=None) -&gt; str:\n        \"\"\"Trigger a connector-to-Lexsi upload for a file path.\n        Returns the stored `filepath` in Lexsi storage to be referenced by other APIs.\n\n        :param file_path: Source path in the connector (bucket/object path, sftp path, etc.).\n        :param data_type: Upload type such as `data`, `model`, etc.\n        :param tag: Optional tag to associate with the upload.\n        :return: Server-side filepath for the uploaded artifact.\"\"\"\n        if not self.project_name:\n            return \"Missing Project Name\"\n        query_params = f\"project_name={self.project_name}&amp;link_service_name={data_connector_name}&amp;data_type={data_type}&amp;tag={tag}&amp;bucket_name={bucket_name}&amp;file_path={file_path}\"\n        if self.organization_id:\n            query_params += f\"&amp;organization_id={self.organization_id}\"\n        res = self.api_client.post(f\"{UPLOAD_FILE_DATA_CONNECTORS}?{query_params}\")\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    project_config = self.config()\n\n    if project_config == \"Not Found\":\n        if self.metadata.get(\"modality\") == \"image\":\n            if (\n                not model_path\n                or not model_architecture\n                or not model_type\n                or not model_name\n            ):\n                raise Exception(\"Model details is required for Image project type\")\n\n            uploaded_path = upload_file_and_return_path(file_path, \"data\", tag)\n\n            model_uploaded_path = upload_file_and_return_path(model_path, \"model\")\n\n            payload = {\n                \"project_name\": self.project_name,\n                \"project_type\": self.metadata.get(\"project_type\"),\n                \"metadata\": {\n                    \"path\": uploaded_path,\n                    \"model_name\": model_name,\n                    \"model_path\": model_uploaded_path,\n                    \"model_architecture\": model_architecture,\n                    \"model_type\": model_type,\n                    \"tag\": tag,\n                    \"tags\": [tag],\n                },\n            }\n\n        if self.metadata.get(\"modality\") == \"tabular\":\n            if not config.get(\"project_type\"):\n                config[\"project_type\"] = self.metadata.get(\"project_type\")\n            if not config:\n                config = {\n                    \"project_type\": \"\",\n                    \"unique_identifier\": \"\",\n                    \"true_label\": \"\",\n                    \"pred_label\": \"\",\n                    \"feature_exclude\": [],\n                    \"drop_duplicate_uid\": False,\n                    \"handle_errors\": False,\n                }\n                raise Exception(\n                    f\"Project Config is required, since no config is set for project \\n {json.dumps(config,indent=1)}\"\n                )\n\n            Validate.check_for_missing_keys(\n                config, [\"project_type\", \"unique_identifier\", \"true_label\"]\n            )\n\n            Validate.value_against_list(\n                \"project_type\", config, [\"classification\", \"regression\"]\n            )\n\n            uploaded_path = upload_file_and_return_path(file_path, \"data\", tag)\n\n            file_info = self.api_client.post(\n                UPLOAD_DATA_FILE_INFO_URI, {\"path\": uploaded_path}\n            )\n\n            column_names = file_info.get(\"details\").get(\"column_names\")\n\n            Validate.value_against_list(\n                \"unique_identifier\",\n                config[\"unique_identifier\"],\n                column_names,\n                lambda: self.delete_file(uploaded_path),\n            )\n\n            if config.get(\"feature_exclude\"):\n                Validate.value_against_list(\n                    \"feature_exclude\",\n                    config[\"feature_exclude\"],\n                    column_names,\n                    lambda: self.delete_file(uploaded_path),\n                )\n\n            feature_exclude = [\n                config[\"unique_identifier\"],\n                config[\"true_label\"],\n                *config.get(\"feature_exclude\", []),\n            ]\n\n            feature_include = [\n                feature\n                for feature in column_names\n                if feature not in feature_exclude\n            ]\n\n            feature_encodings = config.get(\"feature_encodings\", {})\n            if feature_encodings:\n                Validate.value_against_list(\n                    \"feature_encodings_feature\",\n                    list(feature_encodings.keys()),\n                    column_names,\n                )\n                Validate.value_against_list(\n                    \"feature_encodings_feature\",\n                    list(feature_encodings.values()),\n                    [\"labelencode\", \"countencode\", \"onehotencode\"],\n                )\n\n            payload = {\n                \"project_name\": self.project_name,\n                \"project_type\": config[\"project_type\"],\n                \"unique_identifier\": config[\"unique_identifier\"],\n                \"true_label\": config[\"true_label\"],\n                \"pred_label\": config.get(\"pred_label\"),\n                \"metadata\": {\n                    \"path\": uploaded_path,\n                    \"tag\": tag,\n                    \"tags\": [tag],\n                    \"drop_duplicate_uid\": config.get(\"drop_duplicate_uid\"),\n                    \"handle_errors\": config.get(\"handle_errors\", False),\n                    \"feature_exclude\": feature_exclude,\n                    \"feature_include\": feature_include,\n                    \"feature_encodings\": feature_encodings,\n                    \"feature_actual_used\": [],\n                },\n            }\n\n        res = self.api_client.post(UPLOAD_DATA_WITH_CHECK_URI, payload)\n\n        if not res[\"success\"]:\n            self.delete_file(uploaded_path)\n            raise Exception(res.get(\"details\"))\n\n        poll_events(self.api_client, self.project_name, res[\"event_id\"])\n\n        return res.get(\"details\")\n\n    if project_config != \"Not Found\" and config:\n        raise Exception(\"Config already exists, please remove config\")\n\n    uploaded_path = upload_file_and_return_path(file_path, \"data\", tag)\n\n    payload = {\n        \"path\": uploaded_path,\n        \"tag\": tag,\n        \"type\": \"data\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_data_description","title":"upload_data_description","text":"<pre><code>upload_data_description(data)\n</code></pre> <p>uploads data description for the project</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | DataFrame</code> <p>response</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_data_description(self, data: str | pd.DataFrame) -&gt; str:\n    \"\"\"uploads data description for the project\n\n    :param data: response\n    :return: response\n    \"\"\"\n\n    def build_upload_data():\n        \"\"\"Build the multipart payload for a data-description upload.\n        Accepts a CSV path or DataFrame and serializes DataFrames to CSV bytes.\n\n        :return: A file handle (path input) or `(filename, bytes)` tuple (DataFrame input).\n        \"\"\"\n        if isinstance(data, str):\n            file = open(data, \"rb\")\n            return file\n        elif isinstance(data, pd.DataFrame):\n            csv_buffer = io.BytesIO()\n            data.to_csv(csv_buffer, index=False, encoding=\"utf-8\")\n            csv_buffer.seek(0)\n            file_name = (\n                f\"data_description_sdk_{datetime.now().replace(microsecond=0)}.csv\"\n            )\n            file = (file_name, csv_buffer.getvalue())\n            return file\n        else:\n            raise Exception(\"Invalid Data Type\")\n\n    def upload_file_and_return_path() -&gt; str:\n        \"\"\"Upload the data-description artifact to Lexsi file storage.\n        Returns the stored `filepath`, which is then registered to the project.\n\n        :return: Server-side filepath for the uploaded data-description artifact.\"\"\"\n        files = {\"in_file\": build_upload_data()}\n        res = self.api_client.file(\n            f\"{UPLOAD_DATA_FILE_URI}?project_name={self.project_name}&amp;data_type=data_description\",\n            files,\n        )\n\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    uploaded_path = upload_file_and_return_path()\n\n    payload = {\n        \"path\": uploaded_path,\n        \"type\": \"data_description\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\", \"Data description upload successful\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_data_description_dataconnectors","title":"upload_data_description_dataconnectors","text":"<pre><code>upload_data_description_dataconnectors(\n    data_connector_name, bucket_name=None, file_path=None\n)\n</code></pre> <p>uploads data description for the project</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>name of the data connector</p> required <code>bucket_name</code> <code>Optional[str]</code> <p>if data connector has buckets # Example: s3/gcs buckets</p> <code>None</code> <code>file_path</code> <code>Optional[str]</code> <p>filepath from the bucket for the data to read</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_data_description_dataconnectors(\n    self,\n    data_connector_name: str,\n    bucket_name: Optional[str] = None,\n    file_path: Optional[str] = None,\n) -&gt; str:\n    \"\"\"uploads data description for the project\n\n    :param data_connector_name: name of the data connector\n    :param bucket_name: if data connector has buckets # Example: s3/gcs buckets\n    :param file_path: filepath from the bucket for the data to read\n    :return: response\n    \"\"\"\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Look up the configured data connector by name.\n        Returns a one-row DataFrame (or an error string) with connector metadata.\"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n            if not file_path:\n                return \"Missing argument file_path\"\n    else:\n        return connectors\n\n    def upload_file_and_return_path() -&gt; str:\n        \"\"\"Trigger a connector-to-Lexsi upload for the data-description file.\n        Returns the stored `filepath` to be used in the subsequent register call.\"\"\"\n        if not self.project_name:\n            return \"Missing Project Name\"\n        if self.organization_id:\n            res = self.api_client.post(\n                f\"{UPLOAD_FILE_DATA_CONNECTORS}?project_name={self.project_name}&amp;organization_id={self.organization_id}&amp;link_service_name={data_connector_name}&amp;data_type=data_description&amp;bucket_name={bucket_name}&amp;file_path={file_path}\"\n            )\n        else:\n            res = self.api_client.post(\n                f\"{UPLOAD_FILE_DATA_CONNECTORS}?project_name={self.project_name}&amp;link_service_name={data_connector_name}&amp;data_type=data_description&amp;bucket_name={bucket_name}&amp;file_path={file_path}\"\n            )\n        print(res)\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    uploaded_path = upload_file_and_return_path()\n\n    payload = {\n        \"path\": uploaded_path,\n        \"type\": \"data_description\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\", \"Data description upload successful\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_docker_compose","title":"upload_docker_compose","text":"<pre><code>upload_docker_compose(\n    model_provider,\n    model_name,\n    model_type,\n    model_task_type,\n    hf_token=None,\n    file_path=None,\n)\n</code></pre> <p>Upload a docker compose bundle for custom model hosting. Performs a multipart upload to Lexsi storage and returns the raw API response.</p> <p>Parameters:</p> Name Type Description Default <code>model_provider</code> <code>str</code> <p>Provider name (e.g. <code>openai</code>, <code>anthropic</code>, etc.).</p> required <code>model_name</code> <code>str</code> <p>Model name to register for hosting.</p> required <code>model_type</code> <code>str</code> <p>Model type identifier expected by backend.</p> required <code>model_task_type</code> <code>str</code> <p>Task type (e.g. <code>text-generation</code>, <code>embedding</code>).</p> required <code>hf_token</code> <code>Optional[str]</code> <p>Optional HuggingFace token for private model pulls.</p> <code>None</code> <code>file_path</code> <code>Optional[str]</code> <p>Local path to the docker compose bundle archive.</p> <code>None</code> <p>Returns:</p> Type Description <p>Raw API response from the file upload call.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_docker_compose(\n    self,\n    model_provider: str,\n    model_name: str,\n    model_type: str,\n    model_task_type: str,\n    hf_token: Optional[str] = None,\n    file_path: Optional[str] = None,\n):\n    \"\"\"Upload a docker compose bundle for custom model hosting.\n    Performs a multipart upload to Lexsi storage and returns the raw API response.\n\n    :param model_provider: Provider name (e.g. `openai`, `anthropic`, etc.).\n    :param model_name: Model name to register for hosting.\n    :param model_type: Model type identifier expected by backend.\n    :param model_task_type: Task type (e.g. `text-generation`, `embedding`).\n    :param hf_token: Optional HuggingFace token for private model pulls.\n    :param file_path: Local path to the docker compose bundle archive.\n    :return: Raw API response from the file upload call.\"\"\"\n    files = {\"in_file\": open(file_path, \"rb\")}\n    res = self.api_client.file(\n        f\"{UPLOAD_DATA_FILE_URI}?project_name={self.project_name}&amp;model_provider={model_provider}&amp;model_name={model_name}&amp;model_type={model_type}&amp;model_task_type={model_task_type}&amp;hf_token={hf_token}\",\n        files=files,\n    )\n    return res\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_feature_mapping","title":"upload_feature_mapping","text":"<pre><code>upload_feature_mapping(data)\n</code></pre> <p>uploads feature mapping for the project</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | dict</code> <p>response</p> required <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_feature_mapping(self, data: str | dict) -&gt; str:\n    \"\"\"uploads feature mapping for the project\n\n    :param data: response\n    :return: response\n    \"\"\"\n\n    def build_upload_data():\n        \"\"\"Build the multipart payload for a feature-mapping upload.\n        Accepts a file path or a Python dict and serializes dicts to JSON bytes.\n\n        :return: A file handle (path input) or `(filename, bytes)` tuple (dict input).\n        \"\"\"\n        if isinstance(data, str):\n            file = open(data, \"rb\")\n            return file\n        elif isinstance(data, dict):\n            json_buffer = io.BytesIO()\n            json_str = json.dumps(data, ensure_ascii=False, indent=4)\n            json_buffer.write(json_str.encode(\"utf-8\"))\n            json_buffer.seek(0)\n            file_name = (\n                f\"feature_mapping_sdk_{datetime.now().replace(microsecond=0)}.json\"\n            )\n            file = (file_name, json_buffer.getvalue())\n            return file\n        else:\n            raise Exception(\"Invalid Data Type\")\n\n    def upload_file_and_return_path() -&gt; str:\n        \"\"\"Upload the feature-mapping artifact to Lexsi file storage.\n        Returns the stored `filepath`, which is then registered to the project.\n\n        :return: Server-side filepath for the uploaded feature-mapping artifact.\"\"\"\n        files = {\"in_file\": build_upload_data()}\n        res = self.api_client.file(\n            f\"{UPLOAD_DATA_FILE_URI}?project_name={self.project_name}&amp;data_type=feature_mapping\",\n            files,\n        )\n\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    uploaded_path = upload_file_and_return_path()\n\n    payload = {\n        \"path\": uploaded_path,\n        \"type\": \"feature_mapping\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\", \"Feature mapping upload successful\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_feature_mapping_dataconnectors","title":"upload_feature_mapping_dataconnectors","text":"<pre><code>upload_feature_mapping_dataconnectors(\n    data_connector_name, bucket_name=None, file_path=None\n)\n</code></pre> <p>uploads feature mapping for the project</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>name of the data connector</p> required <code>bucket_name</code> <code>Optional[str]</code> <p>if data connector has buckets # Example: s3/gcs buckets</p> <code>None</code> <code>file_path</code> <code>Optional[str]</code> <p>filepath from the bucket for the data to read</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_feature_mapping_dataconnectors(\n    self,\n    data_connector_name: str,\n    bucket_name: Optional[str] = None,\n    file_path: Optional[str] = None,\n) -&gt; str:\n    \"\"\"uploads feature mapping for the project\n\n    :param data_connector_name: name of the data connector\n    :param bucket_name: if data connector has buckets # Example: s3/gcs buckets\n    :param file_path: filepath from the bucket for the data to read\n    :return: response\n    \"\"\"\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Look up the configured data connector by name.\n        Returns a one-row DataFrame (or an error string) with connector metadata.\"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n            if not file_path:\n                return \"Missing argument file_path\"\n    else:\n        return connectors\n\n    def upload_file_and_return_path() -&gt; str:\n        \"\"\"Trigger a connector-to-Lexsi upload for the feature-mapping file.\n        Returns the stored `filepath` to be used in the subsequent register call.\"\"\"\n        if not self.project_name:\n            return \"Missing Project Name\"\n        if self.organization_id:\n            res = self.api_client.post(\n                f\"{UPLOAD_FILE_DATA_CONNECTORS}?project_name={self.project_name}&amp;organization_id={self.organization_id}&amp;link_service_name={data_connector_name}&amp;data_type=feature_mapping&amp;bucket_name={bucket_name}&amp;file_path={file_path}\"\n            )\n        else:\n            res = self.api_client.post(\n                f\"{UPLOAD_FILE_DATA_CONNECTORS}?project_name={self.project_name}&amp;link_service_name={data_connector_name}&amp;data_type=feature_mapping&amp;bucket_name={bucket_name}&amp;file_path={file_path}\"\n            )\n        print(res)\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    uploaded_path = upload_file_and_return_path()\n\n    payload = {\n        \"path\": uploaded_path,\n        \"type\": \"feature_mapping\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\", \"Feature mapping upload successful\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_model","title":"upload_model","text":"<pre><code>upload_model(\n    model_path,\n    model_architecture,\n    model_type,\n    model_name,\n    model_data_tags,\n    model_test_tags,\n    instance_type=None,\n    explainability_method=[\"shap\"],\n    feature_list=None,\n)\n</code></pre> <p>Uploads your custom model on Lexsi.ai</p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>str</code> <p>path of the model</p> required <code>model_architecture</code> <code>str</code> <p>architecture of model [\"machine_learning\", \"deep_learning\"]</p> required <code>model_type</code> <code>str</code> <p>type of the model based on the architecture [\"Xgboost\",\"Lgboost\",\"CatBoost\",\"Random_forest\",\"Linear_Regression\",\"Logistic_Regression\",\"Gaussian_NaiveBayes\",\"SGD\"] use upload_model_types() method to get all allowed model_types</p> required <code>model_name</code> <code>str</code> <p>name of the model</p> required <code>model_data_tags</code> <code>list</code> <p>data tags for model</p> required <code>model_test_tags</code> <code>Optional[list]</code> <p>test tags for model (optional)</p> required <code>instance_type</code> <code>Optional[str]</code> <p>instance to be used for uploading model (optional)</p> <code>None</code> <code>explainability_method</code> <code>Optional[list]</code> <p>explainability method to be used while uploading model [\"shap\", \"lime\"] (optional)</p> <code>['shap']</code> <code>feature_list</code> <code>Optional[list]</code> <p>list of features in sequence which are to be passed in the model (optional)</p> <code>None</code> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_model(\n    self,\n    model_path: str,\n    model_architecture: str,\n    model_type: str,\n    model_name: str,\n    model_data_tags: list,\n    model_test_tags: Optional[list],\n    instance_type: Optional[str] = None,\n    explainability_method: Optional[list] = [\"shap\"],\n    feature_list: Optional[list] = None,\n):\n    \"\"\"Uploads your custom model on Lexsi.ai\n\n    :param model_path: path of the model\n    :param model_architecture: architecture of model [\"machine_learning\", \"deep_learning\"]\n    :param model_type: type of the model based on the architecture [\"Xgboost\",\"Lgboost\",\"CatBoost\",\"Random_forest\",\"Linear_Regression\",\"Logistic_Regression\",\"Gaussian_NaiveBayes\",\"SGD\"]\n            use upload_model_types() method to get all allowed model_types\n    :param model_name: name of the model\n    :param model_data_tags: data tags for model\n    :param model_test_tags: test tags for model (optional)\n    :param instance_type: instance to be used for uploading model (optional)\n    :param explainability_method: explainability method to be used while uploading model [\"shap\", \"lime\"] (optional)\n    :param feature_list: list of features in sequence which are to be passed in the model (optional)\n    \"\"\"\n\n    def upload_file_and_return_path() -&gt; str:\n        \"\"\"Upload a local model artifact to Lexsi file storage.\n        Returns the stored `filepath` referenced by the model upload request.\"\"\"\n        files = {\"in_file\": open(model_path, \"rb\")}\n        model_data_tags_str = \",\".join(model_data_tags)\n        res = self.api_client.file(\n            f\"{UPLOAD_DATA_FILE_URI}?project_name={self.project_name}&amp;data_type=model&amp;tag={model_data_tags_str}\",\n            files,\n        )\n\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    model_types = self.api_client.get(GET_MODEL_TYPES_URI)\n    valid_model_architecture = model_types.get(\"model_architecture\").keys()\n    Validate.value_against_list(\n        \"model_achitecture\", model_architecture, valid_model_architecture\n    )\n\n    valid_model_types = model_types.get(\"model_architecture\")[model_architecture]\n    Validate.value_against_list(\"model_type\", model_type, valid_model_types)\n\n    tags = self.tags()\n    Validate.value_against_list(\"model_data_tags\", model_data_tags, tags)\n\n    if model_test_tags:\n        Validate.value_against_list(\"model_test_tags\", model_test_tags, tags)\n\n    uploaded_path = upload_file_and_return_path()\n\n    if instance_type:\n        custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n        Validate.value_against_list(\n            \"instance_type\",\n            instance_type,\n            [\n                server[\"instance_name\"]\n                for server in custom_batch_servers.get(\"details\", [])\n            ],\n        )\n\n    if explainability_method:\n        Validate.value_against_list(\n            \"explainability_method\", explainability_method, [\"shap\", \"lime\"]\n        )\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n        \"model_architecture\": model_architecture,\n        \"model_type\": model_type,\n        \"model_path\": uploaded_path,\n        \"model_data_tags\": model_data_tags,\n        \"model_test_tags\": model_test_tags,\n        \"explainability_method\": explainability_method,\n        \"feature_list\": feature_list,\n    }\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(UPLOAD_MODEL_URI, payload)\n\n    if not res.get(\"success\"):\n        raise Exception(res.get(\"details\"))\n\n    poll_events(\n        self.api_client,\n        self.project_name,\n        res[\"event_id\"],\n        lambda: self.delete_file(uploaded_path),\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_model_dataconnectors","title":"upload_model_dataconnectors","text":"<pre><code>upload_model_dataconnectors(\n    data_connector_name,\n    model_architecture,\n    model_type,\n    model_name,\n    model_data_tags,\n    model_test_tags,\n    instance_type=None,\n    explainability_method=[\"shap\"],\n    bucket_name=None,\n    file_path=None,\n)\n</code></pre> <p>Uploads your custom model on Lexsi.ai</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>name of the data connector</p> required <code>model_architecture</code> <code>str</code> <p>architecture of model [\"machine_learning\", \"deep_learning\"]</p> required <code>model_type</code> <code>str</code> <p>type of the model based on the architecture [\"Xgboost\",\"Lgboost\",\"CatBoost\",\"Random_forest\",\"Linear_Regression\",\"Logistic_Regression\",\"Gaussian_NaiveBayes\",\"SGD\"] use upload_model_types() method to get all allowed model_types</p> required <code>model_name</code> <code>str</code> <p>name of the model</p> required <code>model_data_tags</code> <code>list</code> <p>data tags for model</p> required <code>model_test_tags</code> <code>Optional[list]</code> <p>test tags for model (optional)</p> required <code>instance_type</code> <code>Optional[str]</code> <p>instance to be used for uploading model (optional)</p> <code>None</code> <code>explainability_method</code> <code>Optional[list]</code> <p>explainability method to be used while uploading model [\"shap\", \"lime\"] (optional)</p> <code>['shap']</code> <code>bucket_name</code> <code>Optional[str]</code> <p>if data connector has buckets # Example: s3/gcs buckets</p> <code>None</code> <code>file_path</code> <code>Optional[str]</code> <p>filepath from the bucket for the data to read</p> <code>None</code> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_model_dataconnectors(\n    self,\n    data_connector_name: str,\n    model_architecture: str,\n    model_type: str,\n    model_name: str,\n    model_data_tags: list,\n    model_test_tags: Optional[list],\n    instance_type: Optional[str] = None,\n    explainability_method: Optional[list] = [\"shap\"],\n    bucket_name: Optional[str] = None,\n    file_path: Optional[str] = None,\n):\n    \"\"\"Uploads your custom model on Lexsi.ai\n\n    :param data_connector_name: name of the data connector\n    :param model_architecture: architecture of model [\"machine_learning\", \"deep_learning\"]\n    :param model_type: type of the model based on the architecture [\"Xgboost\",\"Lgboost\",\"CatBoost\",\"Random_forest\",\"Linear_Regression\",\"Logistic_Regression\",\"Gaussian_NaiveBayes\",\"SGD\"]\n            use upload_model_types() method to get all allowed model_types\n    :param model_name: name of the model\n    :param model_data_tags: data tags for model\n    :param model_test_tags: test tags for model (optional)\n    :param instance_type: instance to be used for uploading model (optional)\n    :param explainability_method: explainability method to be used while uploading model [\"shap\", \"lime\"] (optional)\n    :param bucket_name: if data connector has buckets # Example: s3/gcs buckets\n    :param file_path: filepath from the bucket for the data to read\n    \"\"\"\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Look up the configured data connector by name.\n        Returns a one-row DataFrame (or an error string) with connector metadata.\"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n            if not file_path:\n                return \"Missing argument file_path\"\n    else:\n        return connectors\n\n    def upload_file_and_return_path() -&gt; str:\n        \"\"\"Trigger a connector-to-Lexsi upload for model artifacts.\n        Returns the stored `filepath` referenced by the model upload request.\"\"\"\n        if not self.project_name:\n            return \"Missing Project Name\"\n        model_data_tags_str = \",\".join(model_data_tags)\n        if self.organization_id:\n            res = self.api_client.post(\n                f\"{UPLOAD_FILE_DATA_CONNECTORS}?project_name={self.project_name}&amp;organization_id={self.organization_id}&amp;link_service_name={data_connector_name}&amp;data_type=model&amp;bucket_name={bucket_name}&amp;file_path={file_path}&amp;tag={model_data_tags_str}\"\n            )\n        else:\n            res = self.api_client.post(\n                f\"{UPLOAD_FILE_DATA_CONNECTORS}?project_name={self.project_name}&amp;link_service_name={data_connector_name}&amp;data_type=model&amp;bucket_name={bucket_name}&amp;file_path={file_path}&amp;tag={model_data_tags_str}\"\n            )\n        print(res)\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    model_types = self.api_client.get(GET_MODEL_TYPES_URI)\n    valid_model_architecture = model_types.get(\"model_architecture\").keys()\n    Validate.value_against_list(\n        \"model_achitecture\", model_architecture, valid_model_architecture\n    )\n\n    valid_model_types = model_types.get(\"model_architecture\")[model_architecture]\n    Validate.value_against_list(\"model_type\", model_type, valid_model_types)\n\n    tags = self.tags()\n    Validate.value_against_list(\"model_data_tags\", model_data_tags, tags)\n\n    if model_test_tags:\n        Validate.value_against_list(\"model_test_tags\", model_test_tags, tags)\n\n    uploaded_path = upload_file_and_return_path()\n\n    if instance_type:\n        custom_batch_servers = self.api_client.get(AVAILABLE_BATCH_SERVERS_URI)\n        Validate.value_against_list(\n            \"instance_type\",\n            instance_type,\n            [\n                server[\"instance_name\"]\n                for server in custom_batch_servers.get(\"details\", [])\n            ],\n        )\n\n    if explainability_method:\n        Validate.value_against_list(\n            \"explainability_method\", explainability_method, [\"shap\", \"lime\"]\n        )\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n        \"model_architecture\": model_architecture,\n        \"model_type\": model_type,\n        \"model_path\": uploaded_path,\n        \"model_data_tags\": model_data_tags,\n        \"model_test_tags\": model_test_tags,\n        \"explainability_method\": explainability_method,\n    }\n\n    if instance_type:\n        payload[\"instance_type\"] = instance_type\n\n    res = self.api_client.post(UPLOAD_MODEL_URI, payload)\n\n    if not res.get(\"success\"):\n        raise Exception(res.get(\"details\"))\n\n    poll_events(\n        self.api_client,\n        self.project_name,\n        res[\"event_id\"],\n        lambda: self.delete_file(uploaded_path),\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.Project.upload_model_types","title":"upload_model_types","text":"<pre><code>upload_model_types()\n</code></pre> <p>Model types which can be uploaded using upload_model()</p> <p>Returns:</p> Type Description <code>dict</code> <p>response</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def upload_model_types(self) -&gt; dict:\n    \"\"\"Model types which can be uploaded using upload_model()\n\n    :return: response\n    \"\"\"\n    model_types = self.api_client.get(GET_MODEL_TYPES_URI)\n\n    return model_types\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.build_expression","title":"build_expression","text":"<pre><code>build_expression(expression_string)\n</code></pre> <p>Parse a human expression string into configuration and metadata tokens. Maps operators to backend enums and preserves parentheses/logical operator ordering.</p> <p>Parameters:</p> Name Type Description Default <code>expression_string</code> <p>Expression string like <code>A == 1 and B !== 2</code>.</p> required <p>Returns:</p> Type Description <p><code>(configuration, metadata_expression)</code> token lists.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def build_expression(expression_string):\n    \"\"\"Parse a human expression string into configuration and metadata tokens.\n    Maps operators to backend enums and preserves parentheses/logical operator ordering.\n\n    :param expression_string: Expression string like `A == 1 and B !== 2`.\n    :return: `(configuration, metadata_expression)` token lists.\"\"\"\n    condition_operators = {\n        \"!==\": \"_NOTEQ\",\n        \"==\": \"_ISEQ\",\n        \"&gt;\": \"_GRT\",\n        \"&lt;\": \"_LST\",\n    }\n    logical_operators = {\"and\": \"_AND\", \"or\": \"_OR\"}\n\n    metadata_expression = []\n    configuration = []\n    string_to_be_parsed = expression_string\n\n    matches = re.findall(r\"(\\w+)\\s*([!=&lt;&gt;]+)\\s*(\\w+)\", expression_string)\n\n    total_opening_parentheses = re.findall(r\"\\(\", expression_string)\n    total_closing_parentheses = re.findall(r\"\\)\", expression_string)\n\n    if len(total_opening_parentheses) != len(total_closing_parentheses):\n        raise Exception(\"Invalid expression, check parentheses\")\n\n    for i, match in enumerate(matches):\n        column, expression, value = match\n        if expression not in condition_operators.keys():\n            raise Exception(f\"Not a valid condition operator in {match}\")\n\n        opening_parentheses = re.findall(r\"\\(\", string_to_be_parsed.split(column, 1)[0])\n        if opening_parentheses:\n            metadata_expression.extend(opening_parentheses)\n            configuration.extend(opening_parentheses)\n\n        metadata_expression.append(\n            {\n                \"column\": column,\n                \"value\": value,\n                \"expression\": expression,\n            }\n        )\n        configuration.append(\n            {\n                \"column\": column,\n                \"value\": value,\n                \"expression\": condition_operators[expression],\n            }\n        )\n\n        string_to_be_parsed = string_to_be_parsed.split(value, 1)[1]\n        between_conditions_split = string_to_be_parsed.split(\n            matches[i + 1][0] if i &lt; len(matches) - 1 else None, 1\n        )\n        closing_parentheses = re.findall(\n            r\"\\)\",\n            between_conditions_split[0] if len(between_conditions_split) &gt; 0 else \"\",\n        )\n        if closing_parentheses:\n            metadata_expression.extend(closing_parentheses)\n            configuration.extend(closing_parentheses)\n\n        if i &lt; len(matches) - 1:\n            between_conditions = between_conditions_split[0].strip()\n            between_conditions = between_conditions.replace(\")\", \"\").replace(\"(\", \"\")\n            logical_operator = re.search(r\"and|or\", between_conditions)\n            if not logical_operator:\n                raise Exception(f\"{between_conditions} is not valid logical operator\")\n            log_operator = logical_operator.group()\n            log_operator_split = list(\n                filter(\n                    lambda op: op != \"\" and op != \" \",\n                    between_conditions.split(log_operator, 1),\n                )\n            )\n            if len(log_operator_split) &gt; 0:\n                raise Exception(f\"{between_conditions} is not valid logical operator\")\n            metadata_expression.append(log_operator)\n            configuration.append(logical_operators[log_operator])\n\n    return configuration, metadata_expression\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.generate_expression","title":"generate_expression","text":"<pre><code>generate_expression(expression)\n</code></pre> <p>Render a tokenized expression into a readable string. Used to display stored observation/policy expressions from their metadata format.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <p>Token list produced by <code>build_expression</code>.</p> required <p>Returns:</p> Type Description <p>Rendered expression string, or None if input is empty.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def generate_expression(expression):\n    \"\"\"Render a tokenized expression into a readable string.\n    Used to display stored observation/policy expressions from their metadata format.\n\n    :param expression: Token list produced by `build_expression`.\n    :return: Rendered expression string, or None if input is empty.\"\"\"\n    if not expression:\n        return None\n    generated_expression = \"\"\n    for item in expression:\n        if isinstance(item, str):\n            generated_expression += \" \" + item\n        else:\n            generated_expression += (\n                f\" {item['column']} {item['expression']} {item['value']}\"\n            )\n    return generated_expression\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.project.validate_configuration","title":"validate_configuration","text":"<pre><code>validate_configuration(\n    configuration,\n    params,\n    project_name=\"\",\n    api_client=APIClient(),\n    observations=False,\n)\n</code></pre> <p>Validate an expression configuration against allowed features/operators. Raises exceptions for invalid columns/operators/values and can validate observation comparisons.</p> <p>Parameters:</p> Name Type Description Default <code>configuration</code> <p>Configuration token list (from <code>build_expression</code>).</p> required <code>params</code> <p>Allowed features/operators payload fetched from the backend.</p> required <code>project_name</code> <p>Project name used for backend validation calls.</p> <code>''</code> <code>api_client</code> <p>API client used for optional backend validation.</p> <code>APIClient()</code> <code>observations</code> <p>If True, validate observation column-vs-column comparisons.</p> <code>False</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the configuration is invalid.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def validate_configuration(\n    configuration, params, project_name=\"\", api_client=APIClient(), observations=False\n):\n    \"\"\"Validate an expression configuration against allowed features/operators.\n    Raises exceptions for invalid columns/operators/values and can validate observation comparisons.\n\n    :param configuration: Configuration token list (from `build_expression`).\n    :param params: Allowed features/operators payload fetched from the backend.\n    :param project_name: Project name used for backend validation calls.\n    :param api_client: API client used for optional backend validation.\n    :param observations: If True, validate observation column-vs-column comparisons.\n    :raises Exception: If the configuration is invalid.\"\"\"\n    for expression in configuration:\n        if isinstance(expression, str):\n            if expression not in [\"(\", \")\", *params.get(\"logical_operators\")]:\n                raise Exception(f\"{expression} not a valid logical operator\")\n\n        if isinstance(expression, dict):\n            # validate column name\n            Validate.value_against_list(\n                \"feature\",\n                expression.get(\"column\"),\n                list(params.get(\"features\", {}).keys()),\n            )\n\n            # validate operator\n            Validate.value_against_list(\n                \"condition_operator\",\n                expression.get(\"expression\"),\n                params.get(\"condition_operators\"),\n            )\n\n            # validate value(s)\n            expression_value = expression.get(\"value\")\n            valid_feature_values = params.get(\"features\").get(expression.get(\"column\"))\n            if observations and isinstance(valid_feature_values, list):\n                condition_operators = {\n                    \"_NOTEQ\": \"!==\",\n                    \"_ISEQ\": \"==\",\n                    \"_GRT\": \"&gt;\",\n                    \"_LST\": \"&lt;\",\n                }\n                res = api_client.get(\n                    f\"{VALIDATE_POLICY_URI}?project_name={project_name}&amp;column1_name={expression.get('column')}&amp;column2_name={expression.get('value')}&amp;operation={condition_operators[expression.get('expression')]}\"\n                )\n                if not res.get(\"success\"):\n                    raise Exception(res.get(\"message\"))\n            if isinstance(valid_feature_values, str):\n                #     if valid_feature_values == \"input\" and not parse_float(\n                #         expression_value\n                #     ):\n                #         raise Exception(\n                #             f\"Invalid value comparison with {expression_value} for {expression.get('column')}\"\n                #         )\n                if valid_feature_values == \"datetime\" and not parse_datetime(\n                    expression_value\n                ):\n                    raise Exception(\n                        f\"Invalid value comparison with {expression_value} for {expression.get('column')}\"\n                    )\n\n                else:\n                    condition_operators = {\n                        \"_NOTEQ\": \"!==\",\n                        \"_ISEQ\": \"==\",\n                        \"_GRT\": \"&gt;\",\n                        \"_LST\": \"&lt;\",\n                    }\n                    res = api_client.get(\n                        f\"{VALIDATE_POLICY_URI}?project_name={project_name}&amp;column1_name={expression.get('column')}&amp;column2_name={expression.get('value')}&amp;operation={condition_operators[expression.get('expression')]}\"\n                    )\n                    if not res.get(\"success\"):\n                        raise Exception(res.get(\"message\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case","title":"Case","text":"<pre><code>Case(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Represents an explainability case for a prediction. Provides visualization helpers such as SHAP, LIME, Integrated Gradients, and decision paths.</p> <p>Capture API client used to fetch additional explainability data. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Capture API client used to fetch additional explainability data.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.alerts_trail","title":"alerts_trail","text":"<pre><code>alerts_trail(page_num=1, days=7)\n</code></pre> <p>Fetch alerts for this case over the given window. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def alerts_trail(self, page_num: Optional[int] = 1, days: Optional[int] = 7):\n    \"\"\"Fetch alerts for this case over the given window.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    if days == 7:\n        return pd.DataFrame(self.audit_trail.get(\"alerts\", {}))\n    resp = self.api_client.post(\n        f\"{GET_TRIGGERS_DAYS_URI}?project_name={self.project_name}&amp;page_num={page_num}&amp;days={days}\"\n    )\n    if resp.get(\"details\"):\n        return pd.DataFrame(resp.get(\"details\"))\n    else:\n        return \"No alerts found.\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.audit","title":"audit","text":"<pre><code>audit()\n</code></pre> <p>Return stored audit trail. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def audit(self):\n    \"\"\"Return stored audit trail.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    return self.audit_trail\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_decision","title":"explainability_decision","text":"<pre><code>explainability_decision()\n</code></pre> <p>Return a DataFrame summarizing the final decision for the case, including the true value, predicted value, predicted category, and final decision.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>decision dataframe</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_decision(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame summarizing the final decision for the case, including the true value, predicted value, predicted category, and final decision.\n\n    :return: decision dataframe\n    \"\"\"\n    data = {\n        \"True Value\": self.true_value,\n        \"Prediction Value\": self.pred_value,\n        \"Prediction Category\": self.pred_category,\n        \"Final Prediction\": self.final_decision,\n    }\n    decision_df = pd.DataFrame([data])\n\n    return decision_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_dlb_feature_importance","title":"explainability_dlb_feature_importance","text":"<pre><code>explainability_dlb_feature_importance()\n</code></pre> <p>Plot a horizontal bar chart showing Deep Lift Bayesian (DLB)-based feature importance for the case.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_dlb_feature_importance(self):\n    \"\"\"Plot a horizontal bar chart showing Deep Lift Bayesian (DLB)-based feature importance for the case.\"\"\"\n    fig = go.Figure()\n    if len(list(self.dlb_feature_importance.values())) &lt; 1:\n        return \"No DLB Feature Importance for the case\"\n\n    if isinstance(list(self.dlb_feature_importance.values())[0], dict):\n        for col in self.dlb_feature_importance.keys():\n            fig.add_trace(\n                go.Bar(\n                    x=list(self.dlb_feature_importance[col].values()),\n                    y=list(self.dlb_feature_importance[col].keys()),\n                    orientation=\"h\",\n                    name=col,\n                )\n            )\n    else:\n        fig.add_trace(\n            go.Bar(\n                x=list(self.dlb_feature_importance.values()),\n                y=list(self.dlb_feature_importance.keys()),\n                orientation=\"h\",\n            )\n        )\n    fig.update_layout(\n        barmode=\"relative\",\n        height=800,\n        width=800,\n        yaxis_autorange=\"reversed\",\n        bargap=0.01,\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=1.1,\n    )\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_gradcam","title":"explainability_gradcam","text":"<pre><code>explainability_gradcam()\n</code></pre> <p>Visualize Grad-CAM results for image data, showing heatmaps and superimposed regions that contributed to the prediction.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_gradcam(self):\n    \"\"\"Visualize Grad-CAM results for image data, showing heatmaps and superimposed regions that contributed to the prediction.\"\"\"\n    if not self.image_data.get(\"gradcam\", None):\n        return \"No Gradcam method found for this case\"\n    fig = go.Figure()\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"gradcam\", {}).get(\"heatmap\"),\n            xref=\"x\",\n            yref=\"y\",\n            x=0,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"gradcam\", {}).get(\"superimposed\"),\n            xref=\"x\",\n            yref=\"y\",\n            x=1.2,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.add_annotation(\n        x=0.5,\n        y=0.1,\n        text=\"Attributions\",\n        showarrow=False,\n        font=dict(size=16),\n        xref=\"x\",\n        yref=\"y\",\n    )\n    fig.add_annotation(\n        x=1.7,\n        y=0.1,\n        text=\"Superimposed\",\n        showarrow=False,\n        font=dict(size=16),\n        xref=\"x\",\n        yref=\"y\",\n    )\n    fig.update_layout(\n        xaxis=dict(visible=False, range=[0, 2.5]),\n        yaxis=dict(visible=False, range=[0, 1]),\n        margin=dict(l=30, r=30, t=30, b=30),\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_ig_feature_importance","title":"explainability_ig_feature_importance","text":"<pre><code>explainability_ig_feature_importance()\n</code></pre> <p>Plot a horizontal bar chart showing Integrated Gradients-based feature importance for the case.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_ig_feature_importance(self):\n    \"\"\"Plot a horizontal bar chart showing Integrated Gradients-based feature importance for the case.\"\"\"\n    fig = go.Figure()\n\n    if len(list(self.ig_features_importance.values())) &lt; 1:\n        return \"No IG Feature Importance for the case\"\n\n    if isinstance(list(self.ig_features_importance.values())[0], dict):\n        for col in self.ig_features_importance.keys():\n            fig.add_trace(\n                go.Bar(\n                    x=list(self.ig_features_importance[col].values()),\n                    y=list(self.ig_features_importance[col].keys()),\n                    orientation=\"h\",\n                    name=col,\n                )\n            )\n    else:\n        fig.add_trace(\n            go.Bar(\n                x=list(self.ig_features_importance.values()),\n                y=list(self.ig_features_importance.keys()),\n                orientation=\"h\",\n            )\n        )\n    fig.update_layout(\n        barmode=\"relative\",\n        height=800,\n        width=800,\n        yaxis_autorange=\"reversed\",\n        bargap=0.01,\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=1.1,\n    )\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_integrated_gradients","title":"explainability_integrated_gradients","text":"<pre><code>explainability_integrated_gradients()\n</code></pre> <p>Render an integrated gradients attribution plot for image cases, showing positive and negative attributions side-by-side.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_integrated_gradients(self):\n    \"\"\"Render an integrated gradients attribution plot for image cases, showing positive and negative attributions side-by-side.\"\"\"\n    if not self.image_data.get(\"integrated_gradients\", None):\n        return \"No Integrated Gradients method found for this case\"\n    fig = go.Figure()\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"integrated_gradients\", {}).get(\n                \"attributions\"\n            ),\n            xref=\"x\",\n            yref=\"y\",\n            x=0,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"integrated_gradients\", {}).get(\n                \"positive_attributions\"\n            ),\n            xref=\"x\",\n            yref=\"y\",\n            x=1.2,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"integrated_gradients\", {}).get(\n                \"negative_attributions\"\n            ),\n            xref=\"x\",\n            yref=\"y\",\n            x=2.4,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.add_annotation(\n        x=0.5,\n        y=0.1,\n        text=\"Attributions\",\n        showarrow=False,\n        font=dict(size=16),\n        xref=\"x\",\n        yref=\"y\",\n    )\n    fig.add_annotation(\n        x=1.7,\n        y=0.1,\n        text=\"Positive Attributions\",\n        showarrow=False,\n        font=dict(size=16),\n        xref=\"x\",\n        yref=\"y\",\n    )\n    fig.add_annotation(\n        x=2.9,\n        y=0.1,\n        text=\"Negative Attributions\",\n        showarrow=False,\n        font=dict(size=16),\n        xref=\"x\",\n        yref=\"y\",\n    )\n    fig.update_layout(\n        xaxis=dict(visible=False, range=[0, 2.5]),\n        yaxis=dict(visible=False, range=[0, 1]),\n        margin=dict(l=30, r=30, t=30, b=30),\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_lime","title":"explainability_lime","text":"<pre><code>explainability_lime()\n</code></pre> <p>Render a LIME attribution plot for image cases, displaying attributions as an overlay on the original image.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_lime(self):\n    \"\"\"Render a LIME attribution plot for image cases, displaying attributions as an overlay on the original image.\"\"\"\n    if not self.image_data.get(\"lime\", None):\n        return \"No Lime method found for this case\"\n    fig = go.Figure()\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"lime\", {}).get(\"plot\"),\n            xref=\"x\",\n            yref=\"y\",\n            x=0,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.update_layout(\n        xaxis=dict(visible=False, range=[0, 2.5]),\n        yaxis=dict(visible=False, range=[0, 1]),\n        margin=dict(l=30, r=30, t=30, b=30),\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_lime_feature_importance","title":"explainability_lime_feature_importance","text":"<pre><code>explainability_lime_feature_importance()\n</code></pre> <p>Plot a horizontal bar chart showing LIME-based feature importance for the case.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_lime_feature_importance(self):\n    \"\"\"Plot a horizontal bar chart showing LIME-based feature importance for the case.\"\"\"\n    fig = go.Figure()\n\n    if len(list(self.lime_feature_importance.values())) &lt; 1:\n        return \"No Lime Feature Importance for the case\"\n\n    if isinstance(list(self.lime_feature_importance.values())[0], dict):\n        for col in self.lime_feature_importance.keys():\n            fig.add_trace(\n                go.Bar(\n                    x=list(self.lime_feature_importance[col].values()),\n                    y=list(self.lime_feature_importance[col].keys()),\n                    orientation=\"h\",\n                    name=col,\n                )\n            )\n    else:\n        fig.add_trace(\n            go.Bar(\n                x=list(self.lime_feature_importance.values()),\n                y=list(self.lime_feature_importance.keys()),\n                orientation=\"h\",\n            )\n        )\n    fig.update_layout(\n        barmode=\"relative\",\n        height=800,\n        width=800,\n        yaxis_autorange=\"reversed\",\n        bargap=0.01,\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=1.1,\n    )\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_observations","title":"explainability_observations","text":"<pre><code>explainability_observations()\n</code></pre> <p>Return a DataFrame listing the checklist of observations (e.g., heuristics or warnings) associated with the case.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>observations dataframe</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_observations(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame listing the checklist of observations (e.g., heuristics or warnings) associated with the case.\n\n    :return: observations dataframe\n    \"\"\"\n    observations_df = pd.DataFrame(self.observation_checklist)\n\n    return observations_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_policies","title":"explainability_policies","text":"<pre><code>explainability_policies()\n</code></pre> <p>Return a DataFrame listing policies or rules applied during the model\u2019s decision for the case.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>policies dataframe</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_policies(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame listing policies or rules applied during the model\u2019s decision for the case.\n\n    :return: policies dataframe\n    \"\"\"\n    policy_df = pd.DataFrame(self.policy_checklist)\n\n    return policy_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_prediction_path","title":"explainability_prediction_path","text":"<pre><code>explainability_prediction_path()\n</code></pre> <p>Display the model\u2019s prediction path as a sequence of decision nodes for the case, typically visualized as an SVG or plot.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_prediction_path(self):\n    \"\"\"Display the model\u2019s prediction path as a sequence of decision nodes for the case, typically visualized as an SVG or plot.\"\"\"\n    svg = SVG(self.case_prediction_svg)\n    display(svg)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_raw_data","title":"explainability_raw_data","text":"<pre><code>explainability_raw_data()\n</code></pre> <p>Return the raw data used for the case as a DataFrame, with feature names and values.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>raw data dataframe</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_raw_data(self) -&gt; pd.DataFrame:\n    \"\"\"Return the raw data used for the case as a DataFrame, with feature names and values.\n\n    :return: raw data dataframe\n    \"\"\"\n    raw_data_df = (\n        pd.DataFrame([self.data])\n        .transpose()\n        .reset_index()\n        .rename(columns={\"index\": \"Feature\", 0: \"Value\"})\n    )\n    return raw_data_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_shap","title":"explainability_shap","text":"<pre><code>explainability_shap()\n</code></pre> <p>Render a SHAP attribution plot for image cases, displaying attributions as an overlay on the original image.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_shap(self):\n    \"\"\"Render a SHAP attribution plot for image cases, displaying attributions as an overlay on the original image.\"\"\"\n    if not self.image_data.get(\"shap\", None):\n        return \"No Shap method found for this case\"\n    fig = go.Figure()\n\n    fig.add_layout_image(\n        dict(\n            source=self.image_data.get(\"shap\", {}).get(\"plot\"),\n            xref=\"x\",\n            yref=\"y\",\n            x=0,\n            y=1,\n            sizex=1,\n            sizey=1,\n            xanchor=\"left\",\n            yanchor=\"top\",\n            layer=\"below\",\n        )\n    )\n\n    fig.update_layout(\n        xaxis=dict(visible=False, range=[0, 2.5]),\n        yaxis=dict(visible=False, range=[0, 1]),\n        margin=dict(l=30, r=30, t=30, b=30),\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_shap_feature_importance","title":"explainability_shap_feature_importance","text":"<pre><code>explainability_shap_feature_importance()\n</code></pre> <p>Plot a horizontal bar chart showing SHAP-based feature importance for the case. Uses stored Shapley values for features.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_shap_feature_importance(self):\n    \"\"\"Plot a horizontal bar chart showing SHAP-based feature importance for the case. Uses stored Shapley values for features.\"\"\"\n    fig = go.Figure()\n\n    if len(list(self.shap_feature_importance.values())) &lt; 1:\n        return \"No Shap Feature Importance for the case\"\n\n    if isinstance(list(self.shap_feature_importance.values())[0], dict):\n        for col in self.shap_feature_importance.keys():\n            fig.add_trace(\n                go.Bar(\n                    x=list(self.shap_feature_importance[col].values()),\n                    y=list(self.shap_feature_importance[col].keys()),\n                    orientation=\"h\",\n                    name=col,\n                )\n            )\n    else:\n        fig.add_trace(\n            go.Bar(\n                x=list(self.shap_feature_importance.values()),\n                y=list(self.shap_feature_importance.keys()),\n                orientation=\"h\",\n            )\n        )\n    fig.update_layout(\n        barmode=\"relative\",\n        height=800,\n        width=800,\n        yaxis_autorange=\"reversed\",\n        bargap=0.01,\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=1.1,\n    )\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_similar_cases","title":"explainability_similar_cases","text":"<pre><code>explainability_similar_cases()\n</code></pre> <p>Return a DataFrame of cases similar to the current case (if similar cases are available). If no similar cases are found, returns a message.</p> <p>Returns:</p> Type Description <code>DataFrame | str</code> <p>similar cases dataframe</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_similar_cases(self) -&gt; pd.DataFrame | str:\n    \"\"\"Return a DataFrame of cases similar to the current case (if similar cases are available). If no similar cases are found, returns a message.\n\n    :return: similar cases dataframe\n    \"\"\"\n    if not self.similar_cases_data:\n        return \"No similar cases found. Or add 'similar_cases' in components case_info()\"\n\n    similar_cases_df = pd.DataFrame(self.similar_cases_data)\n    return similar_cases_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.explainability_summary","title":"explainability_summary","text":"<pre><code>explainability_summary()\n</code></pre> <p>Request or return cached explainability summary text. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_summary(self):\n    \"\"\"Request or return cached explainability summary text.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    if self.data_id and not self.summary:\n        payload = {\n            \"project_name\": self.project_name,\n            \"viewed_case_id\": self.data_id,\n        }\n        res = self.api_client.post(EXPLAINABILITY_SUMMARY, payload)\n        if not res.get(\"success\"):\n            raise Exception(res.get(\"details\", \"Failed to summarize\"))\n\n        self.summary = res.get(\"details\")\n        return res.get(\"details\")\n\n    return self.summary\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.Case.feature_importance","title":"feature_importance","text":"<pre><code>feature_importance(feature)\n</code></pre> <p>Return feature importance values for a specific feature. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def feature_importance(self, feature: str):\n    \"\"\"Return feature importance values for a specific feature.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    if self.shap_feature_importance:\n        return self.shap_feature_importance.get(feature, {})\n    elif self.lime_feature_importance:\n        return self.lime_feature_importance.get(feature, {})\n    elif self.ig_features_importance:\n        return self.ig_features_importance.get(feature, {})\n    else:\n        return \"No Feature Importance found for the case\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText","title":"CaseText","text":"<p>               Bases: <code>BaseModel</code></p> <p>Explainability view for text-based cases. Supports token-level importance, attention visualization, and LLM output analysis.</p>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.audit","title":"audit","text":"<pre><code>audit()\n</code></pre> <p>Return audit details for the text case. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def audit(self):\n    \"\"\"Return audit details for the text case.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    return self.audit_trail\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.explainability_feature_importance","title":"explainability_feature_importance","text":"<pre><code>explainability_feature_importance()\n</code></pre> <p>Plots Feature Importance chart Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_feature_importance(self):\n    \"\"\"Plots Feature Importance chart\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    fig = go.Figure()\n    feature_importance = self.explainability.get(\"feature_importance\", {})\n\n    if not feature_importance:\n        return \"No Feature Importance for the case\"\n    raw_data_df = (\n        pd.DataFrame([feature_importance])\n        .transpose()\n        .reset_index()\n        .rename(columns={\"index\": \"Feature\", 0: \"Value\"})\n        .sort_values(by=\"Value\", ascending=False)\n    )\n    fig.add_trace(\n        go.Bar(x=raw_data_df[\"Value\"], y=raw_data_df[\"Feature\"], orientation=\"h\")\n    )\n    fig.update_layout(\n        barmode=\"relative\",\n        height=max(400, len(raw_data_df) * 20),\n        width=800,\n        yaxis=dict(\n            autorange=\"reversed\",\n            tickmode=\"array\",\n            tickvals=list(raw_data_df[\"Feature\"]),\n            ticktext=list(raw_data_df[\"Feature\"]),\n            tickfont=dict(size=10),\n        ),\n        bargap=0.01,\n        margin=dict(l=150, r=20, t=30, b=30),\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=0.5,\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.explainability_raw_data","title":"explainability_raw_data","text":"<pre><code>explainability_raw_data()\n</code></pre> <p>Return the raw data used for the case as a DataFrame, with feature names and values.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>raw data dataframe</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def explainability_raw_data(self) -&gt; pd.DataFrame:\n    \"\"\"Return the raw data used for the case as a DataFrame, with feature names and values.\n\n    :return: raw data dataframe\n    \"\"\"\n    raw_data_df = (\n        pd.DataFrame([self.explainability.get(\"feature_importance\", {})])\n        .transpose()\n        .reset_index()\n        .rename(columns={\"index\": \"Feature\", 0: \"Value\"})\n        .sort_values(by=\"Value\", ascending=False)\n    )\n    return raw_data_df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.network_graph","title":"network_graph","text":"<pre><code>network_graph()\n</code></pre> <p>Decode and return a base64-encoded network graph image. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def network_graph(self):\n    \"\"\"Decode and return a base64-encoded network graph image.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    network_graph_data = self.explainability.get(\"network_graph\", {})\n    if not network_graph_data:\n        return \"No Network graph found for this case\"\n    base64_str = network_graph_data\n    try:\n        img_bytes = base64.b64decode(base64_str)\n        image = Image.open(BytesIO(img_bytes))\n        return image\n    except Exception as e:\n        print(f\"Error decoding base64 image: {e}\")\n        return None\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.output","title":"output","text":"<pre><code>output()\n</code></pre> <p>Get output Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def output(self):\n    \"\"\"Get output\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    return self.output\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.prompt","title":"prompt","text":"<pre><code>prompt()\n</code></pre> <p>Get prompt Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def prompt(self):\n    \"\"\"Get prompt\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    return self.prompt\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.case.CaseText.token_attribution_graph","title":"token_attribution_graph","text":"<pre><code>token_attribution_graph()\n</code></pre> <p>Decode and return a base64-encoded token attribution graph. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/case.py</code> <pre><code>def token_attribution_graph(self):\n    \"\"\"Decode and return a base64-encoded token attribution graph.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n    relevance_data = self.explainability.get(\"relevance\", {})\n    if not relevance_data:\n        return \"No Token Attribution graph found for this case\"\n    base64_str = relevance_data\n    try:\n        img_bytes = base64.b64decode(base64_str)\n        image = Image.open(BytesIO(img_bytes))\n        return image\n    except Exception as e:\n        print(f\"Error decoding base64 image: {e}\")\n        return None\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.dashboard.Dashboard","title":"Dashboard","text":"<pre><code>Dashboard(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Client-side wrapper for dashboards generated by Lexsi. Enables fetching dashboard metadata and underlying data used for monitoring and analysis.</p> <p>Print configuration then render the dashboard frame. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/dashboard.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Print configuration then render the dashboard frame.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n\n    self.print_config()\n    self.plot()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.dashboard.Dashboard.get_config","title":"get_config","text":"<pre><code>get_config()\n</code></pre> <p>Return a copy of the dashboard configuration dictionary (excluding metadata) so you can inspect settings like type and metrics.</p> Source code in <code>lexsi_sdk/core/dashboard.py</code> <pre><code>def get_config(self) -&gt; dict:\n    \"\"\"Return a copy of the dashboard configuration dictionary (excluding metadata) so you can inspect settings like type and metrics.\"\"\"\n    config_copy = {**self.config}\n    config_copy.pop(\"metadata\", None)\n    return config_copy\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.dashboard.Dashboard.get_raw_data","title":"get_raw_data","text":"<pre><code>get_raw_data()\n</code></pre> <p>Return a dictionary containing the raw data underlying the dashboard, tailored to the dashboard\u2019s type (e.g., data drift, target drift, performance metrics).</p> Source code in <code>lexsi_sdk/core/dashboard.py</code> <pre><code>def get_raw_data(self) -&gt; dict:\n    \"\"\"Return a dictionary containing the raw data underlying the dashboard, tailored to the dashboard\u2019s type (e.g., data drift, target drift, performance metrics).\"\"\"\n    raw_data = {\"created_at\": self.config.get(\"created_at\")}\n\n    if self.config[\"type\"] == \"data_drift\":\n        data_drift_table = next(\n            filter(\n                lambda data: data[\"metric\"] == \"DataDriftTable\",\n                self.raw_data.get(\"metrics\"),\n            ),\n            None,\n        )\n        if data_drift_table:\n            for item in data_drift_table[\"result\"].get(\"drift_by_columns\"):\n                item.pop(\"current_small_distribution\", None)\n                item.pop(\"reference_small_distribution\", None)\n                item.pop(\"current_big_distribution\", None)\n                item.pop(\"reference_big_distribution\", None)\n                item.pop(\"current_mean\", None)\n                item.pop(\"reference_std\", None)\n            raw_data.update(data_drift_table[\"result\"])\n\n    if self.config[\"type\"] == \"target_drift\":\n        column_drift_metric = next(\n            filter(\n                lambda data: data[\"metric\"] == \"ColumnDriftMetric\",\n                self.raw_data.get(\"metrics\"),\n            ),\n            None,\n        )\n        if column_drift_metric:\n            column_drift_metric[\"result\"].pop(\"data\", None)\n\n            raw_data.update(column_drift_metric[\"result\"])\n\n    if self.config[\"type\"] == \"performance\":\n        classification_quality_metric = next(\n            filter(\n                lambda data: data[\"metric\"] == \"ClassificationQualityMetric\",\n                self.raw_data.get(\"metrics\"),\n            ),\n            None,\n        )\n        if classification_quality_metric:\n            for curr_ref in [\"current\", \"reference\"]:\n                classification_quality_metric[\"result\"][curr_ref].pop(\n                    \"rate_plots_data\", None\n                )\n                classification_quality_metric[\"result\"][curr_ref].pop(\n                    \"plot_data\", None\n                )\n            raw_data.update(classification_quality_metric[\"result\"])\n\n    return raw_data\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.dashboard.Dashboard.plot","title":"plot","text":"<pre><code>plot(width='100%', height=800)\n</code></pre> <p>Render the dashboard in an iframe, specifying the width and height of the frame. Displays the HTML or fetches the dashboard from the SDK portal.</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>Width of the embedded frame.</p> <code>'100%'</code> <code>height</code> <code>int</code> <p>Height of the embedded frame.</p> <code>800</code> Source code in <code>lexsi_sdk/core/dashboard.py</code> <pre><code>def plot(self, width: int = \"100%\", height: int = 800):\n    \"\"\"Render the dashboard in an iframe, specifying the width and height of the frame. Displays the HTML or fetches the dashboard from the SDK portal.\n\n    :param width: Width of the embedded frame.\n    :param height: Height of the embedded frame.\n    \"\"\"\n    if isinstance(self.raw_data, str) and \"&lt;/html&gt;\" in self.raw_data:\n        display(HTML(self.raw_data))\n    else:\n        uri = os.environ.get(\"XAI_APP_URL\", XAI_APP_URI)\n        url = f\"{uri}/sdk/dashboard{self.query_params}\"\n        display(IFrame(src=f\"{url}\", width=width, height=height))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.dashboard.Dashboard.print_config","title":"print_config","text":"<pre><code>print_config()\n</code></pre> <p>Pretty-print the dashboard configuration in JSON format for inspection.</p> Source code in <code>lexsi_sdk/core/dashboard.py</code> <pre><code>def print_config(self):\n    \"\"\"Pretty-print the dashboard configuration in JSON format for inspection.\"\"\"\n    config = {k: v for k, v in self.config.items() if v is not None}\n    config.pop(\"metadata\", None)\n    print(\"Using config: \", end=\"\")\n    print(json.dumps(config, indent=4))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.alert.Alert","title":"Alert","text":"<pre><code>Alert(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Represents a monitoring alert generated by a model. Provides helper methods to inspect drift, unused features, and alert metadata.</p> <p>Initialize base model without extra behavior. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/alert.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize base model without extra behavior.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.alert.Alert.view_detailed_report","title":"view_detailed_report","text":"<pre><code>view_detailed_report()\n</code></pre> <p>Return a detailed report for the alert, containing analysis and potential remediation recommendations.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>description</p> Source code in <code>lexsi_sdk/core/alert.py</code> <pre><code>def view_detailed_report(self) -&gt; pd.DataFrame:\n    \"\"\"Return a detailed report for the alert, containing analysis and potential remediation recommendations.\n\n    :return: _description_\n    \"\"\"\n    if not self.detailed_report:\n        return \"No detailed report found for the alert.\"\n\n    if isinstance(self.detailed_report, list):\n        detailed_report = [\n            {\n                key: value\n                for key, value in feature.items()\n                if key != \"current_small_hist\" and key != \"ref_small_hist\"\n            }\n            for feature in self.detailed_report\n        ]\n    if isinstance(self.detailed_report, dict):\n        detailed_report = [self.detailed_report]\n\n    return pd.DataFrame(detailed_report)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.alert.Alert.view_info","title":"view_info","text":"<pre><code>view_info()\n</code></pre> <p>Return basic information about an alert, such as its type, category, severity, and timestamp.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>description</p> Source code in <code>lexsi_sdk/core/alert.py</code> <pre><code>def view_info(self) -&gt; pd.DataFrame:\n    \"\"\"Return basic information about an alert, such as its type, category, severity, and timestamp.\n\n    :return: _description_\n    \"\"\"\n    if not self.info:\n        return \"There was an error while executing the alert.\"\n\n    return pd.DataFrame([self.info])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.alert.Alert.view_not_used_features","title":"view_not_used_features","text":"<pre><code>view_not_used_features()\n</code></pre> <p>Return features that were not used in the model\u2019s decision-making for the alert. Helps identify features excluded from analysis.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>description</p> Source code in <code>lexsi_sdk/core/alert.py</code> <pre><code>def view_not_used_features(self) -&gt; pd.DataFrame:\n    \"\"\"Return features that were not used in the model\u2019s decision-making for the alert. Helps identify features excluded from analysis.\n\n    :return: _description_\n    \"\"\"\n    if not self.not_used_features:\n        return \"Not used features is empty.\"\n\n    return pd.DataFrame(self.not_used_features)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject","title":"TextProject","text":"<pre><code>TextProject(**kwargs)\n</code></pre> <p>               Bases: <code>Project</code></p> <p>Specialized project abstraction for text and LLM-based workloads. Supports sessions, messages, traces, guardrails, and token-level explainability.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize a `Project` instance and attach the API client.\n    Populates model fields from `kwargs` and stores `api_client` for later requests.\n\n    :param kwargs: Project fields used to construct the instance (including `api_client`).\n    \"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.available_guardrails","title":"available_guardrails","text":"<pre><code>available_guardrails()\n</code></pre> <p>Return a DataFrame of all guardrails available to configure in this project. Each row describes a single guardrail type.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing all available guardrail types</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def available_guardrails(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame of all guardrails available to configure in this project.\n    Each row describes a single guardrail type.\n\n    :return: a DataFrame containing all available guardrail types\n    \"\"\"\n    res = self.api_client.get(AVAILABLE_GUARDRAILS_URI)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.chat_completion","title":"chat_completion","text":"<pre><code>chat_completion(\n    model,\n    messages,\n    provider,\n    api_key=None,\n    session_id=None,\n    max_tokens=None,\n    stream=False,\n)\n</code></pre> <p>Generate a chat completion using an OpenAI-compliant interface.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the model to use for generating the chat completion</p> required <code>messages</code> <code>List[Dict[str, Any]]</code> <p>List of chat messages, where each message contains a role and content</p> required <code>provider</code> <code>str</code> <p>Model provider (e.g., \"OpenAI\", \"Anthropic\")</p> required <code>api_key</code> <code>Optional[str]</code> <p>API key for the selected provider, if required</p> <code>None</code> <code>session_id</code> <code>Optional[UUID]</code> <p>Session ID associated with this chat completion, if provided</p> <code>None</code> <code>max_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>stream</code> <code>Optional[bool]</code> <p>Whether to stream the response</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[dict, Iterator[str]]</code> <p>a chat completion response dictionary or a streaming iterator of response chunks</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def chat_completion(\n    self,\n    model: str,\n    messages: List[Dict[str, Any]],\n    provider: str,\n    api_key: Optional[str] = None,\n    session_id: Optional[UUID] = None,\n    max_tokens: Optional[int] = None,\n    stream: Optional[bool] = False,\n) -&gt; Union[dict, Iterator[str]]:\n    \"\"\"Generate a chat completion using an OpenAI-compliant interface.\n\n    :param model: Name of the model to use for generating the chat completion\n    :param messages: List of chat messages, where each message contains a role and content\n    :param provider: Model provider (e.g., \"OpenAI\", \"Anthropic\")\n    :param api_key: API key for the selected provider, if required\n    :param session_id: Session ID associated with this chat completion, if provided\n    :param max_tokens: Maximum number of tokens to generate\n    :param stream: Whether to stream the response\n    :return: a chat completion response dictionary or a streaming iterator of response chunks\n    \"\"\"\n    payload = {\n        \"model\": model,\n        \"messages\": messages,\n        \"max_tokens\": max_tokens,\n        \"stream\": stream,\n        \"project_name\": self.project_name,\n        \"provider\": provider,\n        \"api_key\": api_key,\n        \"session_id\": session_id,\n    }\n\n    if not stream:\n        return self.api_client.post(RUN_CHAT_COMPLETION, payload=payload)\n\n    return self.api_client.stream(\n        uri=RUN_CHAT_COMPLETION, method=\"POST\", payload=payload\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.completion","title":"completion","text":"<pre><code>completion(\n    model,\n    prompt,\n    provider,\n    api_key=None,\n    session_id=None,\n    max_tokens=None,\n    stream=False,\n)\n</code></pre> <p>Generate a text completion using an OpenAI-compliant interface.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the model to use for generating the completion</p> required <code>prompt</code> <code>str</code> <p>Input prompt to be provided to the model</p> required <code>provider</code> <code>str</code> <p>Model provider (e.g., \"OpenAI\", \"Anthropic\")</p> required <code>api_key</code> <code>Optional[str]</code> <p>API key for the selected provider, if required</p> <code>None</code> <code>session_id</code> <code>Optional[UUID]</code> <p>Session ID associated with this completion request, if provided</p> <code>None</code> <code>max_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>stream</code> <code>Optional[bool]</code> <p>Whether to stream the response</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>a completion response dictionary or a streaming iterator of response chunks</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def completion(\n    self,\n    model: str,\n    prompt: str,\n    provider: str,\n    api_key: Optional[str] = None,\n    session_id: Optional[UUID] = None,\n    max_tokens: Optional[int] = None,\n    stream: Optional[bool] = False,\n) -&gt; dict:\n    \"\"\"Generate a text completion using an OpenAI-compliant interface.\n\n    :param model: Name of the model to use for generating the completion\n    :param prompt: Input prompt to be provided to the model\n    :param provider: Model provider (e.g., \"OpenAI\", \"Anthropic\")\n    :param api_key: API key for the selected provider, if required\n    :param session_id: Session ID associated with this completion request, if provided\n    :param max_tokens: Maximum number of tokens to generate\n    :param stream: Whether to stream the response\n    :return: a completion response dictionary or a streaming iterator of response chunks\n    \"\"\"\n\n    payload = {\n        \"model\": model,\n        \"prompt\": prompt,\n        \"max_tokens\": max_tokens,\n        \"stream\": stream,\n        \"project_name\": self.project_name,\n        \"provider\": provider,\n        \"api_key\": api_key,\n        \"session_id\": session_id,\n    }\n    if not stream:\n        return self.api_client.post(RUN_COMPLETION, payload=payload)\n\n    return self.api_client.stream(\n        uri=RUN_COMPLETION, method=\"POST\", payload=payload\n    )\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.configure_guardrail","title":"configure_guardrail","text":"<pre><code>configure_guardrail(\n    guardrail_name, guardrail_config, model_name, apply_on\n)\n</code></pre> <p>Configure a new guardrail in the project. Requires the guardrail name, a configuration dictionary, the model name, and where to apply it (input or output). Returns a confirmation message.</p> <p>Parameters:</p> Name Type Description Default <code>guardrail_name</code> <code>str</code> <p>Name of the guardrail</p> required <code>guardrail_config</code> <code>dict</code> <p>Configuration dictionary for the guardrail</p> required <code>model_name</code> <code>str</code> <p>Name of the model to which the guardrail applies</p> required <code>apply_on</code> <code>str</code> <p>Specifies when to apply the guardrail (\"input\" or \"output\")</p> required <p>Returns:</p> Type Description <code>str</code> <p>a response indicating the result of the configuration operation</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def configure_guardrail(\n    self,\n    guardrail_name: str,\n    guardrail_config: dict,\n    model_name: str,\n    apply_on: str,\n) -&gt; str:\n    \"\"\"Configure a new guardrail in the project.\n    Requires the guardrail name, a configuration dictionary, the model name, and where to apply it (input or output).\n    Returns a confirmation message.\n\n    :param guardrail_name: Name of the guardrail\n    :param guardrail_config: Configuration dictionary for the guardrail\n    :param model_name: Name of the model to which the guardrail applies\n    :param apply_on: Specifies when to apply the guardrail (\"input\" or \"output\")\n    :return: a response indicating the result of the configuration operation\n    \"\"\"\n    payload = {\n        \"name\": guardrail_name,\n        \"config\": guardrail_config,\n        \"model_name\": model_name,\n        \"apply_on\": apply_on,\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(CONFIGURE_GUARDRAILS_URI, payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.create_embeddings","title":"create_embeddings","text":"<pre><code>create_embeddings(\n    input, model, provider, api_key=None, session_id=None\n)\n</code></pre> <p>Create embeddings using an OpenAI-compliant embeddings interface.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str]]</code> <p>Input text or list of text strings to generate embeddings for</p> required <code>model</code> <code>str</code> <p>Name of the model to use for generating embeddings</p> required <code>provider</code> <code>str</code> <p>Model provider (e.g., \"OpenAI\", \"Anthropic\")</p> required <code>api_key</code> <code>Optional[str]</code> <p>API key for the selected provider, if required</p> <code>None</code> <code>session_id</code> <code>Optional[UUID]</code> <p>Session ID associated with this embeddings request, if provided</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>a dictionary containing the embeddings response</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def create_embeddings(\n    self,\n    input: Union[str, List[str]],\n    model: str,\n    provider: str,\n    api_key : Optional[str] = None,\n    session_id : Optional[UUID] = None,\n) -&gt; dict:  \n    \"\"\"Create embeddings using an OpenAI-compliant embeddings interface.\n\n    :param input: Input text or list of text strings to generate embeddings for\n    :param model: Name of the model to use for generating embeddings\n    :param provider: Model provider (e.g., \"OpenAI\", \"Anthropic\")\n    :param api_key: API key for the selected provider, if required\n    :param session_id: Session ID associated with this embeddings request, if provided\n    :return: a dictionary containing the embeddings response\n    \"\"\"\n    payload = {\n        \"model\": model,\n        \"input\": input,\n        \"project_name\": self.project_name,\n        \"provider\": provider,\n        \"api_key\": api_key,\n        \"session_id\": session_id,\n    }\n\n    res = self.api_client.post(RUN_CREATE_EMBEDDING, payload=payload)\n    return res\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.delete_guardrail","title":"delete_guardrail","text":"<pre><code>delete_guardrail(guardrail_id)\n</code></pre> <p>Delete a guardrail from the project using its ID. Returns the API response message.</p> <p>Parameters:</p> Name Type Description Default <code>guardrail_id</code> <code>str</code> <p>ID of the guardrail</p> required <p>Returns:</p> Type Description <code>str</code> <p>a response indicating the result of the delete operation</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def delete_guardrail(self, guardrail_id: str) -&gt; str:\n    \"\"\"Delete a guardrail from the project using its ID.\n    Returns the API response message.\n\n    :param guardrail_id: ID of the guardrail\n    :return: a response indicating the result of the delete operation\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"guardrail_id\": guardrail_id,\n    }\n    res = self.api_client.post(DELETE_GUARDRAILS_URI, payload=payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.generate_text_case","title":"generate_text_case","text":"<pre><code>generate_text_case(\n    model_name,\n    prompt,\n    serverless_instance_type,\n    instance_type=None,\n    explainability_method=[\"DLB\"],\n    explain_model=False,\n    session_id=None,\n    max_tokens=None,\n    min_tokens=None,\n    stream=False,\n)\n</code></pre> <p>Generate a text inference case using the specified model and prompt.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Name of the model to use for text generation</p> required <code>prompt</code> <code>str</code> <p>Input prompt to be provided to the model</p> required <code>serverless_instance_type</code> <code>ServerlessInstanceTypeValues</code> <p>Serverless instance type used for case inference Use str values from supported instance types defined in classes: - <code>ServerlessInstanceTypeValues</code></p> required <code>instance_type</code> <code>Optional[Union[BatchCPUInstanceTypeValues, BatchGPUInstanceTypeValues]]</code> <p>Instance type used for explainability processing, defaults to None Use str values from supported instance types defined in classes: - <code>BatchCPUInstanceTypeValues</code> - <code>BatchGPUInstanceTypeValues</code></p> <code>None</code> <code>explainability_method</code> <code>Optional[list]</code> <p>Explainability method(s) for the case, defaults to [\"DLB\"]</p> <code>['DLB']</code> <code>explain_model</code> <code>Optional[bool]</code> <p>Boolean flag indicating whether to run explainability for the case, defaults to False</p> <code>False</code> <code>session_id</code> <code>Optional[str]</code> <p>Session ID associated with this case, if applicable</p> <code>None</code> <code>max_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>min_tokens</code> <code>Optional[int]</code> <p>Minimum number of tokens to generate</p> <code>None</code> <code>stream</code> <code>Optional[bool]</code> <p>Whether to stream the response</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>a dictionary containing the generated text and related metadata</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def generate_text_case(\n    self,\n    model_name: str,\n    prompt: str,\n    serverless_instance_type: ServerlessInstanceTypeValues,\n    instance_type: Optional[Union[BatchCPUInstanceTypeValues, BatchGPUInstanceTypeValues]] = None,\n    explainability_method: Optional[list] = [\"DLB\"],\n    explain_model: Optional[bool] = False,\n    session_id: Optional[str] = None,\n    max_tokens: Optional[int] = None,\n    min_tokens: Optional[int] = None,\n    stream: Optional[bool] = False,\n) -&gt; dict:\n    \"\"\"Generate a text inference case using the specified model and prompt.\n\n    :param model_name: Name of the model to use for text generation\n    :param prompt: Input prompt to be provided to the model\n    :param serverless_instance_type: Serverless instance type used for case inference\n        Use str values from supported instance types defined in classes:\n        - ``ServerlessInstanceTypeValues``\n    :param instance_type: Instance type used for explainability processing, defaults to None\n        Use str values from supported instance types defined in classes:\n        - ``BatchCPUInstanceTypeValues``\n        - ``BatchGPUInstanceTypeValues``\n    :param explainability_method: Explainability method(s) for the case, defaults to [\"DLB\"]\n    :param explain_model: Boolean flag indicating whether to run explainability for the case, defaults to False\n    :param session_id: Session ID associated with this case, if applicable\n    :param max_tokens: Maximum number of tokens to generate\n    :param min_tokens: Minimum number of tokens to generate\n    :param stream: Whether to stream the response\n    :return: a dictionary containing the generated text and related metadata\n    \"\"\"\n    if explain_model and not instance_type:\n        raise Exception(\"instance_type required for explainability.\")\n    llm = monitor(\n        project=self,\n        client=LexsiModels(project=self, api_client=self.api_client),\n        session_id=session_id,\n    )\n    res = llm.generate_text_case(\n        model_name=model_name,\n        prompt=prompt,\n        instance_type=instance_type,\n        serverless_instance_type=serverless_instance_type,\n        explainability_method=explainability_method,\n        explain_model=explain_model,\n        max_tokens=max_tokens,\n        min_tokens=min_tokens,\n        stream=stream,\n    )\n    return res\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.guardrails","title":"guardrails","text":"<pre><code>guardrails()\n</code></pre> <p>List all guardrails currently configured for the project. Returns a DataFrame describing each guardrail and its configuration.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing the configured guardrails and their details</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def guardrails(self) -&gt; pd.DataFrame:\n    \"\"\"List all guardrails currently configured for the project.\n    Returns a DataFrame describing each guardrail and its configuration.\n\n    :return: a DataFrame containing the configured guardrails and their details\n    \"\"\"\n    res = self.api_client.get(\n        f\"{GET_GUARDRAILS_URI}?project_name={self.project_name}\"\n    )\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.image_generation","title":"image_generation","text":"<pre><code>image_generation(\n    model, prompt, provider, api_key=None, session_id=None\n)\n</code></pre> <p>Generate images using an OpenAI-compliant image generation interface.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the model to use for image generation</p> required <code>prompt</code> <code>str</code> <p>Text prompt describing the image to generate</p> required <code>provider</code> <code>str</code> <p>Model provider (e.g., \"OpenAI\", \"Anthropic\")</p> required <code>api_key</code> <code>Optional[str]</code> <p>API key for the selected provider, if required</p> <code>None</code> <code>session_id</code> <code>Optional[UUID]</code> <p>Session ID associated with this image generation request, if provided</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>a dictionary containing the image generation response</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def image_generation(\n    self,\n    model: str,\n    prompt: str,\n    provider: str,\n    api_key: Optional[str] = None,\n    session_id : Optional[UUID] = None,\n) -&gt; dict:\n    \"\"\"Generate images using an OpenAI-compliant image generation interface.\n\n    :param model: Name of the model to use for image generation\n    :param prompt: Text prompt describing the image to generate\n    :param provider: Model provider (e.g., \"OpenAI\", \"Anthropic\")\n    :param api_key: API key for the selected provider, if required\n    :param session_id: Session ID associated with this image generation request, if provided\n    :return: a dictionary containing the image generation response\n    \"\"\"\n\n    payload = {\n        \"model\": model,\n        \"prompt\": prompt,\n        \"project_name\": self.project_name,\n        \"provider\": provider,\n        \"api_key\": api_key,\n        \"session_id\": session_id,\n    }\n\n    res = self.api_client.post(RUN_IMAGE_GENERATION, payload=payload)\n\n    return res\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.initialize_text_model","title":"initialize_text_model","text":"<pre><code>initialize_text_model(\n    model_provider,\n    model_name,\n    model_task_type,\n    model_type,\n    inference_compute=None,\n    inference_settings=None,\n    assets=None,\n    requirements_file=None,\n    app_file=None,\n)\n</code></pre> <p>Initialize a text model for the project, specifying the model provider, model name, task type, model type (classification/regression), inference compute settings, inference settings, and optional assets. Polls for completion and returns when done.</p> <p>Parameters:</p> Name Type Description Default <code>model_provider</code> <code>str</code> <p>model provider name for initialization Model Providers - <code>Hugging Face</code> - <code>OpenAI</code> - <code>Anthropic</code> - <code>Groq</code> - <code>Grok</code> - <code>Gemini</code> - <code>Together</code> - <code>Replicate</code> - <code>Mistral</code> - <code>AWS Bedrock</code> - <code>Open Router</code></p> required <code>model_name</code> <code>str</code> <p>name of the model to be initialized (e.g., meta-llama/Llama-3.2-1B-Instruct).</p> required <code>model_task_type</code> <code>str</code> <p>task type of model Model Task Types - <code>question-answering</code> - <code>summarization</code> - <code>text-classification</code> - <code>text-generation</code> - <code>text2text-generation</code> - <code>token-classification</code></p> required <code>model_type</code> <code>str</code> <p>architecture of the model to be initialized Model Types - <code>bert</code> - <code>llm</code></p> required <code>inference_compute</code> <code>Optional[InferenceCompute]</code> <p>inference compute configuration used to run the model during inference (e.g., CPU/GPU type, memory, replicas, and other hardware or scaling settings). Required for the Hugging Face provider models, not required for other providers</p> <code>None</code> <code>inference_settings</code> <code>Optional[InferenceSettings]</code> <p>inference runtime settings. Required for the Hugging Face provider models, not required for other providers</p> <code>None</code> <code>assets</code> <code>Optional[dict]</code> <p>assets required for the model, including provider credentials, access tokens, or other secrets needed at runtime (e.g., {\"HF_TOKEN\":\"hf_njbjkfdsnjfkdnskbfk\"}).</p> <code>None</code> <code>requirements_file</code> <code>Optional[str]</code> <p>file path for the requirements file a YAML file defining the runtime environment, including base Docker image, system-level dependencies, and Python packages required for model deployment. Not required for the transformers serverless inference engine.  Example:: image: nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04 system_packages: - build-essential python_packages: - fastapi&gt;=0.115.5 - uvicorn&gt;=0.30.6 - transformers==4.52.3 - pydantic&gt;=2.9.2 - torch==2.7.0 - accelerate==1.8.1</p> <code>None</code> <code>app_file</code> <code>Optional[str]</code> <p>file path for the app file a Python application file that implements the model inference logic, including how inputs are processed and how predictions are generated and returned</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>response</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def initialize_text_model(\n    self, \n    model_provider: str, \n    model_name: str, \n    model_task_type:str, \n    model_type: str,  \n    inference_compute: Optional[InferenceCompute] = None,\n    inference_settings: Optional[InferenceSettings] = None,\n    assets: Optional[dict] = None,\n    requirements_file: Optional[str] = None,\n    app_file: Optional[str] = None\n) -&gt; str:\n    \"\"\"Initialize a text model for the project, specifying the model provider, model name, task type, model type (classification/regression), inference compute settings, inference settings, and optional assets. Polls for completion and returns when done.\n\n    :param model_provider: model provider name for initialization\n        **Model Providers**\n        - ``Hugging Face``\n        - ``OpenAI``\n        - ``Anthropic``\n        - ``Groq``\n        - ``Grok``\n        - ``Gemini``\n        - ``Together``\n        - ``Replicate``\n        - ``Mistral``\n        - ``AWS Bedrock``\n        - ``Open Router``\n\n    :param model_name: name of the model to be initialized\n        (e.g., meta-llama/Llama-3.2-1B-Instruct).\n\n    :param model_task_type: task type of model\n        **Model Task Types**\n        - ``question-answering``\n        - ``summarization``\n        - ``text-classification``\n        - ``text-generation``\n        - ``text2text-generation``\n        - ``token-classification``\n\n    :param model_type: architecture of the model to be initialized\n        **Model Types**\n        - ``bert``\n        - ``llm``\n\n    :param inference_compute: inference compute configuration used to run the model during inference\n        (e.g., CPU/GPU type, memory, replicas, and other hardware or scaling settings).\n        Required for the Hugging Face provider models, not required for other providers\n    :type inference_compute: InferenceCompute | None\n\n    :param inference_settings: inference runtime settings.\n        Required for the Hugging Face provider models, not required for other providers\n    :type inference_settings: InferenceSettings | None\n\n    :param assets: assets required for the model, including provider credentials, access tokens,\n        or other secrets needed at runtime\n        (e.g., {\"HF_TOKEN\":\"hf_njbjkfdsnjfkdnskbfk\"}).\n\n    :param requirements_file: file path for the requirements file\n        a YAML file defining the runtime environment, including base Docker image,\n        system-level dependencies, and Python packages required for model deployment.\n        Not required for the transformers serverless inference engine.\n\n        Example::\n            image: nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04\n            system_packages:\n                - build-essential\n            python_packages:\n                - fastapi&gt;=0.115.5\n                - uvicorn&gt;=0.30.6\n                - transformers==4.52.3\n                - pydantic&gt;=2.9.2\n                - torch==2.7.0\n                - accelerate==1.8.1\n\n    :param app_file: file path for the app file\n        a Python application file that implements the model inference logic,\n        including how inputs are processed and how predictions are generated and returned\n\n    :return: response\n    \"\"\"\n    data = {\n        \"model_provider\": model_provider,\n        \"model_name\": model_name,\n        \"model_task_type\": model_task_type,\n        \"project_name\": self.project_name,\n        \"model_type\": model_type,\n        \"inference_compute\": inference_compute,\n        \"inference_settings\": inference_settings,\n        \"assets\": assets\n    }\n\n    payload ={\n        \"data\": (None,json.dumps(data)),\n    }\n    if requirements_file:\n        payload[\"requirements_file\"] = (\"requirements.yaml\", open(requirements_file, \"rb\"))\n    if app_file:\n        payload[\"app_file\"] = (\"app.py\", open(app_file, \"rb\"))\n\n    res = self.api_client.file(f\"{INITIALIZE_TEXT_MODEL_URI}\", payload)\n    if not res.get(\"success\"):\n        raise Exception(res.get(\"details\", \"Model Initialization Failed\"))\n    poll_events(self.api_client, self.project_name, res[\"event_id\"])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.llm_monitor","title":"llm_monitor","text":"<pre><code>llm_monitor(client, session_id=None)\n</code></pre> <p>Monitor a custom large language model (LLM) client for inference. Accepts a client object (e.g., an OpenAI API wrapper) and an optional session_id to monitor a specific conversation.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <p>client to monitor like OpenAI</p> required <code>session_id</code> <p>id of the session</p> <code>None</code> <p>Returns:</p> Type Description <p>response</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def llm_monitor(self, client, session_id=None):\n    \"\"\"Monitor a custom large language model (LLM) client for inference. Accepts a client object (e.g., an OpenAI API wrapper) and an optional session_id to monitor a specific conversation.\n\n    :param client: client to monitor like OpenAI\n    :param session_id: id of the session\n    :return: response\n    \"\"\"\n    return monitor(project=self, client=client, session_id=session_id)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.messages","title":"messages","text":"<pre><code>messages(session_id)\n</code></pre> <p>Return a DataFrame listing all messages in a given session. Requires the session_id. Each row corresponds to a single message record.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>UUID of the session (e.g., 10f2510c-17dd-4b99-8926-ef4625513a2f).</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing all messages for the specified session</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def messages(self, session_id: str) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame listing all messages in a given session. Requires the session_id.\n    Each row corresponds to a single message record.\n\n    :param session_id: UUID of the session\n        (e.g., 10f2510c-17dd-4b99-8926-ef4625513a2f).\n    :return: a DataFrame containing all messages for the specified session\n    \"\"\"\n    res = self.api_client.get(\n        f\"{MESSAGES_URI}?project_name={self.project_name}&amp;session_id={session_id}\"\n    )\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.model_inference_settings","title":"model_inference_settings","text":"<pre><code>model_inference_settings(\n    model_name, inference_compute, inference_settings\n)\n</code></pre> <p>Configure inference compute and runtime settings for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Name of the model for inference settings update (e.g., meta-llama/Llama-3.2-1B-Instruct).</p> required <code>inference_compute</code> <code>InferenceCompute</code> <p>Inference compute configuration for the model. Required for Hugging Face provider models, not required for other providers</p> required <code>inference_settings</code> <code>InferenceSettings</code> <p>Inference runtime settings for the model. Required for Hugging Face provider models, not required for other providers</p> required <p>Returns:</p> Type Description <code>str</code> <p>a response indicating the result of the inference settings configuration</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def model_inference_settings(\n    self,\n    model_name: str,\n    inference_compute: InferenceCompute,\n    inference_settings: InferenceSettings,\n) -&gt; str:\n    \"\"\"Configure inference compute and runtime settings for a model.\n\n    :param model_name: Name of the model for inference settings update\n        (e.g., meta-llama/Llama-3.2-1B-Instruct).\n\n    :param inference_compute: Inference compute configuration for the model.\n        Required for Hugging Face provider models, not required for other providers\n    :type inference_compute: InferenceCompute | None\n\n    :param inference_settings: Inference runtime settings for the model.\n        Required for Hugging Face provider models, not required for other providers\n    :type inference_settings: InferenceSettings | None\n\n    :return: a response indicating the result of the inference settings configuration\n    \"\"\"\n    payload = {\n        \"model_name\": model_name,\n        \"project_name\": self.project_name,\n        \"inference_compute\": inference_compute,\n        \"inference_settings\": inference_settings,\n    }\n\n    res = self.api_client.post(f\"{TEXT_MODEL_INFERENCE_SETTINGS_URI}\", payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\", \"Failed to update inference settings\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.quantize_model","title":"quantize_model","text":"<pre><code>quantize_model(\n    model_name,\n    quant_name,\n    quantization_type,\n    qbit,\n    instance_type,\n    tag=None,\n    input_column=None,\n    no_of_samples=None,\n)\n</code></pre> <p>Quantize a trained model to reduce its size and improve inference efficiency. Requires the model name, quantization method, quantization type,number of bits, and compute instance type.  Optional parameters allow specifying a tag,input column, and number of samples used during quantization.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Name of the base model to be quantized</p> required <code>quant_name</code> <code>str</code> <p>Name of the quantization method to use Quantization Methods - <code>quanto</code> - <code>bnb</code> - <code>hqq</code> - <code>torchao</code> - <code>gptq</code> - <code>awq</code> - <code>llmcomp-awq</code> - <code>llmcomp-gptq</code> - <code>llmcomp-simple</code> - <code>llmcomp-smoothquant</code></p> required <code>quantization_type</code> <code>str</code> <p>Type of quantization to apply Quantization Types - <code>static</code> - <code>dynamic</code></p> required <code>qbit</code> <code>int</code> <p>Number of bits to use for quantization Quantization Bits - <code>4</code> - <code>8</code></p> required <code>instance_type</code> <code>str</code> <p>Instance type used for performing quantization</p> required <code>tag</code> <code>Optional[str]</code> <p>Optional tag name to associate with the quantized model</p> <code>None</code> <code>input_column</code> <code>Optional[str]</code> <p>Optional input column used from the dataset for quantization</p> <code>None</code> <code>no_of_samples</code> <code>Optional[str]</code> <p>Optional number of samples to use for quantization</p> <code>None</code> <p>Returns:</p> Type Description <p>a response indicating the result of the quantization operation</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def quantize_model(\n    self,\n    model_name: str,\n    quant_name: str,\n    quantization_type: str,\n    qbit: int,\n    instance_type: str,\n    tag: Optional[str] = None,\n    input_column: Optional[str] = None,\n    no_of_samples: Optional[str] = None,\n):\n    \"\"\"Quantize a trained model to reduce its size and improve inference efficiency.\n    Requires the model name, quantization method, quantization type,number of bits, and compute instance type. \n    Optional parameters allow specifying a tag,input column, and number of samples used during quantization.\n\n    :param model_name: Name of the base model to be quantized\n    :param quant_name: Name of the quantization method to use\n        **Quantization Methods**\n        - ``quanto``\n        - ``bnb``\n        - ``hqq``\n        - ``torchao``\n        - ``gptq``\n        - ``awq``\n        - ``llmcomp-awq``\n        - ``llmcomp-gptq``\n        - ``llmcomp-simple``\n        - ``llmcomp-smoothquant``\n    :param quantization_type: Type of quantization to apply\n        **Quantization Types**\n        - ``static``\n        - ``dynamic``\n    :param qbit: Number of bits to use for quantization\n        **Quantization Bits**\n        - ``4``\n        - ``8``\n    :param instance_type: Instance type used for performing quantization\n    :param tag: Optional tag name to associate with the quantized model\n    :param input_column: Optional input column used from the dataset for quantization\n    :param no_of_samples: Optional number of samples to use for quantization\n    :return: a response indicating the result of the quantization operation\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": model_name,\n        \"quant_name\": quant_name,\n        \"quantization_type\": quantization_type,\n        \"qbit\": qbit,\n        \"instance_type\": instance_type,\n        \"tag\": tag,\n        \"input_column\": input_column,\n        \"no_of_samples\": no_of_samples,\n    }\n\n    res = self.api_client.post(QUANTIZE_MODELS_URI, payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    poll_events(self.api_client, self.project_name, res.get(\"event_id\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.sessions","title":"sessions","text":"<pre><code>sessions()\n</code></pre> <p>Return a DataFrame listing all conversation sessions for this text project. Each row corresponds to a single session metadata record.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing the conversation session metadata</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def sessions(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame listing all conversation sessions for this text project.\n    Each row corresponds to a single session metadata record.\n\n    :return: a DataFrame containing the conversation session metadata\n    \"\"\"\n    res = self.api_client.get(f\"{SESSIONS_URI}?project_name={self.project_name}\")\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.traces","title":"traces","text":"<pre><code>traces(trace_id)\n</code></pre> <p>Retrieve the execution traces for a given trace ID and return them as a DataFrame. Each row corresponds to a single trace record.</p> <p>Parameters:</p> Name Type Description Default <code>trace_id</code> <code>str</code> <p>UUID of the trace (e.g., 10f2510c-17dd-4b99-8926-ef4625513a2f).</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing the execution traces for the specified trace ID</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def traces(self, trace_id: str) -&gt; pd.DataFrame:\n    \"\"\"Retrieve the execution traces for a given trace ID and return them as a DataFrame.\n    Each row corresponds to a single trace record.\n\n    :param trace_id: UUID of the trace\n        (e.g., 10f2510c-17dd-4b99-8926-ef4625513a2f).\n    :return: a DataFrame containing the execution traces for the specified trace ID\n    \"\"\"\n    res = self.api_client.get(\n        f\"{TRACES_URI}?project_name={self.project_name}&amp;trace_id={trace_id}\"\n    )\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.update_guardrail_status","title":"update_guardrail_status","text":"<pre><code>update_guardrail_status(guardrail_id, status)\n</code></pre> <p>Update the status (active or inactive) of a specified guardrail. Requires the guardrail_id and a boolean status value.</p> <p>Parameters:</p> Name Type Description Default <code>guardrail_id</code> <code>str</code> <p>ID of the guardrail</p> required <code>status</code> <code>bool</code> <p>Boolean value indicating whether the guardrail should be active (True) or inactive (False)</p> required <p>Returns:</p> Type Description <code>str</code> <p>a response indicating the result of the update operation</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def update_guardrail_status(self, guardrail_id: str, status: bool) -&gt; str:\n    \"\"\"Update the status (active or inactive) of a specified guardrail.\n    Requires the guardrail_id and a boolean status value.\n\n    :param guardrail_id: ID of the guardrail\n    :param status: Boolean value indicating whether the guardrail should be active (True) or inactive (False)\n    :return: a response indicating the result of the update operation\n    \"\"\"\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"guardrail_id\": guardrail_id,\n        \"status\": status,\n    }\n    res = self.api_client.post(UPDATE_GUARDRAILS_STATUS_URI, payload=payload)\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.upload_data","title":"upload_data","text":"<pre><code>upload_data(data, tag)\n</code></pre> <p>Upload text data to the project by specifying either a file path or a pandas DataFrame and a tag. Handles conversion to CSV for DataFrame uploads and returns the API response.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | DataFrame</code> <p>File path or pandas DataFrame containing the rows to upload</p> required <code>tag</code> <code>str</code> <p>Tag to associate with the uploaded data</p> required <p>Returns:</p> Type Description <code>str</code> <p>a response containing the server\u2019s upload result</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def upload_data(\n    self,\n    data: str | pd.DataFrame,\n    tag: str,\n) -&gt; str:\n    \"\"\"Upload text data to the project by specifying either a file path or a pandas DataFrame and a tag.\n    Handles conversion to CSV for DataFrame uploads and returns the API response.\n\n    :param data: File path or pandas DataFrame containing the rows to upload\n    :param tag: Tag to associate with the uploaded data\n    :return: a response containing the server\u2019s upload result\n    \"\"\"\n\n    def build_upload_data(data):\n        \"\"\"Prepare file payload from path or DataFrame.\n\n        :param data: File path or DataFrame to convert.\n        :return: Tuple or file handle suitable for multipart upload.\n        \"\"\"\n        if isinstance(data, str):\n            file = open(data, \"rb\")\n            return file\n        elif isinstance(data, pd.DataFrame):\n            csv_buffer = io.BytesIO()\n            data.to_csv(csv_buffer, index=False, encoding=\"utf-8\")\n            csv_buffer.seek(0)\n            file_name = f\"{tag}_sdk_{datetime.now().replace(microsecond=0)}.csv\"\n            file = (file_name, csv_buffer.getvalue())\n            return file\n        else:\n            raise Exception(\"Invalid Data Type\")\n\n    def upload_file_and_return_path(data, data_type, tag=None) -&gt; str:\n        \"\"\"Upload a file and return the stored path.\n\n        :param data: Data payload (path or DataFrame).\n        :param data_type: Type of data being uploaded.\n        :param tag: Optional tag.\n        :return: File path stored on the server.\n        \"\"\"\n        files = {\"in_file\": build_upload_data(data)}\n        res = self.api_client.file(\n            f\"{UPLOAD_DATA_FILE_URI}?project_name={self.project_name}&amp;data_type={data_type}&amp;tag={tag}\",\n            files,\n        )\n\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    uploaded_path = upload_file_and_return_path(data, \"data\", tag)\n\n    payload = {\n        \"path\": uploaded_path,\n        \"tag\": tag,\n        \"type\": \"data\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.text.TextProject.upload_data_dataconnectors","title":"upload_data_dataconnectors","text":"<pre><code>upload_data_dataconnectors(\n    data_connector_name,\n    tag,\n    bucket_name=None,\n    file_path=None,\n    dataset_name=None,\n)\n</code></pre> <p>Upload text data stored in a configured data connector (such as S3 or GCS). Requires the connector name, a tag, and optionally the bucket name and file path. Returns the API response.</p> <p>Parameters:</p> Name Type Description Default <code>data_connector_name</code> <code>str</code> <p>Name of the configured data connector</p> required <code>tag</code> <code>str</code> <p>Tag to associate with the uploaded data</p> required <code>bucket_name</code> <code>Optional[str]</code> <p>Name of the bucket or storage location, if required by the connector</p> <code>None</code> <code>file_path</code> <code>Optional[str]</code> <p>File path within the connector storage</p> <code>None</code> <code>dataset_name</code> <code>Optional[str]</code> <p>Optional dataset name to persist the uploaded data</p> <code>None</code> <p>Returns:</p> Type Description <p>a response containing the server\u2019s upload result</p> Source code in <code>lexsi_sdk/core/text.py</code> <pre><code>def upload_data_dataconnectors(\n    self,\n    data_connector_name: str,\n    tag: str,\n    bucket_name: Optional[str] = None,\n    file_path: Optional[str] = None,\n    dataset_name: Optional[str] = None,\n):\n    \"\"\"Upload text data stored in a configured data connector (such as S3 or GCS).\n    Requires the connector name, a tag, and optionally the bucket name and file path.\n    Returns the API response.\n\n    :param data_connector_name: Name of the configured data connector\n    :param tag: Tag to associate with the uploaded data\n    :param bucket_name: Name of the bucket or storage location, if required by the connector\n    :param file_path: File path within the connector storage\n    :param dataset_name: Optional dataset name to persist the uploaded data\n    :return: a response containing the server\u2019s upload result\n    \"\"\"\n\n    def get_connector() -&gt; str | pd.DataFrame:\n        \"\"\"Fetch connector metadata for the requested link service.\n\n        :return: DataFrame of connector info or error string.\n        \"\"\"\n        url = build_list_data_connector_url(\n            LIST_DATA_CONNECTORS, self.project_name, self.organization_id\n        )\n        res = self.api_client.post(url)\n\n        if res[\"success\"]:\n            df = pd.DataFrame(res[\"details\"])\n            filtered_df = df.loc[df[\"link_service_name\"] == data_connector_name]\n            if filtered_df.empty:\n                return \"No data connector found\"\n            return filtered_df\n\n        return res[\"details\"]\n\n    connectors = get_connector()\n    if isinstance(connectors, pd.DataFrame):\n        value = connectors.loc[\n            connectors[\"link_service_name\"] == data_connector_name,\n            \"link_service_type\",\n        ].values[0]\n        ds_type = value\n\n        if ds_type == \"s3\" or ds_type == \"gcs\":\n            if not bucket_name:\n                return \"Missing argument bucket_name\"\n            if not file_path:\n                return \"Missing argument file_path\"\n    else:\n        return connectors\n\n    def upload_file_and_return_path(file_path, data_type, tag=None) -&gt; str:\n        \"\"\"Upload a file from connector storage and return stored path.\n\n        :param file_path: Path within the connector store.\n        :param data_type: Type of data being uploaded.\n        :param tag: Optional tag for the upload.\n        :return: Stored file path returned by the API.\n        \"\"\"\n        if not self.project_name:\n            return \"Missing Project Name\"\n        query_params = f\"project_name={self.project_name}&amp;link_service_name={data_connector_name}&amp;data_type={data_type}&amp;tag={tag}&amp;bucket_name={bucket_name}&amp;file_path={file_path}&amp;dataset_name={dataset_name}\"\n        if self.organization_id:\n            query_params += f\"&amp;organization_id={self.organization_id}\"\n        res = self.api_client.post(f\"{UPLOAD_FILE_DATA_CONNECTORS}?{query_params}\")\n        if not res[\"success\"]:\n            raise Exception(res.get(\"details\"))\n        uploaded_path = res.get(\"metadata\").get(\"filepath\")\n\n        return uploaded_path\n\n    uploaded_path = upload_file_and_return_path(file_path, \"data\", tag)\n\n    payload = {\n        \"path\": uploaded_path,\n        \"tag\": tag,\n        \"type\": \"data\",\n        \"project_name\": self.project_name,\n    }\n    res = self.api_client.post(UPLOAD_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        self.delete_file(uploaded_path)\n        raise Exception(res.get(\"details\"))\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer","title":"Tracer","text":"<pre><code>Tracer()\n</code></pre> <p>Helpers to instrument various agent frameworks with OpenTelemetry.</p> <p>Initialize exporter endpoint from environment. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize exporter endpoint from environment.\n    Stores configuration and prepares the object for use.\"\"\"\n    self.base_url = os.getenv(\"XAI_API_URL\", \"https://apiv1.lexsi.ai\")\n    self.endpoint = f\"{self.base_url}\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_agents_tracing","title":"setup_agents_tracing","text":"<pre><code>setup_agents_tracing(project, session_id=None)\n</code></pre> <p>Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>object</code> <p>Object containing project details; must expose project_name.</p> required <code>session_id</code> <code>str</code> <p>Optional session identifier to annotate spans.</p> <code>None</code> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_agents_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"\n    Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.\n\n    :param project: Object containing project details; must expose project_name.\n    :param session_id: Optional session identifier to annotate spans.\n    \"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"OpenAI-Agents\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # tracer_provider.add_span_processor(ConsoleSpanExporter())\n    # Instrument OpenAI\n    OpenAIAgentsInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_autogen_tracing","title":"setup_autogen_tracing","text":"<pre><code>setup_autogen_tracing(project, session_id=None)\n</code></pre> <p>Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>object</code> <p>Object containing project details; must expose project_name.</p> required <code>session_id</code> <code>str</code> <p>Optional session identifier to annotate spans.</p> <code>None</code> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_autogen_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"\n    Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.\n\n    :param project: Object containing project details; must expose project_name.\n    :param session_id: Optional session identifier to annotate spans.\n    \"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"Autogen\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # Instrument Autogen\n    AutogenAgentChatInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_crewai_tracing","title":"setup_crewai_tracing","text":"<pre><code>setup_crewai_tracing(project, session_id=None)\n</code></pre> <p>Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>object</code> <p>Object containing project details; must expose project_name.</p> required <code>session_id</code> <code>str</code> <p>Optional session identifier to annotate spans.</p> <code>None</code> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_crewai_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"\n    Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.\n\n    :param project: Object containing project details; must expose project_name.\n    :param session_id: Optional session identifier to annotate spans.\n    \"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"Crewai\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # tracer_provider.add_span_processor(ConsoleSpanExporter())\n    # Instrument CrewAI\n    CrewAIInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_dspy_tracing","title":"setup_dspy_tracing","text":"<pre><code>setup_dspy_tracing(project, session_id=None)\n</code></pre> <p>Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>object</code> <p>Object containing project details; must expose project_name.</p> required <code>session_id</code> <code>str</code> <p>Optional session identifier to annotate spans.</p> <code>None</code> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_dspy_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"\n    Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.\n\n    :param project: Object containing project details; must expose project_name.\n    :param session_id: Optional session identifier to annotate spans.\n    \"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"DSPy\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # tracer_provider.add_span_processor(ConsoleSpanExporter())\n    # Instrument DSPy\n    DSPyInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_langchain_tracing","title":"setup_langchain_tracing","text":"<pre><code>setup_langchain_tracing(project, session_id=None)\n</code></pre> <p>Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>object</code> <p>Object containing project details; must expose project_name.</p> required <code>session_id</code> <code>str</code> <p>Optional session identifier to annotate spans.</p> <code>None</code> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_langchain_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"\n    Sets up OpenTelemetry tracing for a given project with OTLP and console exporters.\n\n    :param project: Object containing project details; must expose project_name.\n    :param session_id: Optional session identifier to annotate spans.\n    \"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"Langgraph\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # Instrument LangChain\n    LangChainInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_llamaindex_tracing","title":"setup_llamaindex_tracing","text":"<pre><code>setup_llamaindex_tracing(project, session_id=None)\n</code></pre> <p>Enable tracing for LlamaIndex runs. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_llamaindex_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"Enable tracing for LlamaIndex runs.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"Llamaindex\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # tracer_provider.add_span_processor(ConsoleSpanExporter())\n    # Instrument llama\n    LlamaIndexInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.tracer.Tracer.setup_smolagents_tracing","title":"setup_smolagents_tracing","text":"<pre><code>setup_smolagents_tracing(project, session_id=None)\n</code></pre> <p>Enable tracing for Smolagents runs. Encapsulates a small unit of SDK logic and returns the computed result.</p> Source code in <code>lexsi_sdk/core/tracer.py</code> <pre><code>def setup_smolagents_tracing(self, project: object, session_id: str = None) -&gt; None:\n    \"\"\"Enable tracing for Smolagents runs.\n    Encapsulates a small unit of SDK logic and returns the computed result.\"\"\"\n\n    # Extract project name or use default\n\n    project_name = getattr(project, \"project_name\")\n    # Create resource with service and project details\n    resource = Resource(\n        attributes={\n            \"service.name\": \"Smolagents\",\n            \"project_name\": project_name,\n            \"session_id\": session_id if session_id else \"None\",\n        }\n    )\n\n    # Initialize tracer provider\n    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n    trace_api.set_tracer_provider(tracer_provider)\n\n    # Add OTLP and console span processors\n    tracer_provider.add_span_processor(\n        SimpleSpanProcessor(OTLPSpanExporter(self.endpoint))\n    )\n    # tracer_provider.add_span_processor(ConsoleSpanExporter())\n    # Instrument Smol\n    SmolagentsInstrumentor().instrument()\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.model_summary.ModelSummary","title":"ModelSummary","text":"<pre><code>ModelSummary(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Provides high-level summaries of trained models including features, metrics, drift indicators, and metadata for quick inspection.</p> <p>Store API client reference for subsequent calls. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/model_summary.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Store API client reference for subsequent calls.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.model_summary.ModelSummary.data_config","title":"data_config","text":"<pre><code>data_config()\n</code></pre> <p>Return the data configuration used for the project (e.g., feature exclusions and encodings) by calling the API.</p> <p>Returns:</p> Type Description <p>response</p> Source code in <code>lexsi_sdk/core/model_summary.py</code> <pre><code>def data_config(self):\n    \"\"\"Return the data configuration used for the project (e.g., feature exclusions and encodings) by calling the API.\n\n    :return: response\n    \"\"\"\n    model_name = self.model_results.get(\"model_name\")\n    res = self.api_client.get(\n        f\"{GET_PROJECT_CONFIG}?project_name={self.project_name}&amp;model_name={model_name}\"\n    )\n    if res.get(\"details\") != \"Not Found\":\n        res[\"details\"].pop(\"updated_by\")\n        res[\"details\"][\"metadata\"].pop(\"path\")\n        res[\"details\"][\"metadata\"].pop(\"avaialble_tags\")\n\n    return res.get(\"details\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.model_summary.ModelSummary.feature_importance","title":"feature_importance","text":"<pre><code>feature_importance(xai_method)\n</code></pre> <p>Plot global feature importance for the model using the specified explainability method (SHAP or LIME).</p> Source code in <code>lexsi_sdk/core/model_summary.py</code> <pre><code>def feature_importance(self, xai_method: str):\n    \"\"\"Plot global feature importance for the model using the specified explainability method (SHAP or LIME).\"\"\"\n    global_features = None\n    if xai_method == \"shap\":\n        global_features = self.model_results.get(\"GFI\", {}).get(\"shap_gfi\", None)\n    if xai_method == \"lime\":\n        global_features = self.model_results.get(\"GFI\", {}).get(\"lime_gfi\", None)\n    # if not global_features:\n    #     global_features = self.model_results.get(\"GFI\")\n    if not global_features:\n        return f\"No feature importance found for {xai_method}\"\n    fig = go.Figure()\n\n    fig.add_trace(\n        go.Bar(\n            y=list(global_features.keys()),\n            x=list(global_features.values()),\n            orientation=\"h\",\n        )\n    )\n\n    fig.update_layout(\n        title=\"Global Feaure\",\n        xaxis_title=\"Values\",\n        yaxis_title=\"Features\",\n        width=800,\n        height=600,\n        yaxis_autorange=\"reversed\",\n        bargap=0.01,\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=1.1,\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.model_summary.ModelSummary.info","title":"info","text":"<pre><code>info()\n</code></pre> <p>Return a dictionary summarizing model details such as source, name, type, parameters, data tags used for modeling, and modelling info.</p> <p>Returns:</p> Type Description <code>dict</code> <p>model info dict</p> Source code in <code>lexsi_sdk/core/model_summary.py</code> <pre><code>def info(self) -&gt; dict:\n    \"\"\"Return a dictionary summarizing model details such as source, name, type, parameters, data tags used for modeling, and modelling info.\n\n    :return: model info dict\n    \"\"\"\n    info = {\n        \"source\": self.Source,\n        \"model_name\": self.model_results.get(\"model_name\"),\n        \"model_type\": self.model_results.get(\"model_type\"),\n        \"model_param\": self.model_results.get(\"model_params\"),\n        \"data_tags_used_for_modelling\": self.model_results.get(\"data_used_tags\"),\n        \"modelling_info\": self.model_results.get(\"modelling_info\"),\n    }\n\n    return info\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.model_summary.ModelSummary.prediction_path","title":"prediction_path","text":"<pre><code>prediction_path()\n</code></pre> <p>Display the model\u2019s prediction path as an SVG for the current case, retrieving it from the API.</p> Source code in <code>lexsi_sdk/core/model_summary.py</code> <pre><code>def prediction_path(self):\n    \"\"\"Display the model\u2019s prediction path as an SVG for the current case, retrieving it from the API.\"\"\"\n    model_name = self.model_results.get(\"model_name\")\n    res = self.api_client.get(\n        f\"{MODEL_SVG_URI}?project_name={self.project_name}&amp;model_name={model_name}\"\n    )\n\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    svg = SVG(res.get(\"details\"))\n    display(svg)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticDataTag","title":"SyntheticDataTag","text":"<pre><code>SyntheticDataTag(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Represents metadata for synthetic datasets generated within Lexsi. Used to track lineage, configuration, and dataset properties.</p> <p>Bind API client reference for follow-up requests. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Bind API client reference for follow-up requests.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticDataTag.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata()\n</code></pre> <p>Return the metadata dictionary for the synthetic data tag.</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def get_metadata(self) -&gt; dict:\n    \"\"\"Return the metadata dictionary for the synthetic data tag.\"\"\"\n\n    return self.metadata\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticDataTag.get_model_name","title":"get_model_name","text":"<pre><code>get_model_name()\n</code></pre> <p>Return the name of the synthetic model associated with the tag.</p> <p>Returns:</p> Type Description <code>str</code> <p>model type</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def get_model_name(self) -&gt; str:\n    \"\"\"Return the name of the synthetic model associated with the tag.\n\n    :return: model type\n    \"\"\"\n    return self.model_name\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticDataTag.view_metadata","title":"view_metadata","text":"<pre><code>view_metadata()\n</code></pre> <p>Pretty-print the metadata associated with the synthetic data tag using JSON indentation.</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def view_metadata(self) -&gt; dict:\n    \"\"\"Pretty-print the metadata associated with the synthetic data tag using JSON indentation.\"\"\"\n\n    print(json.dumps(self.metadata, indent=4))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel","title":"SyntheticModel","text":"<pre><code>SyntheticModel(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Represents a synthetic model configuration used for data generation. Exposes model parameters and generation statistics.</p> <p>Bind API client reference for this synthetic model. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Bind API client reference for this synthetic model.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel.anonymity_score","title":"anonymity_score","text":"<pre><code>anonymity_score()\n</code></pre> <p>get anonymity score</p> <p>Returns:</p> Type Description <p>description</p> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def anonymity_score(self):\n    \"\"\"get anonymity score\n\n    :raises Exception: _description_\n    :return: _description_\n    \"\"\"\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": self.model_name,\n    }\n\n    res = self.api_client.post(GET_ANONYMITY_SCORE_URI, payload)\n\n    if not res[\"success\"]:\n        print(res[\"details\"])\n        raise Exception(\"Error while getting anonymity score.\")\n\n    print(\"metadata:\")\n    print(res[\"details\"][\"metadata\"])\n    print(\"\\n\")\n\n    return pd.DataFrame(res[\"details\"][\"scores\"], index=[0])\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel.generate_anonymity_score","title":"generate_anonymity_score","text":"<pre><code>generate_anonymity_score(\n    aux_columns, control_tag, instance_type=\"shared\"\n)\n</code></pre> <p>generate anonymity score</p> <p>Parameters:</p> Name Type Description Default <code>aux_columns</code> <code>List[str]</code> <p>list of features</p> required <code>control_tag</code> <code>str</code> <p>tag</p> required <code>instance_type</code> <code>Optional[str]</code> <p>type of instance to run training for all available instances check xai.available_synthetic_custom_servers() defaults to shared</p> <code>'shared'</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def generate_anonymity_score(\n    self,\n    aux_columns: List[str],\n    control_tag: str,\n    instance_type: Optional[str] = \"shared\",\n):\n    \"\"\"generate anonymity score\n\n    :param aux_columns: list of features\n    :param control_tag: tag\n    :param instance_type: type of instance to run training\n        for all available instances check xai.available_synthetic_custom_servers()\n        defaults to shared\n\n    :return: None\n    \"\"\"\n    if instance_type != \"shared\":\n        available_servers = self.api_client.get(\n            AVAILABLE_SYNTHETIC_CUSTOM_SERVERS_URI\n        )[\"details\"]\n        servers = list(\n            map(lambda instance: instance[\"instance_name\"], available_servers)\n        )\n        Validate.value_against_list(\"instance_type\", instance_type, servers)\n\n    if len(aux_columns) &lt; 2:\n        raise Exception(\"aux_columns requires minimum 2 columns.\")\n\n    project_config = self.project.config()[\"metadata\"]\n\n    Validate.value_against_list(\n        \"feature\", aux_columns, project_config[\"feature_include\"]\n    )\n\n    all_tags = self.project.all_tags()\n\n    Validate.value_against_list(\"tag\", [control_tag], all_tags)\n\n    payload = {\n        \"aux_columns\": aux_columns,\n        \"control_tag\": control_tag,\n        \"model_name\": self.model_name,\n        \"project_name\": self.project_name,\n        \"instance_type\": instance_type,\n    }\n\n    res = self.api_client.post(GENERATE_ANONYMITY_SCORE_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    print(\"Calculating anonymity score...\")\n    poll_events(self.api_client, self.project_name, res[\"event_id\"])\n    print(\"Anonymity score calculated successfully.\\n\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel.generate_synthetic_datapoints","title":"generate_synthetic_datapoints","text":"<pre><code>generate_synthetic_datapoints(\n    num_of_datapoints, instance_type=\"shared\"\n)\n</code></pre> <p>Generate a specified number of synthetic data points using the model. Accepts the number of data points and an optional instance_type for compute resources. If instance_type is not shared, checks available servers and raises errors for invalid values.</p> <p>Parameters:</p> Name Type Description Default <code>num_of_datapoints</code> <code>int</code> <p>total datapoints to generate</p> required <code>instance_type</code> <code>Optional[str]</code> <p>type of instance to run training for all available instances check xai.available_synthetic_custom_servers() defaults to shared</p> <code>'shared'</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def generate_synthetic_datapoints(\n    self, num_of_datapoints: int, instance_type: Optional[str] = \"shared\"\n):\n    \"\"\"Generate a specified number of synthetic data points using the model. Accepts the number of data points and an optional instance_type for compute resources. If instance_type is not shared, checks available servers and raises errors for invalid values.\n\n    :param num_of_datapoints: total datapoints to generate\n    :param instance_type: type of instance to run training\n        for all available instances check xai.available_synthetic_custom_servers()\n        defaults to shared\n    :return: None\n    \"\"\"\n    if instance_type != \"shared\":\n        available_servers = self.api_client.get(\n            AVAILABLE_SYNTHETIC_CUSTOM_SERVERS_URI\n        )[\"details\"]\n        servers = list(\n            map(lambda instance: instance[\"instance_name\"], available_servers)\n        )\n        Validate.value_against_list(\"instance_type\", instance_type, servers)\n\n    payload = {\n        \"project_name\": self.project_name,\n        \"model_name\": self.model_name,\n        \"instance_type\": instance_type,\n        \"num_of_datapoints\": num_of_datapoints,\n    }\n\n    res = self.api_client.post(GENERATE_SYNTHETIC_DATA_URI, payload)\n\n    if not res[\"success\"]:\n        raise Exception(res[\"details\"])\n\n    print(\"Generating synthetic datapoints...\")\n    poll_events(\n        self.api_client,\n        self.project_name,\n        res[\"event_id\"],\n        progress_message=\"Synthetic Data generation progress\",\n    )\n    print(\"Synthetic datapoints generated successfully.\\n\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel.get_data_quality","title":"get_data_quality","text":"<pre><code>get_data_quality()\n</code></pre> <p>Return a DataFrame summarizing the overall synthetic data quality, including scores for column shapes and column pair trends.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>data quality metrics</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def get_data_quality(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame summarizing the overall synthetic data quality, including scores for column shapes and column pair trends.\n\n    :return: data quality metrics\n    \"\"\"\n    quality = {\n        \"overall_quality_score\": self.overall_quality_score,\n        \"column_shapes\": self.column_shapes,\n        \"column_pair_trends\": self.column_pair_trends,\n    }\n\n    df = pd.DataFrame(quality, index=[0])\n\n    return df\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel.get_model_type","title":"get_model_type","text":"<pre><code>get_model_type()\n</code></pre> <p>Return the model type recorded in the metadata dictionary for the synthetic model (e.g., GAN, VAE).</p> <p>Returns:</p> Type Description <code>str</code> <p>model type</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def get_model_type(self) -&gt; str:\n    \"\"\"Return the model type recorded in the metadata dictionary for the synthetic model (e.g., GAN, VAE).\n\n    :return: model type\n    \"\"\"\n    return self.metadata[\"model_name\"]\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticModel.quality_plot","title":"quality_plot","text":"<pre><code>quality_plot()\n</code></pre> <p>Plot a PSI chart of synthetic data quality across different metrics (columns, quality scores, metric names).</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def quality_plot(self):\n    \"\"\"Plot a PSI chart of synthetic data quality across different metrics (columns, quality scores, metric names).\"\"\"\n    x_data = [item[\"Column\"] for item in self.plot_data]\n    y_data = [item[\"Quality Score\"] for item in self.plot_data]\n    metric_data = [item[\"Metric\"] for item in self.plot_data]\n\n    traces = []\n    for metric in set(metric_data):\n        indices = [i for i, val in enumerate(metric_data) if val == metric]\n        traces.append(\n            go.Bar(\n                x=[x_data[i] for i in indices],\n                y=[y_data[i] for i in indices],\n                name=metric,\n            )\n        )\n\n    fig = go.Figure(data=traces)\n\n    fig.update_layout(\n        barmode=\"relative\",\n        # xaxis_title=\"Column Names\",\n        # yaxis_title=\"Quality Score\",\n        height=450,\n        bargap=0.01,\n        legend_orientation=\"h\",\n        legend_x=0.1,\n        legend_y=1.1,\n    )\n\n    fig.show(config={\"displaylogo\": False})\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticPrompt","title":"SyntheticPrompt","text":"<pre><code>SyntheticPrompt(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Prompt abstraction used in synthetic data generation workflows. Defines the generation logic and constraints.</p> <p>Bind API client reference for prompt actions. Stores configuration and prepares the object for use.</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Bind API client reference for prompt actions.\n    Stores configuration and prepares the object for use.\"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticPrompt.get_config","title":"get_config","text":"<pre><code>get_config()\n</code></pre> <p>Return the stored configuration list for the synthetic prompt.</p> <p>Returns:</p> Type Description <code>List[dict]</code> <p>prompt configuration</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def get_config(self) -&gt; List[dict]:\n    \"\"\"Return the stored configuration list for the synthetic prompt.\n\n    :return: prompt configuration\n    \"\"\"\n    return self.configuration\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.synthetic.SyntheticPrompt.get_expression","title":"get_expression","text":"<pre><code>get_expression()\n</code></pre> <p>Construct the textual expression for the synthetic prompt by concatenating conditional expressions defined in its metadata.</p> <p>Returns:</p> Type Description <code>str</code> <p>prompt expression</p> Source code in <code>lexsi_sdk/core/synthetic.py</code> <pre><code>def get_expression(self) -&gt; str:\n    \"\"\"Construct the textual expression for the synthetic prompt by concatenating conditional expressions defined in its metadata.\n\n    :return: prompt expression\n    \"\"\"\n    expression_list = []\n\n    if not self.metadata:\n        raise Exception(\"Expression not found.\")\n\n    for item in self.metadata[\"expression\"]:\n        if isinstance(item, dict):\n            expression_list.append(\n                f\"{item['column']} {item['expression']} {item['value']}\"\n            )\n        else:\n            expression_list.append(item)\n\n    return \" \".join(expression_list)\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.agent.AgentProject","title":"AgentProject","text":"<pre><code>AgentProject(**kwargs)\n</code></pre> <p>               Bases: <code>Project</code></p> <p>Project abstraction for agent-based workflows. Enables tracing, guardrail enforcement, tool invocation tracking, and agent execution analysis.</p> Source code in <code>lexsi_sdk/core/project.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize a `Project` instance and attach the API client.\n    Populates model fields from `kwargs` and stores `api_client` for later requests.\n\n    :param kwargs: Project fields used to construct the instance (including `api_client`).\n    \"\"\"\n    super().__init__(**kwargs)\n    self.api_client = kwargs.get(\"api_client\")\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.agent.AgentProject.messages","title":"messages","text":"<pre><code>messages(session_id)\n</code></pre> <p>Return a DataFrame listing all messages for a given session. Requires the session_id.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>id of the session</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>response</p> Source code in <code>lexsi_sdk/core/agent.py</code> <pre><code>def messages(self, session_id: str) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame listing all messages for a given session. Requires the session_id.\n\n    :param session_id: id of the session\n    :return: response\n    \"\"\"\n    res = self.api_client.get(\n        f\"{MESSAGES_URI}?project_name={self.project_name}&amp;session_id={session_id}\"\n    )\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.agent.AgentProject.sessions","title":"sessions","text":"<pre><code>sessions()\n</code></pre> <p>Return a DataFrame listing all conversation sessions for this agent project.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>response</p> Source code in <code>lexsi_sdk/core/agent.py</code> <pre><code>def sessions(self) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame listing all conversation sessions for this agent project.\n\n    :return: response\n    \"\"\"\n    res = self.api_client.get(f\"{SESSIONS_URI}?project_name={self.project_name}\")\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#lexsi_sdk.core.agent.AgentProject.traces","title":"traces","text":"<pre><code>traces(trace_id)\n</code></pre> <p>Retrieve execution traces for a given trace ID for agent conversations. Returns a DataFrame of trace details.</p> <p>Parameters:</p> Name Type Description Default <code>trace_id</code> <code>str</code> <p>id of the trace</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>response</p> Source code in <code>lexsi_sdk/core/agent.py</code> <pre><code>def traces(self, trace_id: str) -&gt; pd.DataFrame:\n    \"\"\"Retrieve execution traces for a given trace ID for agent conversations. Returns a DataFrame of trace details.\n\n    :param trace_id: id of the trace\n    :return: response\n    \"\"\"\n    res = self.api_client.get(\n        f\"{TRACES_URI}?project_name={self.project_name}&amp;trace_id={trace_id}\"\n    )\n    if not res[\"success\"]:\n        raise Exception(res.get(\"details\"))\n\n    return pd.DataFrame(res.get(\"details\"))\n</code></pre>"},{"location":"sdk/#data-classes","title":"Data Classes","text":""},{"location":"sdk/#lexsi_sdk.common.types.BatchCPUInstanceTypeValues","title":"BatchCPUInstanceTypeValues","text":"<p>               Bases: <code>TypedDict</code></p> <p>Allowed values for batch CPU instance types.</p> <p>Values::</p> <pre><code>\"small\"\n\"xsmall\"\n\"2xsmall\"\n\"3xsmall\"\n\n\"medium\"\n\"xmedium\"\n\"2xmedium\"\n\"3xmedium\"\n\n\"large\"\n\"xlarge\"\n\"2xlarge\"\n\"3xlarge\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.common.types.BatchGPUInstanceTypeValues","title":"BatchGPUInstanceTypeValues","text":"<p>               Bases: <code>TypedDict</code></p> <p>Allowed values for batch GPU instance types.</p> <p>Values::</p> <pre><code>\"T4.small\"\n\"T4.xsmall\"\n\"T4.2xsmall\"\n\"T4.3xsmall\"\n\n\"A10G.medium\"\n\"A10G.xmedium\"\n\"A10G.2xmedium\"\n\"A10G.3xmedium\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.common.types.CatBoostParams","title":"CatBoostParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>CatBoost hyperparameter configuration.</p> <p>Provide only the keys you want to override.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>int | None</code> <p>Number of boosting iterations. Typical range: 100\u201350000.</p> required <code>learning_rate</code> <code>float | None</code> <p>Learning rate. Range: 0.0\u20131.0 (commonly 0.01\u20130.3).</p> required <code>depth</code> <code>int | None</code> <p>Depth of the tree. Typical range: 1\u201316.</p> required <code>subsample_cb</code> <code>float | None</code> <p>Subsample ratio of training data (CatBoost). Range: 0.0\u20131.0.</p> required <code>colsample_bylevel_cb</code> <code>float | None</code> <p>Subsample ratio of columns per level (CatBoost). Range: 0.0\u20131.0.</p> required <code>min_data_in_leaf</code> <code>int | None</code> <p>Minimum number of samples in a leaf node. Typical range: 1\u2013200.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.CustomServerConfig","title":"CustomServerConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Scheduling options when requesting dedicated inference compute.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime | None</code> <p>Start time for the server.</p> required <code>stop</code> <code>datetime | None</code> <p>Stop time for the server.</p> required <code>shutdown_after</code> <code>int | None</code> <p>Auto-shutdown timeout (in hours).</p> required <code>op_hours</code> <code>bool | None</code> <p>Whether to restrict to business hours.</p> required <code>auto_start</code> <code>bool</code> <p>Automatically start the server when requested.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.DataConfig","title":"DataConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration controlling data selection, preprocessing, sampling, imbalance handling, and explainability.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>list[str] | None</code> <p>Tags used to filter training data.</p> required <code>test_tags</code> <code>list[str] | None</code> <p>Tags used to construct the test/holdout dataset.</p> required <code>feature_exclude</code> <code>list[str] | None</code> <p>Features to exclude from training.</p> required <code>feature_encodings</code> <code>dict[str, str] | None</code> <p>Mapping of feature names to encoding strategies. Example: <code>{\"feature_a\": \"labelencode\", \"feature_b\": \"countencode\"}</code></p> required <code>drop_duplicate_uid</code> <code>bool</code> <p>Drop duplicate records based on a unique identifier.</p> required <code>use_optuna</code> <code>bool</code> <p>Enable Optuna for hyperparameter optimization.</p> required <code>sample_percentage</code> <code>float</code> <p>Fraction of data used for training (0.0\u20131.0).</p> required <code>explainability_sample_percentage</code> <code>float</code> <p>Fraction of data used for explainability computations.</p> required <code>lime_explainability_iterations</code> <code>int</code> <p>Number of LIME perturbation iterations.</p> required <code>explainability_method</code> <code>Literal['shap', 'lime'] | None</code> <p>Explainability method to apply. Supported values: <code>\"shap\"</code>, <code>\"lime\"</code>.</p> required <code>handle_data_imbalance</code> <code>bool</code> <p>Apply SMOTE to address class imbalance.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.DedicatedCPUInstanceTypeValues","title":"DedicatedCPUInstanceTypeValues","text":"<p>               Bases: <code>TypedDict</code></p> <p>Allowed values for dedicated CPU instance types.</p> <p>Values::</p> <pre><code>\"t3.xlarge\"\n\"t3.2xlarge\"\n\n\"m4.large\"\n\"m4.xlarge\"\n\"m4.2xlarge\"\n\"m4.4xlarge\"\n\"m4.10xlarge\"\n\"m4.16xlarge\"\n\n\"c4.large\"\n\"c4.xlarge\"\n\"c4.2xlarge\"\n\"c4.4xlarge\"\n\"c4.8xlarge\"\n\n\"c5.9xlarge\"\n\"c5.12xlarge\"\n\"c5.18xlarge\"\n\"c5.24xlarge\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.common.types.DedicatedGPUInstanceTypeValues","title":"DedicatedGPUInstanceTypeValues","text":"<p>               Bases: <code>TypedDict</code></p> <p>Allowed values for dedicated GPU instance types.</p> <p>Values::</p> <pre><code>\"xlargeT4\"\n\"2xlargeT4\"\n\"4xlargeT4\"\n\"8xlargeT4\"\n\"12xlargeT4\"\n\"16xlargeT4\"\n\"32xlargeT4\"\n\n\"xlargeA10G\"\n\"2xlargeA10G\"\n\"4xlargeA10G\"\n\"8xlargeA10G\"\n\n\"4xlargeH100\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.common.types.FoundationalModelParams","title":"FoundationalModelParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Tabular foundational model configuration (TabTune Library).</p> <p>This config is used when <code>model_type</code> is one of the foundational models (e.g., <code>TabPFN</code>, <code>TabICL</code>, <code>TabDPT</code>, <code>OrionMSP</code>, <code>OrionBix</code>, <code>Mitra</code>, <code>ContextTab</code>). It controls execution device, fitting behavior, reproducibility, and probability calibration.</p>"},{"location":"sdk/#lexsi_sdk.common.types.FoundationalModelParams--notes","title":"Notes","text":"<ul> <li>This wrapper passes these fields into the underlying TabTune model runner.   Unsupported fields are ignored or may raise validation errors depending on   wrapper strictness.</li> <li>Some foundational models may not use all fields (e.g., <code>n_estimators</code>).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>Literal['cpu', 'cuda', 'auto'] | None</code> <p>Execution device for the foundational model. Supported by this wrapper: - <code>\"cpu\"</code>: Force CPU execution - <code>\"cuda\"</code>: Force GPU execution - <code>\"auto\"</code>: Select device automatically</p> required <code>fit_mode</code> <code>str | None</code> <p>Controls what is \"fit\" during the training stage. Common wrapper modes: - <code>\"fit_preprocessors\"</code>: fit only preprocessing / encoders - <code>\"fit_model\"</code>: fit the foundational model (and preprocessors if needed) - <code>\"fit_all\"</code>: run full pipeline fitting (preprocessors + model) If your wrapper only supports a subset, document/validate accordingly.</p> required <code>n_estimators</code> <code>int | None</code> <p>Number of estimators / ensemble members (if supported by the model). For models that don\u2019t use ensembles, this may be ignored.</p> required <code>n_jobs</code> <code>int | None</code> <p>Number of parallel jobs/threads to use. Use <code>-1</code> to utilize all available cores.</p> required <code>random_state</code> <code>int | None</code> <p>Random seed for reproducibility.</p> required <code>softmax_temperature</code> <code>float | None</code> <p>Temperature applied to logits before softmax for probability calibration. - <code>1.0</code> keeps probabilities unchanged - <code>&lt; 1.0</code> sharpens probabilities - <code>&gt; 1.0</code> smooths probabilities</p> required"},{"location":"sdk/#lexsi_sdk.common.types.GCSConfig","title":"GCSConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Google Cloud Storage connector configuration.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>GCP project identifier.</p> required <code>gcp_project_name</code> <code>str</code> <p>GCP project name.</p> required <code>type</code> <code>str</code> <p>Credentials type.</p> required <code>private_key_id</code> <code>str</code> <p>Service account private key ID.</p> required <code>private_key</code> <code>str</code> <p>Service account private key PEM string.</p> required <code>client_email</code> <code>str</code> <p>Service account email.</p> required <code>client_id</code> <code>str</code> <p>Service account client ID.</p> required <code>auth_uri</code> <code>str</code> <p>Auth URI.</p> required <code>token_uri</code> <code>str</code> <p>Token URI.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.GDriveConfig","title":"GDriveConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Google Drive connector configuration.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>GCP project identifier.</p> required <code>type</code> <code>str</code> <p>Credentials type.</p> required <code>private_key_id</code> <code>str</code> <p>Service account private key ID.</p> required <code>private_key</code> <code>str</code> <p>Service account private key PEM string.</p> required <code>client_email</code> <code>str</code> <p>Service account email.</p> required <code>client_id</code> <code>str</code> <p>Service account client ID.</p> required <code>auth_uri</code> <code>str</code> <p>Auth URI.</p> required <code>token_uri</code> <code>str</code> <p>Token URI.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.InferenceCompute","title":"InferenceCompute","text":"<p>               Bases: <code>TypedDict</code></p> <p>Inference compute selection payload.</p> <p>Parameters:</p> Name Type Description Default <code>instance_type</code> <code>Union[DedicatedCPUInstanceTypeValues, DedicatedGPUInstanceTypeValues, ServerlessInstanceTypeValues]</code> <p>Instance type identifier. Use str values from supported instance types defined in classes: - <code>DedicatedCPUInstanceTypeValues</code> - <code>DedicatedGPUInstanceTypeValues</code> - <code>ServerlessInstanceTypeValues</code></p> required <code>custom_server_config</code> <code>CustomServerConfig | None</code> <p>Optional scheduling configuration.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.InferenceSettings","title":"InferenceSettings","text":"<p>               Bases: <code>TypedDict</code></p> <p>Inference settings that can be applied to models.</p> <p>Parameters:</p> Name Type Description Default <code>inference_engine</code> <code>str</code> <p>Inference engine for the models Inference Engine - <code>vLLM-AUTO</code> - <code>vLLM-FLASH_ATTN</code> - <code>vLLM-FLASHINFER</code> - <code>vLLM-XFORMERS</code> - <code>SGLang-AUTO</code> - <code>SGLang-TORCH_NATIVE</code> - <code>SGLang-FLASHINFER</code> - <code>SGLang-FA3</code> - <code>Transformers</code> - <code>Transformers-Serverless</code></p> required"},{"location":"sdk/#lexsi_sdk.common.types.LightGBMParams","title":"LightGBMParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>LightGBM hyperparameter configuration.</p> <p>Keys correspond to common LightGBM training parameters. Provide only the keys you want to override.</p> <p>Parameters:</p> Name Type Description Default <code>boosting_type</code> <code>Literal['gbdt', 'dart'] | None</code> <p>Boosting algorithm type. Allowed values: <code>\"gbdt\"</code>, <code>\"dart\"</code>.</p> required <code>num_leaves</code> <code>int | None</code> <p>Maximum number of leaves in one tree. Typical range: 16\u20131024.</p> required <code>max_depth</code> <code>int | None</code> <p>Maximum tree depth. Use -1 for no limit (LightGBM convention) if your training code supports it.</p> required <code>learning_rate</code> <code>float | None</code> <p>Learning rate (shrinkage). Range: 0.0\u20131.0 (commonly 0.01\u20130.3).</p> required <code>n_estimators</code> <code>int | None</code> <p>Number of boosting iterations / trees. Typical range: 50\u20135000.</p> required <code>min_child_samples</code> <code>int | None</code> <p>Minimum number of data points in a leaf. Typical range: 5\u2013200.</p> required <code>min_child_weight</code> <code>float | None</code> <p>Minimum sum of hessian in one leaf. Range: &gt;= 0.</p> required <code>min_split_gain</code> <code>float | None</code> <p>Minimum gain required to make a split. Range: &gt;= 0.</p> required <code>subsample</code> <code>float | None</code> <p>Subsample ratio of the training instances (a.k.a. bagging_fraction). Range: 0.0\u20131.0.</p> required <code>colsample_bytree</code> <code>float | None</code> <p>Subsample ratio of columns when constructing each tree (a.k.a. feature_fraction). Range: 0.0\u20131.0.</p> required <code>tree_learner</code> <code>Literal['serial', 'voting', 'data', 'feature'] | None</code> <p>Tree learning algorithm. Allowed values: <code>\"serial\"</code>, <code>\"voting\"</code>, <code>\"data\"</code>, <code>\"feature\"</code>.</p> required <code>class_weight</code> <code>Literal['balanced'] | None</code> <p>Class weights. Allowed values: <code>\"balanced\"</code>.</p> required <code>random_state</code> <code>int | None</code> <p>Random seed for reproducibility.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.PEFTParams","title":"PEFTParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameter-Efficient Fine-Tuning (PEFT) configuration (TabTune wrapper).</p> <p>This config enables lightweight adaptation (e.g., LoRA) for foundational models. It is typically used when <code>tuning_strategy=\"peft\"</code>.</p>"},{"location":"sdk/#lexsi_sdk.common.types.PEFTParams--notes","title":"Notes","text":"<ul> <li>Applies only to models/backbones that support PEFT in the wrapper.</li> <li>If the underlying model does not support PEFT, these options may be ignored   or raise an error depending on wrapper strictness.</li> <li>All parameters are optional; unspecified values fall back to defaults.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>int | None</code> <p>Rank of the low-rank adaptation matrices (LoRA rank). Typical values: <code>4</code>, <code>8</code>, <code>16</code>, <code>32</code>. Default: <code>8</code>.</p> required <code>lora_alpha</code> <code>int | None</code> <p>Scaling factor for LoRA layers. Typical values: <code>8</code>, <code>16</code>, <code>32</code>, <code>64</code>. Default: <code>16</code>.</p> required <code>lora_dropout</code> <code>float | None</code> <p>Dropout rate applied within LoRA layers. Range: <code>0.0</code> \u2013 <code>0.5</code> (commonly <code>0.0</code> \u2013 <code>0.1</code>). Default: <code>0.05</code>.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.ProcessorParams","title":"ProcessorParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Data preprocessing and feature engineering configuration.</p> <p>These parameters control how input data is cleaned and transformed prior to training. The wrapper typically applies them before fitting either classical ML models or foundational tabular models.</p> <p>Parameters:</p> Name Type Description Default <code>imputation_strategy</code> <code>Literal['mean', 'median', 'mode', 'knn'] | None</code> <p>Strategy to handle missing values. Supported by this wrapper: - <code>\"mean\"</code>: numerical mean - <code>\"median\"</code>: numerical median - <code>\"mode\"</code>: most frequent value - <code>\"knn\"</code>: kNN-based imputation</p> required <code>scaling_strategy</code> <code>Literal['standard', 'minmax', 'robust'] | None</code> <p>Feature scaling method. Supported by this wrapper: - <code>\"standard\"</code>: standardization (z-score) - <code>\"minmax\"</code>: min-max scaling - <code>\"robust\"</code>: robust scaling (median/IQR)</p> required <code>resampling_strategy</code> <code>Literal['smote', 'random_oversample', 'none'] | None</code> <p>Strategy to address class imbalance (classification). Supported by this wrapper: - <code>\"smote\"</code>: SMOTE oversampling - <code>\"random_oversample\"</code>: random oversampling - <code>\"none\"</code>: do not resample</p> required"},{"location":"sdk/#lexsi_sdk.common.types.ProjectConfig","title":"ProjectConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration keys required to describe a project.</p> <p>Parameters:</p> Name Type Description Default <code>project_type</code> <code>str | None</code> <p>Project type identifier.</p> required <code>model_name</code> <code>str | None</code> <p>Model name associated with the project.</p> required <code>unique_identifier</code> <code>str</code> <p>Column name used as the unique identifier.</p> required <code>true_label</code> <code>str</code> <p>Column name containing ground-truth labels.</p> required <code>tag</code> <code>str</code> <p>Column name used to tag/filter records.</p> required <code>pred_label</code> <code>str | None</code> <p>Column name containing predicted labels (if present).</p> required <code>feature_exclude</code> <code>list[str] | None</code> <p>Features to exclude from training/inference.</p> required <code>drop_duplicate_uid</code> <code>bool | None</code> <p>Drop duplicate records based on the unique identifier.</p> required <code>handle_errors</code> <code>bool | None</code> <p>Whether to handle/ignore errors during processing.</p> required <code>feature_encodings</code> <code>dict | None</code> <p>Mapping of feature names to encoding strategies.</p> required <code>handle_data_imbalance</code> <code>bool | None</code> <p>Apply imbalance handling (e.g., SMOTE).</p> required <code>sample_percentage</code> <code>float | None</code> <p>Fraction of data used for training (0.0\u20131.0).</p> required <code>explainability_method</code> <code>list[str] | None</code> <p>Explainability methods to apply.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.RandomForestParams","title":"RandomForestParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>RandomForest hyperparameter configuration.</p> <p>Provide only the keys you want to override.</p> <p>Parameters:</p> Name Type Description Default <code>max_depth</code> <code>int | None</code> <p>Maximum depth of the tree. Use <code>None</code> for unlimited depth (if supported by your training wrapper).</p> required <code>max_features</code> <code>int | float | Literal['auto', 'sqrt', 'log2'] | None</code> <p>Number of features to consider when looking for the best split. Allowed values: - <code>\"auto\"</code> (implementation-dependent; often same as <code>\"sqrt\"</code> for classification) - <code>\"sqrt\"</code> - <code>\"log2\"</code> - <code>int</code> (absolute number of features) - <code>float</code> (fraction of features, 0.0\u20131.0)</p> required <code>max_leaf_nodes</code> <code>int | None</code> <p>Maximum number of leaf nodes.</p> required <code>min_samples_leaf</code> <code>int | None</code> <p>Minimum number of samples required to be at a leaf node. Typical range: 1\u201350.</p> required <code>min_samples_split</code> <code>int | None</code> <p>Minimum number of samples required to split an internal node. Typical range: 2\u2013200.</p> required <code>n_estimators</code> <code>int | None</code> <p>Number of trees in the forest. Typical range: 10\u20135000.</p> required <code>criterion</code> <code>Literal['gini', 'entropy', 'mse', 'squared_error'] | None</code> <p>Function to measure the quality of a split. Allowed values: - Classification: <code>\"gini\"</code>, <code>\"entropy\"</code> - Regression: <code>\"squared_error\"</code>, <code>\"mse\"</code></p> required"},{"location":"sdk/#lexsi_sdk.common.types.S3Config","title":"S3Config","text":"<p>               Bases: <code>TypedDict</code></p> <p>Amazon S3 connector configuration.</p> <p>Parameters:</p> Name Type Description Default <code>region</code> <code>str | None</code> <p>AWS region (e.g., <code>\"us-east-1\"</code>).</p> required <code>access_key</code> <code>str</code> <p>AWS access key ID.</p> required <code>secret_key</code> <code>str</code> <p>AWS secret access key.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.SFTPConfig","title":"SFTPConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>SFTP connector configuration.</p> <p>Parameters:</p> Name Type Description Default <code>hostname</code> <code>str</code> <p>SFTP host.</p> required <code>port</code> <code>str</code> <p>SFTP port.</p> required <code>username</code> <code>str</code> <p>SFTP username.</p> required <code>password</code> <code>str</code> <p>SFTP password.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.ServerlessInstanceTypeValues","title":"ServerlessInstanceTypeValues","text":"<p>               Bases: <code>TypedDict</code></p> <p>Allowed values for serverless instance types.</p> <p>Values::</p> <pre><code>\"nova-0.5\"\n\"nova-1\"\n\"nova-1.5\"\n\"nova-2\"\n\"nova-4\"\n\"nova-6\"\n\"nova-8\"\n\"nova-10\"\n\n\"gova-0.5\"\n\"gova-1\"\n\"gova-1.5\"\n\"gova-2\"\n\"gova-4\"\n\"gova-6\"\n\"gova-8\"\n\"gova-10\"\n\"gova-12\"\n\"gova-14\"\n\"gova-16\"\n\"gova-18\"\n\"gova-20\"\n\"gova-22\"\n\"gova-24\"\n</code></pre>"},{"location":"sdk/#lexsi_sdk.common.types.SyntheticDataConfig","title":"SyntheticDataConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration required when generating synthetic data.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Synthetic model name (e.g., CTGAN/GPT2 tabular).</p> required <code>tags</code> <code>list[str]</code> <p>Tags used to filter source data.</p> required <code>feature_exclude</code> <code>list[str]</code> <p>Features to exclude from synthetic training/generation.</p> required <code>feature_include</code> <code>list[str]</code> <p>Features to include for synthetic training/generation.</p> required <code>feature_actual_used</code> <code>list[str]</code> <p>Final set of features actually used (post-validation).</p> required <code>drop_duplicate_uid</code> <code>bool</code> <p>Drop duplicate records based on a unique identifier.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.SyntheticModelHyperParams","title":"SyntheticModelHyperParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Common hyperparameter keys for supported synthetic models.</p> <p>GPT2-related keys:</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int | None</code> <p>Training batch size.</p> required <code>early_stopping_patience</code> <code>int | None</code> <p>Epochs to wait before early stopping.</p> required <code>early_stopping_threshold</code> <code>float | None</code> <p>Minimum improvement threshold for early stopping.</p> required <code>epochs</code> <code>int | None</code> <p>Training epochs.</p> required <code>model_type</code> <code>str | None</code> <p>Model type identifier.</p> required <code>random_state</code> <code>int | None</code> <p>Random seed.</p> required <code>tabular_config</code> <code>str | None</code> <p>Tabular configuration identifier/name.</p> required <code>train_size</code> <code>float | None  CTGAN-related keys:</code> <p>Fraction of data used for training (0.0\u20131.0).</p> required <code>test_ratio</code> <code>float | None</code> <p>Fraction of data used for validation/testing (0.0\u20131.0).</p> required"},{"location":"sdk/#lexsi_sdk.common.types.TuningParams","title":"TuningParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Hyperparameter tuning / fine-tuning configuration (TabTune wrapper).</p> <p>This config controls optimization loops used in: - meta-learning or episodic training - few-shot adaptation - iterative fine-tuning / search</p>"},{"location":"sdk/#lexsi_sdk.common.types.TuningParams--notes","title":"Notes","text":"<ul> <li>These fields may be used only for foundational models (depending on the   wrapper logic).</li> <li>If both episodic (support/query) and standard training fields are provided,   the wrapper should define precedence clearly.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>epochs</code> <code>int | None</code> <p>Number of training epochs. Typical range: 1\u2013200 (depends on model and dataset size).</p> required <code>learning_rate</code> <code>float | None</code> <p>Learning rate used during optimization. Common range: 1e-5\u20131e-1.</p> required <code>batch_size</code> <code>int | None</code> <p>Number of samples per batch. Typical range: 8\u20134096 depending on model and memory.</p> required <code>support_size</code> <code>int | None</code> <p>Number of support samples per episode (few-shot). Example: 16, 32, 64.</p> required <code>query_size</code> <code>int | None</code> <p>Number of query samples per episode (few-shot). Example: 16, 32, 64.</p> required <code>n_episodes</code> <code>int | None</code> <p>Number of episodes for meta-learning / episodic training. Typical range: 50\u20135000.</p> required <code>steps_per_epoch</code> <code>int | None</code> <p>Number of optimization steps per epoch. If not provided, the wrapper may infer it from dataset size and batch size.</p> required"},{"location":"sdk/#lexsi_sdk.common.types.XGBoostParams","title":"XGBoostParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>XGBoost hyperparameter configuration.</p> <p>Keys correspond to common XGBoost training parameters. Provide only the keys you want to override.</p> <p>Parameters:</p> Name Type Description Default <code>objective</code> <code>str | None</code> <p>Learning objective. Common values: <code>\"binary:logistic\"</code>, <code>\"binary:logitraw\"</code>, <code>\"multi:softprob\"</code>, <code>\"reg:squarederror\"</code>, <code>\"reg:logistic\"</code>, <code>\"rank:pairwise\"</code>.</p> required <code>booster</code> <code>Literal['gbtree', 'gblinear'] | None</code> <p>Booster type. Allowed values: <code>\"gbtree\"</code>, <code>\"gblinear\"</code>.</p> required <code>eval_metric</code> <code>str | None</code> <p>Evaluation metric used during training. Common values: <code>\"logloss\"</code>, <code>\"auc\"</code>, <code>\"aucpr\"</code>, <code>\"error\"</code>, <code>\"rmse\"</code>, <code>\"mae\"</code>, <code>\"merror\"</code>, <code>\"mlogloss\"</code>.</p> required <code>grow_policy</code> <code>Literal['depthwise', 'lossguide'] | None</code> <p>Tree growth policy (tree-based boosters). Allowed values: <code>\"depthwise\"</code>, <code>\"lossguide\"</code>.</p> required <code>max_depth</code> <code>int | None</code> <p>Maximum depth of a tree. Typical range: 1\u201316.</p> required <code>max_leaves</code> <code>int | None</code> <p>Maximum number of leaves per tree (used with <code>lossguide</code>). Typical range: 0\u20134096 (0 means \"no limit\" depending on implementation).</p> required <code>min_child_weight</code> <code>float | None</code> <p>Minimum sum of instance weight needed in a child. Higher values make the model more conservative.</p> required <code>colsample_bytree</code> <code>float | None</code> <p>Subsample ratio of columns when constructing each tree. Range: 0.0\u20131.0.</p> required <code>colsample_bylevel</code> <code>float | None</code> <p>Subsample ratio of columns for each level. Range: 0.0\u20131.0.</p> required <code>colsample_bynode</code> <code>float | None</code> <p>Subsample ratio of columns for each split/node. Range: 0.0\u20131.0.</p> required <code>learning_rate</code> <code>float | None</code> <p>Step size shrinkage (eta). Range: 0.0\u20131.0 (commonly 0.01\u20130.3).</p> required <code>n_estimators</code> <code>int | None</code> <p>Number of boosting rounds / trees. Typical range: 50\u20135000.</p> required <code>subsample</code> <code>float | None</code> <p>Subsample ratio of the training instances. Range: 0.0\u20131.0.</p> required <code>alpha</code> <code>float | None</code> <p>L1 regularization term on weights (reg_alpha). Range: &gt;= 0.</p> required <code>lambda_</code> <code>float | None</code> <p>L2 regularization term on weights (reg_lambda). Range: &gt;= 0.</p> required <code>seed</code> <code>int | None</code> <p>Random seed for reproducibility.</p> required"}]}